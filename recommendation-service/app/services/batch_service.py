import asyncio
import schedule
import time
from typing import List, Dict, Any
from datetime import datetime, timedelta

from app.services.database_service import DatabaseService
from app.services.als_service import ALSRecommendationService
from app.utils.logger import get_logger
from app.models.schemas import RecommendationType

logger = get_logger(__name__)

class BatchService:
    """ì¶”ì²œ ì‹œìŠ¤í…œ ë°°ì¹˜ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.db_service = DatabaseService()
        self.rec_service = ALSRecommendationService()
        self.is_running = False
    
    async def run_full_batch(self) -> bool:
        """ì „ì²´ ì‚¬ìš©ì ì¶”ì²œ ë°°ì¹˜ ì²˜ë¦¬"""
        logger.info("ğŸš€ ì „ì²´ ì¶”ì²œ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
        
        # ëŒ€ìƒ ì‚¬ìš©ì ì¡°íšŒ
        user_ids = self.db_service.get_users_for_batch_processing("full")
        if not user_ids:
            logger.warning("âš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # ë°°ì¹˜ ë¡œê·¸ ìƒì„± (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        batch_id = self.db_service.create_batch_log("full", len(user_ids))
        if not batch_id:
            logger.info("â„¹ï¸ DB ë°°ì¹˜ ë¡œê·¸ ë¯¸ì‚¬ìš© - íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©í•˜ì—¬ ê³„ì† ì§„í–‰")
            batch_id = -1  # ì„ì‹œ ID
        
        try:
            all_recommendations = []
            processed_users = 0
            
            # ì‚¬ìš©ìë³„ ì¶”ì²œ ìƒì„± (ë°°ì¹˜ ë‹¨ìœ„ë¡œ)
            batch_size = 100
            for i in range(0, len(user_ids), batch_size):
                batch_users = user_ids[i:i + batch_size]
                
                for user_id in batch_users:
                    try:
                        # ì‚¬ìš©ìë³„ ì¶”ì²œ ìƒì„±
                        user_recs = await self._generate_user_recommendations(user_id)
                        all_recommendations.extend(user_recs)
                        processed_users += 1
                        
                        # ì§„í–‰ìƒí™© ë¡œê¹…
                        if processed_users % 50 == 0:
                            logger.info(f"ğŸ“Š ì§„í–‰ìƒí™©: {processed_users}/{len(user_ids)} ì‚¬ìš©ì ì²˜ë¦¬ ì™„ë£Œ")
                            
                    except Exception as e:
                        logger.error(f"âŒ ì‚¬ìš©ì {user_id} ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                        continue
                
                # ë°°ì¹˜ ë‹¨ìœ„ë¡œ DB ì €ì¥
                if all_recommendations:
                    success = self.db_service.save_recommendations_batch(
                        all_recommendations[-len(batch_users)*10:], batch_id if batch_id > 0 else 0
                    )
                    if not success:
                        logger.error("âŒ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨")
                        break
            
            # ìµœì¢… ë°°ì¹˜ ë¡œê·¸ ì—…ë°ì´íŠ¸ (batch_idê°€ ìœ íš¨í•œ ê²½ìš°ë§Œ)
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, len(all_recommendations), "completed"
                )
            
            logger.info(f"âœ… ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {processed_users}ëª…, {len(all_recommendations)}ê±´ ì¶”ì²œ")
            
            # ë°°ì¹˜ ë¡œê·¸ë¥¼ íŒŒì¼ì—ë„ ê¸°ë¡
            self._write_batch_log_to_file("full", processed_users, len(all_recommendations), "completed")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, 0, "failed", str(e)
                )
            self._write_batch_log_to_file("full", processed_users, 0, "failed", str(e))
            return False
    
    async def run_incremental_batch(self) -> bool:
        """ì¦ë¶„ ì¶”ì²œ ë°°ì¹˜ ì²˜ë¦¬ (ìµœê·¼ í™œë™ ì‚¬ìš©ìë§Œ)"""
        logger.info("ğŸ”„ ì¦ë¶„ ì¶”ì²œ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
        
        # ìµœê·¼ í™œë™ ì‚¬ìš©ì ì¡°íšŒ
        user_ids = self.db_service.get_users_for_batch_processing("incremental")
        if not user_ids:
            logger.info("â„¹ï¸ ì¦ë¶„ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
            return True
        
        # ë°°ì¹˜ ë¡œê·¸ ìƒì„± (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        batch_id = self.db_service.create_batch_log("incremental", len(user_ids))
        if not batch_id:
            logger.info("â„¹ï¸ DB ë°°ì¹˜ ë¡œê·¸ ë¯¸ì‚¬ìš© - íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©í•˜ì—¬ ê³„ì† ì§„í–‰")
            batch_id = -1  # ì„ì‹œ ID
        
        try:
            all_recommendations = []
            processed_users = 0
            
            for user_id in user_ids:
                try:
                    user_recs = await self._generate_user_recommendations(user_id)
                    all_recommendations.extend(user_recs)
                    processed_users += 1
                    
                except Exception as e:
                    logger.error(f"âŒ ì‚¬ìš©ì {user_id} ì¦ë¶„ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
                    continue
            
            # DB ì €ì¥
            if all_recommendations:
                success = self.db_service.save_recommendations_batch(
                    all_recommendations, batch_id if batch_id > 0 else 0
                )
                
                if success:
                    if batch_id > 0:
                        self.db_service.update_batch_log(
                            batch_id, processed_users, len(all_recommendations), "completed"
                        )
                    logger.info(f"âœ… ì¦ë¶„ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {processed_users}ëª…, {len(all_recommendations)}ê±´ ì¶”ì²œ")
                    
                    # ë°°ì¹˜ ë¡œê·¸ë¥¼ íŒŒì¼ì—ë„ ê¸°ë¡
                    self._write_batch_log_to_file("incremental", processed_users, len(all_recommendations), "completed")
                    
                    return True
                else:
                    logger.error("âŒ ì¦ë¶„ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨")
                    if batch_id > 0:
                        self.db_service.update_batch_log(
                            batch_id, processed_users, 0, "failed", "ì €ì¥ ì‹¤íŒ¨"
                        )
                    self._write_batch_log_to_file("incremental", processed_users, 0, "failed", "ì €ì¥ ì‹¤íŒ¨")
                    return False
            else:
                logger.info("â„¹ï¸ ìƒì„±ëœ ì¶”ì²œì´ ì—†ìŠµë‹ˆë‹¤")
                if batch_id > 0:
                    self.db_service.update_batch_log(
                        batch_id, processed_users, 0, "completed"
                    )
                self._write_batch_log_to_file("incremental", processed_users, 0, "completed", "ì¶”ì²œ ì—†ìŒ")
                return True
                
        except Exception as e:
            logger.error(f"âŒ ì¦ë¶„ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, 0, "failed", str(e)
                )
            self._write_batch_log_to_file("incremental", processed_users, 0, "failed", str(e))
            return False
    
    async def run_mini_batch(self, user_limit: int = 50) -> bool:
        """Mini ë°°ì¹˜ ì²˜ë¦¬ (ì‚¬ìš©ì ìˆ˜ ì œí•œ)"""
        logger.info(f"ğŸ”„ Mini ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (ìµœëŒ€ {user_limit}ëª…)")
        
        # ì œí•œëœ ìˆ˜ì˜ ì‚¬ìš©ì ì¡°íšŒ
        all_user_ids = self.db_service.get_users_for_batch_processing("full")
        if not all_user_ids:
            logger.info("â„¹ï¸ ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
            return True
        
        # ì‚¬ìš©ì ìˆ˜ ì œí•œ
        user_ids = all_user_ids[:user_limit]
        logger.info(f"ğŸ“Š ì „ì²´ ì‚¬ìš©ì: {len(all_user_ids)}ëª…, Mini ë°°ì¹˜ ëŒ€ìƒ: {len(user_ids)}ëª…")
        
        # ë°°ì¹˜ ë¡œê·¸ ìƒì„±
        batch_id = self.db_service.create_batch_log("mini", len(user_ids))
        if not batch_id:
            logger.info("â„¹ï¸ DB ë°°ì¹˜ ë¡œê·¸ ë¯¸ì‚¬ìš© - íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©í•˜ì—¬ ê³„ì† ì§„í–‰")
            batch_id = -1
        
        try:
            all_recommendations = []
            processed_users = 0
            
            # ì‚¬ìš©ìë³„ ì¶”ì²œ ìƒì„± (ì†Œê·œëª¨ ë°°ì¹˜)
            batch_size = 20  # mini batchëŠ” ë” ì‘ì€ ë‹¨ìœ„ë¡œ
            for i in range(0, len(user_ids), batch_size):
                batch_users = user_ids[i:i + batch_size]
                
                for user_id in batch_users:
                    try:
                        user_recs = await self._generate_user_recommendations(user_id)
                        all_recommendations.extend(user_recs)
                        processed_users += 1
                        
                        # ì§„í–‰ìƒí™© ë¡œê¹… (mini batchëŠ” ë” ìì£¼)
                        if processed_users % 10 == 0:
                            logger.info(f"ğŸ“Š Mini ë°°ì¹˜ ì§„í–‰: {processed_users}/{len(user_ids)} ì‚¬ìš©ì ì²˜ë¦¬ ì™„ë£Œ")
                            
                    except Exception as e:
                        logger.error(f"âŒ ì‚¬ìš©ì {user_id} ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                        continue
                
                # ë°°ì¹˜ ë‹¨ìœ„ë¡œ DB ì €ì¥
                if all_recommendations:
                    batch_recs = all_recommendations[-len(batch_users)*10:]
                    success = self.db_service.save_recommendations_batch(
                        batch_recs, batch_id if batch_id > 0 else 0
                    )
                    if not success:
                        logger.error("âŒ Mini ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨")
                        break
            
            # ìµœì¢… ë°°ì¹˜ ë¡œê·¸ ì—…ë°ì´íŠ¸
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, len(all_recommendations), "completed"
                )
            
            logger.info(f"âœ… Mini ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {processed_users}ëª…, {len(all_recommendations)}ê±´ ì¶”ì²œ")
            
            # íŒŒì¼ ë¡œê·¸ ê¸°ë¡
            self._write_batch_log_to_file("mini", processed_users, len(all_recommendations), "completed")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Mini ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, 0, "failed", str(e)
                )
            self._write_batch_log_to_file("mini", processed_users, 0, "failed", str(e))
            return False
    
    async def _generate_user_recommendations(self, user_id: int) -> List[Dict[str, Any]]:
        """ê°œë³„ ì‚¬ìš©ì ì¶”ì²œ ìƒì„±"""
        recommendations = []
        
        try:
            # ì—¬í–‰ ê¸°ë¡ ì¶”ì²œ (enum ì‚¬ìš©)
            log_recs, algorithm = self.rec_service.get_recommendations(
                user_id=user_id, 
                rec_type=RecommendationType.RECORD, 
                limit=10
            )
            
            for rec_item in log_recs:
                recommendations.append({
                    "user_id": user_id,
                    "item_id": rec_item.item_id, 
                    "item_type": "log",
                    "score": rec_item.score
                })
                
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì {user_id} ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            # ë¹ˆ ì¶”ì²œ ë°˜í™˜
            
        return recommendations
    
    def start_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if self.is_running:
            logger.warning("âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        logger.info("ğŸ• ì¶”ì²œ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
        
        # ìŠ¤ì¼€ì¤„ ë“±ë¡
        schedule.every().day.at("02:00").do(self._run_full_batch_sync)      # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
        schedule.every(6).hours.do(self._run_incremental_batch_sync)        # 6ì‹œê°„ë§ˆë‹¤
        
        self.is_running = True
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ë£¨í”„
        while self.is_running:
            try:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
            except KeyboardInterrupt:
                logger.info("ğŸ›‘ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ë‹¨ ìš”ì²­")
                break
            except Exception as e:
                logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {str(e)}")
                time.sleep(60)
        
        logger.info("â¹ï¸ ì¶”ì²œ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ")
    
    def stop_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        self.is_running = False
        schedule.clear()
        logger.info("ğŸ›‘ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ë¨")
    
    def _write_batch_log_to_file(self, batch_type: str, processed_users: int, 
                                total_recommendations: int, status: str, 
                                error_message: str = None):
        """ë°°ì¹˜ ë¡œê·¸ë¥¼ íŒŒì¼ì— ê¸°ë¡ (DB ì‹¤íŒ¨ ì‹œ ë°±ì—…ìš©)"""
        try:
            import os
            from datetime import datetime
            
            log_file = "/app/logs/batch.log"
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            log_entry = f"[{timestamp}] {batch_type.upper()} BATCH - "
            log_entry += f"Status: {status}, Users: {processed_users}, Recommendations: {total_recommendations}"
            
            if error_message:
                log_entry += f", Error: {error_message}"
            
            log_entry += "\n"
            
            # ë¡œê·¸ íŒŒì¼ì— ì¶”ê°€
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(log_entry)
                
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {str(e)}")
    
    def _run_full_batch_sync(self):
        """ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì „ì²´ ë°°ì¹˜ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ìš©)"""
        asyncio.run(self.run_full_batch())
    
    def _run_incremental_batch_sync(self):
        """ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì¦ë¶„ ë°°ì¹˜ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ìš©)"""
        asyncio.run(self.run_incremental_batch())
    
    async def manual_batch_trigger(self, batch_type: str = "incremental", user_limit: int = None) -> Dict[str, Any]:
        """ìˆ˜ë™ ë°°ì¹˜ íŠ¸ë¦¬ê±° (APIìš©)"""
        logger.info(f"ğŸ”§ ìˆ˜ë™ ë°°ì¹˜ íŠ¸ë¦¬ê±°: {batch_type}" + (f" (ìµœëŒ€ {user_limit}ëª…)" if user_limit else ""))
        
        start_time = datetime.now()
        
        if batch_type == "full":
            success = await self.run_full_batch()
        elif batch_type == "mini":
            if user_limit is None:
                user_limit = 50  # ê¸°ë³¸ê°’
            success = await self.run_mini_batch(user_limit)
        else:  # incremental
            success = await self.run_incremental_batch()
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        return {
            "success": success,
            "batch_type": batch_type,
            "user_limit": user_limit if batch_type == "mini" else None,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": duration
        } 
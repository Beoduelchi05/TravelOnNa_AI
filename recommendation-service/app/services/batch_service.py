import asyncio
import schedule
import time
from typing import List, Dict, Any
from datetime import datetime, timedelta

from app.services.database_service import DatabaseService
from app.services.als_service import ALSRecommendationService
from app.utils.logger import get_logger
from app.models.schemas import RecommendationType

logger = get_logger(__name__)

class BatchService:
    """ì¶”ì²œ ì‹œìŠ¤í…œ ë°°ì¹˜ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.db_service = DatabaseService()
        self.rec_service = ALSRecommendationService()
        self.is_running = False
        self.memory_limit_mb = 1500  # ë©”ëª¨ë¦¬ ì œí•œ (1.5GB)
    
    async def run_full_batch(self) -> bool:
        """ì „ì²´ ì‚¬ìš©ì ì¶”ì²œ ë°°ì¹˜ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )"""
        logger.info("ğŸš€ ì „ì²´ ì¶”ì²œ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°©ì‹)")
        
        # ëŒ€ìƒ ì‚¬ìš©ì ì¡°íšŒ
        user_ids = self.db_service.get_users_for_batch_processing("full")
        if not user_ids:
            logger.warning("âš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # ë°°ì¹˜ ë¡œê·¸ ìƒì„± (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        batch_id = self.db_service.create_batch_log("full", len(user_ids))
        if not batch_id:
            logger.info("â„¹ï¸ DB ë°°ì¹˜ ë¡œê·¸ ë¯¸ì‚¬ìš© - íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©í•˜ì—¬ ê³„ì† ì§„í–‰")
            batch_id = -1  # ì„ì‹œ ID
        
        try:
            total_recommendations = 0
            processed_users = 0
            
            # **ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬**: ì‘ì€ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ê³  ì¦‰ì‹œ ì €ì¥
            batch_size = 20  # ë°°ì¹˜ í¬ê¸°ë¥¼ ë” ì‘ê²Œ (ë©”ëª¨ë¦¬ ì ˆì•½)
            
            for i in range(0, len(user_ids), batch_size):
                batch_users = user_ids[i:i + batch_size]
                batch_recommendations = []  # ë°°ì¹˜ë³„ ì„ì‹œ ì €ì¥ì†Œ
                
                logger.info(f"ğŸ“¦ ë°°ì¹˜ {i//batch_size + 1}/{(len(user_ids)-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘: {len(batch_users)}ëª…")
                
                for user_id in batch_users:
                    try:
                        # ì‚¬ìš©ìë³„ ì¶”ì²œ ìƒì„±
                        user_recs = await self._generate_user_recommendations(user_id)
                        batch_recommendations.extend(user_recs)
                        processed_users += 1
                        
                        # ì§„í–‰ìƒí™© ë¡œê¹…
                        if processed_users % 50 == 0:
                            logger.info(f"ğŸ“Š ì§„í–‰ìƒí™©: {processed_users}/{len(user_ids)} ì‚¬ìš©ì ì²˜ë¦¬ ì™„ë£Œ")
                            
                    except Exception as e:
                        logger.error(f"âŒ ì‚¬ìš©ì {user_id} ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                        continue
                
                # **ì¦‰ì‹œ DB ì €ì¥ ë° ë©”ëª¨ë¦¬ í•´ì œ**
                if batch_recommendations:
                    success = self.db_service.save_recommendations_batch(
                        batch_recommendations, batch_id if batch_id > 0 else 0
                    )
                    
                    if success:
                        total_recommendations += len(batch_recommendations)
                        logger.info(f"âœ… ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {len(batch_recommendations)}ê±´, ëˆ„ì : {total_recommendations}ê±´")
                    else:
                        logger.error("âŒ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨ - ì²˜ë¦¬ ì¤‘ë‹¨")
                        break
                
                # **ë©”ëª¨ë¦¬ í•´ì œ**
                del batch_recommendations
                
                # **ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰**
                import gc
                gc.collect()
                
                # **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ ë° ì œí•œ í™•ì¸**
                if not self._check_memory_usage():
                    logger.error("âŒ ë©”ëª¨ë¦¬ ì œí•œ ì´ˆê³¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ë‹¨")
                    # í˜„ì¬ê¹Œì§€ì˜ ê²°ê³¼ëŠ” ìœ ì§€í•˜ê³  ì¤‘ë‹¨
                    if batch_id > 0:
                        self.db_service.update_batch_log(
                            batch_id, processed_users, total_recommendations, "stopped", "ë©”ëª¨ë¦¬ ì œí•œ ì´ˆê³¼"
                        )
                    self._write_batch_log_to_file("full", processed_users, total_recommendations, "stopped", "ë©”ëª¨ë¦¬ ì œí•œ ì´ˆê³¼")
                    return False
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë„ˆë¬´ ë†’ìœ¼ë©´ ê²½ê³ 
                try:
                    import psutil
                    process = psutil.Process()
                    memory_mb = process.memory_info().rss / 1024 / 1024
                    if memory_mb > 1024:  # 1GB ì´ˆê³¼
                        logger.warning(f"âš ï¸ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì§€: {memory_mb:.1f}MB")
                except:
                    pass
            
            # ìµœì¢… ë°°ì¹˜ ë¡œê·¸ ì—…ë°ì´íŠ¸ (batch_idê°€ ìœ íš¨í•œ ê²½ìš°ë§Œ)
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, total_recommendations, "completed"
                )
            
            logger.info(f"âœ… ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {processed_users}ëª…, {total_recommendations}ê±´ ì¶”ì²œ")
            
            # ë°°ì¹˜ ë¡œê·¸ë¥¼ íŒŒì¼ì—ë„ ê¸°ë¡
            self._write_batch_log_to_file("full", processed_users, total_recommendations, "completed")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, 0, "failed", str(e)
                )
            self._write_batch_log_to_file("full", processed_users, 0, "failed", str(e))
            return False
    
    async def run_incremental_batch(self) -> bool:
        """ì¦ë¶„ ì¶”ì²œ ë°°ì¹˜ ì²˜ë¦¬ (ìµœê·¼ í™œë™ ì‚¬ìš©ìë§Œ)"""
        logger.info("ğŸ”„ ì¦ë¶„ ì¶”ì²œ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
        
        # ìµœê·¼ í™œë™ ì‚¬ìš©ì ì¡°íšŒ
        user_ids = self.db_service.get_users_for_batch_processing("incremental")
        if not user_ids:
            logger.info("â„¹ï¸ ì¦ë¶„ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
            return True
        
        # ë°°ì¹˜ ë¡œê·¸ ìƒì„± (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        batch_id = self.db_service.create_batch_log("incremental", len(user_ids))
        if not batch_id:
            logger.info("â„¹ï¸ DB ë°°ì¹˜ ë¡œê·¸ ë¯¸ì‚¬ìš© - íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©í•˜ì—¬ ê³„ì† ì§„í–‰")
            batch_id = -1  # ì„ì‹œ ID
        
        try:
            all_recommendations = []
            processed_users = 0
            
            for user_id in user_ids:
                try:
                    user_recs = await self._generate_user_recommendations(user_id)
                    all_recommendations.extend(user_recs)
                    processed_users += 1
                    
                except Exception as e:
                    logger.error(f"âŒ ì‚¬ìš©ì {user_id} ì¦ë¶„ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
                    continue
            
            # DB ì €ì¥
            if all_recommendations:
                success = self.db_service.save_recommendations_batch(
                    all_recommendations, batch_id if batch_id > 0 else 0
                )
                
                if success:
                    if batch_id > 0:
                        self.db_service.update_batch_log(
                            batch_id, processed_users, len(all_recommendations), "completed"
                        )
                    logger.info(f"âœ… ì¦ë¶„ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {processed_users}ëª…, {len(all_recommendations)}ê±´ ì¶”ì²œ")
                    
                    # ë°°ì¹˜ ë¡œê·¸ë¥¼ íŒŒì¼ì—ë„ ê¸°ë¡
                    self._write_batch_log_to_file("incremental", processed_users, len(all_recommendations), "completed")
                    
                    return True
                else:
                    logger.error("âŒ ì¦ë¶„ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨")
                    if batch_id > 0:
                        self.db_service.update_batch_log(
                            batch_id, processed_users, 0, "failed", "ì €ì¥ ì‹¤íŒ¨"
                        )
                    self._write_batch_log_to_file("incremental", processed_users, 0, "failed", "ì €ì¥ ì‹¤íŒ¨")
                    return False
            else:
                logger.info("â„¹ï¸ ìƒì„±ëœ ì¶”ì²œì´ ì—†ìŠµë‹ˆë‹¤")
                if batch_id > 0:
                    self.db_service.update_batch_log(
                        batch_id, processed_users, 0, "completed"
                    )
                self._write_batch_log_to_file("incremental", processed_users, 0, "completed", "ì¶”ì²œ ì—†ìŒ")
                return True
                
        except Exception as e:
            logger.error(f"âŒ ì¦ë¶„ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, 0, "failed", str(e)
                )
            self._write_batch_log_to_file("incremental", processed_users, 0, "failed", str(e))
            return False
    
    async def run_mini_batch(self, user_limit: int = 50) -> bool:
        """Mini ë°°ì¹˜ ì²˜ë¦¬ (ì‚¬ìš©ì ìˆ˜ ì œí•œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )"""
        logger.info(f"ğŸ”„ Mini ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (ìµœëŒ€ {user_limit}ëª…, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )")
        
        # ì œí•œëœ ìˆ˜ì˜ ì‚¬ìš©ì ì¡°íšŒ
        all_user_ids = self.db_service.get_users_for_batch_processing("full")
        if not all_user_ids:
            logger.info("â„¹ï¸ ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
            return True
        
        # ì‚¬ìš©ì ìˆ˜ ì œí•œ
        user_ids = all_user_ids[:user_limit]
        logger.info(f"ğŸ“Š ì „ì²´ ì‚¬ìš©ì: {len(all_user_ids)}ëª…, Mini ë°°ì¹˜ ëŒ€ìƒ: {len(user_ids)}ëª…")
        
        # ë°°ì¹˜ ë¡œê·¸ ìƒì„±
        batch_id = self.db_service.create_batch_log("mini", len(user_ids))
        if not batch_id:
            logger.info("â„¹ï¸ DB ë°°ì¹˜ ë¡œê·¸ ë¯¸ì‚¬ìš© - íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©í•˜ì—¬ ê³„ì† ì§„í–‰")
            batch_id = -1
        
        try:
            total_recommendations = 0
            processed_users = 0
            
            # **ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬**: ë” ì‘ì€ ë°°ì¹˜ ë‹¨ìœ„
            batch_size = 10  # mini batchëŠ” ë” ì‘ì€ ë‹¨ìœ„ë¡œ
            
            for i in range(0, len(user_ids), batch_size):
                batch_users = user_ids[i:i + batch_size]
                batch_recommendations = []  # ë°°ì¹˜ë³„ ì„ì‹œ ì €ì¥ì†Œ
                
                logger.info(f"ğŸ“¦ Mini ë°°ì¹˜ {i//batch_size + 1}/{(len(user_ids)-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘: {len(batch_users)}ëª…")
                
                for user_id in batch_users:
                    try:
                        user_recs = await self._generate_user_recommendations(user_id)
                        batch_recommendations.extend(user_recs)
                        processed_users += 1
                        
                        # ì§„í–‰ìƒí™© ë¡œê¹… (mini batchëŠ” ë” ìì£¼)
                        if processed_users % 5 == 0:
                            logger.info(f"ğŸ“Š Mini ë°°ì¹˜ ì§„í–‰: {processed_users}/{len(user_ids)} ì‚¬ìš©ì ì²˜ë¦¬ ì™„ë£Œ")
                            
                    except Exception as e:
                        logger.error(f"âŒ ì‚¬ìš©ì {user_id} ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                        continue
                
                # **ì¦‰ì‹œ DB ì €ì¥ ë° ë©”ëª¨ë¦¬ í•´ì œ**
                if batch_recommendations:
                    success = self.db_service.save_recommendations_batch(
                        batch_recommendations, batch_id if batch_id > 0 else 0
                    )
                    
                    if success:
                        total_recommendations += len(batch_recommendations)
                        logger.info(f"âœ… Mini ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {len(batch_recommendations)}ê±´, ëˆ„ì : {total_recommendations}ê±´")
                    else:
                        logger.error("âŒ Mini ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨ - ì²˜ë¦¬ ì¤‘ë‹¨")
                        break
                
                # **ë©”ëª¨ë¦¬ í•´ì œ**
                del batch_recommendations
                
                # **ê°€ë¹„ì§€ ì»¬ë ‰ì…˜**
                import gc
                gc.collect()
                
                # **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬**
                try:
                    import psutil
                    process = psutil.Process()
                    memory_mb = process.memory_info().rss / 1024 / 1024
                    logger.info(f"ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.1f}MB (Mini ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ)")
                except ImportError:
                    logger.info("ğŸ“ psutil ì—†ìŒ - ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ìƒëµ")
            
            # ìµœì¢… ë°°ì¹˜ ë¡œê·¸ ì—…ë°ì´íŠ¸
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, total_recommendations, "completed"
                )
            
            logger.info(f"âœ… Mini ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {processed_users}ëª…, {total_recommendations}ê±´ ì¶”ì²œ")
            
            # íŒŒì¼ ë¡œê·¸ ê¸°ë¡
            self._write_batch_log_to_file("mini", processed_users, total_recommendations, "completed")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Mini ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            if batch_id > 0:
                self.db_service.update_batch_log(
                    batch_id, processed_users, 0, "failed", str(e)
                )
            self._write_batch_log_to_file("mini", processed_users, 0, "failed", str(e))
            return False
    
    async def _generate_user_recommendations(self, user_id: int) -> List[Dict[str, Any]]:
        """ê°œë³„ ì‚¬ìš©ì ì¶”ì²œ ìƒì„±"""
        recommendations = []
        
        try:
            # ì—¬í–‰ ê¸°ë¡ ì¶”ì²œ (enum ì‚¬ìš©) - ë” ë§ì€ ì¶”ì²œ ìƒì„±
            log_recs, algorithm = self.rec_service.get_recommendations(
                user_id=user_id, 
                rec_type=RecommendationType.RECORD, 
                limit=50  # 10 â†’ 50ìœ¼ë¡œ ì¦ê°€ (ë” ë§ì€ ì¶”ì²œ ìƒì„±)
            )
            
            for rec_item in log_recs:
                recommendations.append({
                    "user_id": user_id,
                    "item_id": rec_item.item_id, 
                    "item_type": "log",
                    "score": rec_item.score
                })
                
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì {user_id} ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            # ë¹ˆ ì¶”ì²œ ë°˜í™˜
            
        return recommendations
    
    def start_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if self.is_running:
            logger.warning("âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        logger.info("ğŸ• ì¶”ì²œ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
        
        # ìŠ¤ì¼€ì¤„ ë“±ë¡
        schedule.every().day.at("02:00").do(self._run_full_batch_sync)      # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
        schedule.every(6).hours.do(self._run_incremental_batch_sync)        # 6ì‹œê°„ë§ˆë‹¤
        
        self.is_running = True
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ë£¨í”„
        while self.is_running:
            try:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
            except KeyboardInterrupt:
                logger.info("ğŸ›‘ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ë‹¨ ìš”ì²­")
                break
            except Exception as e:
                logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {str(e)}")
                time.sleep(60)
        
        logger.info("â¹ï¸ ì¶”ì²œ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ")
    
    def stop_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        self.is_running = False
        schedule.clear()
        logger.info("ğŸ›‘ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ë¨")
    
    def _write_batch_log_to_file(self, batch_type: str, processed_users: int, 
                                total_recommendations: int, status: str, 
                                error_message: str = None):
        """ë°°ì¹˜ ë¡œê·¸ë¥¼ íŒŒì¼ì— ê¸°ë¡ (DB ì‹¤íŒ¨ ì‹œ ë°±ì—…ìš©)"""
        try:
            import os
            from datetime import datetime
            
            log_file = "/app/logs/batch.log"
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            log_entry = f"[{timestamp}] {batch_type.upper()} BATCH - "
            log_entry += f"Status: {status}, Users: {processed_users}, Recommendations: {total_recommendations}"
            
            if error_message:
                log_entry += f", Error: {error_message}"
            
            log_entry += "\n"
            
            # ë¡œê·¸ íŒŒì¼ì— ì¶”ê°€
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(log_entry)
                
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {str(e)}")
    
    def _run_full_batch_sync(self):
        """ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì „ì²´ ë°°ì¹˜ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ìš©)"""
        asyncio.run(self.run_full_batch())
    
    def _run_incremental_batch_sync(self):
        """ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì¦ë¶„ ë°°ì¹˜ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ìš©)"""
        asyncio.run(self.run_incremental_batch())
    
    async def manual_batch_trigger(self, batch_type: str = "incremental", user_limit: int = None) -> Dict[str, Any]:
        """ìˆ˜ë™ ë°°ì¹˜ íŠ¸ë¦¬ê±° (APIìš©)"""
        logger.info(f"ğŸ”§ ìˆ˜ë™ ë°°ì¹˜ íŠ¸ë¦¬ê±°: {batch_type}" + (f" (ìµœëŒ€ {user_limit}ëª…)" if user_limit else ""))
        
        start_time = datetime.now()
        
        if batch_type == "full":
            success = await self.run_full_batch()
        elif batch_type == "mini":
            if user_limit is None:
                user_limit = 50  # ê¸°ë³¸ê°’
            success = await self.run_mini_batch(user_limit)
        else:  # incremental
            success = await self.run_incremental_batch()
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        return {
            "success": success,
            "batch_type": batch_type,
            "user_limit": user_limit if batch_type == "mini" else None,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": duration
        }
    
    def _check_memory_usage(self) -> bool:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ ë° ì œí•œ ì´ˆê³¼ ì‹œ False ë°˜í™˜"""
        try:
            import psutil
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            
            if memory_mb > self.memory_limit_mb:
                logger.error(f"âŒ ë©”ëª¨ë¦¬ ì œí•œ ì´ˆê³¼: {memory_mb:.1f}MB > {self.memory_limit_mb}MB")
                return False
            
            logger.info(f"ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.1f}MB / {self.memory_limit_mb}MB")
            return True
            
        except ImportError:
            logger.warning("âš ï¸ psutil ì—†ìŒ - ë©”ëª¨ë¦¬ ì²´í¬ ìƒëµ")
            return True
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ì²´í¬ ì‹¤íŒ¨: {str(e)}")
            return True 
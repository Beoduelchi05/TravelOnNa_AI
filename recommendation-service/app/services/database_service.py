import pandas as pd
import pymysql
from sqlalchemy import create_engine, text
from sqlalchemy.pool import QueuePool
from typing import List, Dict, Any, Optional
from app.utils.logger import get_logger
from app.utils.config import get_settings

logger = get_logger(__name__)

class DatabaseService:
    """MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.settings = get_settings()
        self.engine = None
        self._connect()
    
    def _connect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •"""
        try:
            # YAML ì„¤ì •ì—ì„œ DB URL ê°€ì ¸ì˜¤ê¸°
            db_url = self.settings.db_url
            
            if not db_url:
                # URLì´ ì—†ìœ¼ë©´ ê°œë³„ ì„¤ì •ìœ¼ë¡œ êµ¬ì„±
                db_url = (
                    f"mysql+pymysql://{self.settings.db_user}:{self.settings.db_password}"
                    f"@{self.settings.db_host}:{self.settings.db_port}/{self.settings.db_name}"
                    f"?charset=utf8mb4"
                )
            
            # SQLAlchemy ì—”ì§„ ìƒì„±
            pool_config = self.settings.get('datasource.pool', {})
            self.engine = create_engine(
                db_url,
                poolclass=QueuePool,
                pool_size=pool_config.get('size', 5),
                max_overflow=pool_config.get('max_overflow', 10),
                pool_pre_ping=pool_config.get('pre_ping', True),
                pool_recycle=pool_config.get('recycle', 3600),
                echo=self.settings.debug
            )
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            with self.engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            
            logger.info("âœ… MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
            logger.info(f"   - í˜¸ìŠ¤íŠ¸: {self.settings.db_host}")
            logger.info(f"   - ë°ì´í„°ë² ì´ìŠ¤: {self.settings.db_name}")
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            raise
    
    def get_user_item_interactions(self) -> pd.DataFrame:
        """ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë°ì´í„° ì¡°íšŒ (user_actions í…Œì´ë¸” ê¸°ë°˜)"""
        query = """
        SELECT 
            ua.user_id,
            ua.target_id as item_id,
            CASE ua.action_type 
                WHEN 'post' THEN 5.0    -- ì‘ì„±ì ìì‹ ì˜ í¬ìŠ¤íŠ¸ (ë†’ì€ ê°€ì¤‘ì¹˜)
                WHEN 'like' THEN 4.0    -- ì¢‹ì•„ìš” 
                WHEN 'comment' THEN 3.0 -- ëŒ“ê¸€
                WHEN 'view' THEN 1.0    -- ì¡°íšŒ
                ELSE 1.0 
            END as rating,
            ua.action_time as created_at,
            ua.action_type,
            ua.target_type
        FROM user_actions ua
        WHERE ua.target_type IN ('log', 'place', 'plan')
          AND ua.action_time >= DATE_SUB(NOW(), INTERVAL 6 MONTH)  -- ìµœê·¼ 6ê°œì›”
          AND (
              -- log íƒ€ì…ì¸ ê²½ìš° ê³µê°œ ì—¬ë¶€ í™•ì¸
              (ua.target_type = 'log' AND EXISTS (
                  SELECT 1 FROM log l 
                  WHERE l.log_id = ua.target_id AND l.is_public = 1
              ))
              OR 
              -- place/plan íƒ€ì…ì¸ ê²½ìš°ëŠ” ë³„ë„ ì²´í¬ (í˜„ì¬ëŠ” ëª¨ë‘ í¬í•¨)
              ua.target_type IN ('place', 'plan')
          )
        ORDER BY ua.action_time DESC
        LIMIT 50000  -- ë” ë§ì€ ë°ì´í„° ë¡œë“œ
        """
        
        try:
            with self.engine.connect() as conn:
                df = pd.read_sql(query, conn)
            logger.info(f"âœ… user_actions ê¸°ë°˜ ìƒí˜¸ì‘ìš© ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(df)}ê±´ (ê³µê°œ ë¡œê·¸ë§Œ)")
            logger.info(f"   - ì•¡ì…˜ íƒ€ì…ë³„ ë¶„í¬:")
            if len(df) > 0:
                action_counts = df['action_type'].value_counts()
                for action, count in action_counts.items():
                    logger.info(f"     * {action}: {count}ê±´")
                
                # íƒ€ê²Ÿ íƒ€ì…ë³„ ë¶„í¬ë„ í™•ì¸
                target_counts = df['target_type'].value_counts()
                logger.info(f"   - íƒ€ê²Ÿ íƒ€ì…ë³„ ë¶„í¬:")
                for target, count in target_counts.items():
                    logger.info(f"     * {target}: {count}ê±´")
            return df
        except Exception as e:
            logger.error(f"âŒ user_actions ìƒí˜¸ì‘ìš© ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
            return self._get_legacy_user_item_interactions()
    
    def _get_legacy_user_item_interactions(self) -> pd.DataFrame:
        """ê¸°ì¡´ ë°©ì‹ì˜ ìƒí˜¸ì‘ìš© ë°ì´í„° ì¡°íšŒ (fallbackìš©)"""
        query = """
        SELECT 
            ua.user_id,
            ua.log_id as item_id,
            ua.rating,
            ua.interaction_date as created_at
        FROM (
            -- ì¢‹ì•„ìš” ë°ì´í„°
            SELECT 
                lk.user_id,
                lk.log_id,
                5.0 as rating,
                'like' as action_type,
                NOW() as interaction_date
            FROM likes lk
            JOIN log l ON lk.log_id = l.log_id
            WHERE l.is_public = 1
            
            UNION ALL
            
            -- ëŒ“ê¸€ ë°ì´í„°  
            SELECT 
                lc.user_id,
                lc.log_id,
                3.0 as rating,
                'comment' as action_type,
                lc.created_at as interaction_date
            FROM log_comment lc
            JOIN log l ON lc.log_id = l.log_id
            WHERE l.is_public = 1
              AND lc.created_at IS NOT NULL
            
            UNION ALL
            
            -- ì‘ì„±ì ìì‹ ì˜ ê¸°ë¡ (ë†’ì€ ê°€ì¤‘ì¹˜)
            SELECT 
                l.user_id,
                l.log_id,
                4.0 as rating,
                'own' as action_type,
                l.created_at as interaction_date
            FROM log l
            WHERE l.is_public = 1
              AND l.created_at IS NOT NULL
        ) ua
        ORDER BY ua.interaction_date DESC
        LIMIT 10000
        """
        
        try:
            with self.engine.connect() as conn:
                df = pd.read_sql(query, conn)
            logger.info(f"âœ… ê¸°ì¡´ ë°©ì‹ ìƒí˜¸ì‘ìš© ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(df)}ê±´")
            return df
        except Exception as e:
            logger.error(f"âŒ ê¸°ì¡´ ë°©ì‹ ìƒí˜¸ì‘ìš© ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return pd.DataFrame()
    
    def get_item_metadata(self, item_ids: List[int]) -> Dict[str, Dict[str, Any]]:
        """ì•„ì´í…œ(ì—¬í–‰ ê¸°ë¡) ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        if not item_ids:
            return {}
            
        # ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •: named parameterë¡œ ë³€ê²½í•˜ê¸°ë³´ë‹¤ëŠ” í™•ì‹¤í•œ tuple ì‚¬ìš©
        placeholders = ','.join(['%s'] * len(item_ids))
        query = f"""
        SELECT 
            l.log_id,
            l.comment as description,
            l.created_at,
            u.name as author_name,
            p.nickname as author_nickname,
            COUNT(DISTINCT lk.user_id) as like_count,
            COUNT(DISTINCT lc.loco_id) as comment_count
        FROM log l
        JOIN user u ON l.user_id = u.user_id
        LEFT JOIN profile p ON u.user_id = p.user_id
        LEFT JOIN likes lk ON l.log_id = lk.log_id  
        LEFT JOIN log_comment lc ON l.log_id = lc.log_id
        WHERE l.log_id IN ({placeholders})
          AND l.is_public = 1
        GROUP BY l.log_id, l.comment, l.created_at, u.name, p.nickname
        """
        
        try:
            with self.engine.connect() as conn:
                # pandas read_sqlì€ tupleì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ ë³€í™˜
                df = pd.read_sql(query, conn, params=tuple(int(item_id) for item_id in item_ids))
            
            metadata = {}
            for _, row in df.iterrows():
                metadata[str(row['log_id'])] = {
                    "title": f"ì—¬í–‰ ê¸°ë¡ {row['log_id']}",  # ê¸°ë³¸ ì œëª©
                    "description": row['description'][:200] if row['description'] else "",
                    "image_url": None,  # ì‹¤ì œ í…Œì´ë¸”ì— ì—†ìŒ
                    "category": "ì—¬í–‰",  # ê¸°ë³¸ê°’
                    "location": "ë¯¸ì§€ì •",  # ê¸°ë³¸ê°’
                    "author_name": row['author_name'],
                    "author_nickname": row['author_nickname'],
                    "created_at": row['created_at'].isoformat() if row['created_at'] else None,
                    "popularity_rank": int(row['like_count']) + int(row['comment_count']),
                    "extra": {
                        "like_count": int(row['like_count']),
                        "comment_count": int(row['comment_count'])
                    }
                }
            
            logger.info(f"âœ… ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(metadata)}ê°œ")
            return metadata
            
        except Exception as e:
            logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def get_popular_items(self, rec_type: str, limit: int) -> List[int]:
        """ì¸ê¸° ì•„ì´í…œ ì¡°íšŒ (user_actions ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •)"""
        if rec_type == "record":
            # ë¨¼ì € user_actions ê¸°ë°˜ìœ¼ë¡œ ì¸ê¸°ë„ ê³„ì‚° ì‹œë„ (ê³µê°œ ë¡œê·¸ë§Œ, ì¡°ê±´ ì™„í™”)
            query = """
            SELECT 
                ua.target_id as log_id,
                COUNT(*) as popularity_score
            FROM user_actions ua
            JOIN log l ON ua.target_id = l.log_id
            WHERE ua.target_type = 'log'
              AND ua.action_type IN ('like', 'comment', 'view', 'post')
              AND ua.action_time >= DATE_SUB(NOW(), INTERVAL 12 MONTH)  -- 12ê°œì›”ë¡œ í™•ì¥
              AND l.is_public = 1  -- ê³µê°œ ë¡œê·¸ë§Œ
            GROUP BY ua.target_id
            ORDER BY popularity_score DESC, ua.action_time DESC
            LIMIT %s
            """
        elif rec_type == "place":
            query = """
            SELECT 
                p.place_id as log_id,
                COUNT(*) as popularity_score
            FROM place p
            JOIN plan pl ON p.plan_id = pl.plan_id
            WHERE pl.is_public = 1
              AND p.created_at >= DATE_SUB(NOW(), INTERVAL 6 MONTH)  -- 6ê°œì›”ë¡œ í™•ì¥
            GROUP BY p.place_id
            ORDER BY popularity_score DESC
            LIMIT %s
            """
        else:
            # ê¸°ë³¸ê°’: ìµœì‹  ê³µê°œ ê¸°ë¡
            query = """
            SELECT log_id
            FROM log
            WHERE is_public = 1
            ORDER BY created_at DESC
            LIMIT %s
            """
        
        try:
            with self.engine.connect() as conn:
                df = pd.read_sql(query, conn, params=(limit,))
            
            item_ids = df['log_id'].tolist()
            
            # user_actions ê¸°ë°˜ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ ìµœì‹  ê³µê°œ ë¡œê·¸ë¡œ fallback
            if len(item_ids) < limit and rec_type == "record":
                logger.warning(f"âš ï¸ user_actions ê¸°ë°˜ ì¸ê¸° ì•„ì´í…œ ë¶€ì¡± ({len(item_ids)}/{limit}), ìµœì‹  ê³µê°œ ë¡œê·¸ë¡œ ë³´ì™„")
                fallback_query = """
                SELECT log_id
                FROM log
                WHERE is_public = 1
                  AND log_id NOT IN ({})
                ORDER BY created_at DESC
                LIMIT %s
                """.format(','.join(map(str, item_ids)) if item_ids else '0')
                
                remaining_limit = limit - len(item_ids)
                df_fallback = pd.read_sql(fallback_query, conn, params=(remaining_limit,))
                fallback_ids = df_fallback['log_id'].tolist()
                item_ids.extend(fallback_ids)
            
            logger.info(f"âœ… ì¸ê¸° ì•„ì´í…œ ì¡°íšŒ ì™„ë£Œ: {len(item_ids)}ê°œ (ìš”ì²­: {limit}ê°œ)")
            return item_ids
            
        except Exception as e:
            logger.error(f"âŒ ì¸ê¸° ì•„ì´í…œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            # ìµœì¢… í´ë°±: ìµœì‹  ê³µê°œ ë¡œê·¸ ë°˜í™˜
            try:
                with self.engine.connect() as conn:
                    fallback_query = """
                    SELECT log_id
                    FROM log
                    WHERE is_public = 1
                    ORDER BY created_at DESC
                    LIMIT %s
                    """
                    df = pd.read_sql(fallback_query, conn, params=(limit,))
                    return df['log_id'].tolist()
            except:
                logger.error("âŒ ìµœì¢… í´ë°±ë„ ì‹¤íŒ¨, ìˆœì°¨ì  ID ë°˜í™˜")
                return list(range(1, limit + 1))
    
    def get_user_preferences(self, user_id: int) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ"""
        query = """
        SELECT 
            u.user_id,
            p.nickname,
            -- ì„ í˜¸ ì¹´í…Œê³ ë¦¬ (ê°€ì¥ ë§ì´ ì¢‹ì•„ìš”í•œ ì¹´í…Œê³ ë¦¬)
            (SELECT l.category 
             FROM like_log lk 
             JOIN log l ON lk.log_id = l.log_id 
             WHERE lk.user_id = u.user_id 
             GROUP BY l.category 
             ORDER BY COUNT(*) DESC 
             LIMIT 1) as preferred_category,
            -- ì„ í˜¸ ì§€ì—­
            (SELECT l.location 
             FROM like_log lk 
             JOIN log l ON lk.log_id = l.log_id 
             WHERE lk.user_id = u.user_id 
             GROUP BY l.location 
             ORDER BY COUNT(*) DESC 
             LIMIT 1) as preferred_location
        FROM user u
        LEFT JOIN profile p ON u.user_id = p.user_id
        WHERE u.user_id = %(user_id)s
        """
        
        try:
            with self.engine.connect() as conn:
                df = pd.read_sql(query, conn, params={'user_id': int(user_id)})
            
            if len(df) > 0:
                row = df.iloc[0]
                return {
                    "user_id": int(row['user_id']),
                    "nickname": row['nickname'],
                    "preferred_category": row['preferred_category'],
                    "preferred_location": row['preferred_location']
                }
            else:
                return {"user_id": user_id}
                
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"user_id": user_id}
    
    def close(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        if self.engine:
            self.engine.dispose()
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ")
    
    def save_recommendations_batch(self, recommendations: List[Dict[str, Any]], batch_id: int) -> bool:
        """ì¶”ì²œ ê²°ê³¼ë¥¼ recommendations í…Œì´ë¸”ì— ë°°ì¹˜ ì €ì¥"""
        if not recommendations:
            return True
            
        try:
            # ê¸°ì¡´ ì¶”ì²œ ê²°ê³¼ ì‚­ì œ (ì‚¬ìš©ìë³„)
            user_ids = list(set([rec['user_id'] for rec in recommendations]))
            
            with self.engine.begin() as conn:
                # 1. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ - named parameter ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
                if user_ids:
                    # í•˜ë‚˜ì”© ì‚­ì œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½ (ë” ì•ˆì „)
                    delete_query = text("DELETE FROM recommendations WHERE user_id = :user_id")
                    for user_id in user_ids:
                        conn.execute(delete_query, {'user_id': int(user_id)})
                    logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ ì¶”ì²œ ë°ì´í„° ì‚­ì œ ì™„ë£Œ: {len(user_ids)}ëª…")
                
                # 2. ìƒˆ ë°ì´í„° ì‚½ì… - í•˜ë‚˜ì”© ì‚½ì…í•˜ëŠ” ì•ˆì „í•œ ë°©ë²•
                insert_query = text("""
                    INSERT INTO recommendations 
                    (user_id, item_id, item_type, score, created_at)
                    VALUES (:user_id, :item_id, :item_type, :score, NOW())
                """)
                
                inserted_count = 0
                for rec in recommendations:
                    try:
                        conn.execute(insert_query, {
                            'user_id': int(rec['user_id']),
                            'item_id': int(rec['item_id']), 
                            'item_type': str(rec['item_type']),
                            'score': float(rec['score'])
                        })
                        inserted_count += 1
                    except Exception as insert_error:
                        logger.warning(f"âš ï¸ ê°œë³„ ì¶”ì²œ ì‚½ì… ì‹¤íŒ¨: user_id={rec.get('user_id')}, item_id={rec.get('item_id')}, error={str(insert_error)}")
                        continue
            
            logger.info(f"âœ… ì¶”ì²œ ê²°ê³¼ ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {inserted_count}/{len(recommendations)}ê±´")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ì²œ ê²°ê³¼ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            import traceback
            logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def create_batch_log(self, batch_type: str, total_users: int) -> Optional[int]:
        """ë°°ì¹˜ ì²˜ë¦¬ ë¡œê·¸ ìƒì„± (íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©)"""
        try:
            # DB ëŒ€ì‹  íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©
            import os
            from datetime import datetime
            
            log_file = "/app/logs/batch.log"
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            log_entry = f"[{timestamp}] {batch_type.upper()} BATCH STARTED - "
            log_entry += f"Total Users: {total_users}, Status: started\n"
            
            # ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(log_entry)
            
            logger.info(f"âœ… ë°°ì¹˜ ë¡œê·¸ ìƒì„± (íŒŒì¼): type={batch_type}, users={total_users}")
            
            # ê°€ì§œ batch_id ë°˜í™˜ (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
            batch_id = int(datetime.now().timestamp())
            return batch_id
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ë¡œê·¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None
    
    def update_batch_log(self, batch_id: int, processed_users: int, 
                        total_recommendations: int, status: str, 
                        error_message: Optional[str] = None) -> bool:
        """ë°°ì¹˜ ì²˜ë¦¬ ë¡œê·¸ ì—…ë°ì´íŠ¸ (íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©)"""
        try:
            # DB ëŒ€ì‹  íŒŒì¼ ë¡œê·¸ë§Œ ì‚¬ìš©
            import os
            from datetime import datetime
            
            log_file = "/app/logs/batch.log"
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # ë°°ì¹˜ íƒ€ì… ì¶”ì • (batch_idë¡œëŠ” ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ê°„ë‹¨íˆ BATCHë¡œ í‘œì‹œ)
            log_entry = f"[{timestamp}] BATCH UPDATE - "
            log_entry += f"Status: {status}, Users: {processed_users}, Recommendations: {total_recommendations}"
            
            if error_message:
                log_entry += f", Error: {error_message}"
            
            log_entry += "\n"
            
            # ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(log_entry)
            
            logger.info(f"âœ… ë°°ì¹˜ ë¡œê·¸ ì—…ë°ì´íŠ¸ (íŒŒì¼): status={status}, users={processed_users}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def get_users_for_batch_processing(self, batch_type: str = "full") -> List[int]:
        """ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ì ì¡°íšŒ"""
        if batch_type == "incremental":
            # ìµœê·¼ í™œë™í•œ ì‚¬ìš©ìë§Œ (24ì‹œê°„ìœ¼ë¡œ í™•ì¥)
            query = """
            SELECT DISTINCT user_id 
            FROM user_actions 
            WHERE action_time >= DATE_SUB(NOW(), INTERVAL 24 HOUR)
            ORDER BY user_id
            LIMIT 1000
            """
        else:
            # ì „ì²´ ì‚¬ìš©ì (ëª¨ë“  user_actions ë°ì´í„°, ë‚ ì§œ ì œí•œ ì—†ìŒ)
            query = """
            SELECT DISTINCT user_id 
            FROM user_actions 
            ORDER BY user_id
            """
        
        try:
            # ë©”ì¸ ì¿¼ë¦¬ ì‹¤í–‰
            with self.engine.connect() as conn:
                df = pd.read_sql(query, conn)
            
            user_ids = df['user_id'].tolist()
            logger.info(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ì ì¡°íšŒ: {len(user_ids)}ëª… ({batch_type})")
            
            # ë””ë²„ê¹…: ì‹¤ì œ user_actions ë°ì´í„° í™•ì¸ (ìƒˆë¡œìš´ ì»¤ë„¥ì…˜ ì‚¬ìš©)
            try:
                with self.engine.connect() as conn:
                    total_query = "SELECT COUNT(*) as total, COUNT(DISTINCT user_id) as unique_users FROM user_actions"
                    total_df = pd.read_sql(total_query, conn)
                    logger.info(f"ğŸ“Š ì „ì²´ user_actions: {total_df.iloc[0]['total']}ê±´, ê³ ìœ  ì‚¬ìš©ì: {total_df.iloc[0]['unique_users']}ëª…")
            except Exception as e:
                logger.warning(f"âš ï¸ ì „ì²´ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨ (ë¬´ì‹œí•¨): {str(e)}")
            
            # ë‚ ì§œë³„ ë¶„í¬ë„ í™•ì¸ (ìƒˆë¡œìš´ ì»¤ë„¥ì…˜ ì‚¬ìš©)
            if batch_type == "full":
                try:
                    with self.engine.connect() as conn:
                        date_query = """
                        SELECT 
                            DATE(action_time) as action_date,
                            COUNT(*) as daily_actions,
                            COUNT(DISTINCT user_id) as daily_users
                        FROM user_actions 
                        GROUP BY DATE(action_time)
                        ORDER BY action_date DESC
                        LIMIT 7
                        """
                        date_df = pd.read_sql(date_query, conn)
                        logger.info("ğŸ“… ìµœê·¼ 7ì¼ê°„ user_actions ë¶„í¬:")
                        for _, row in date_df.iterrows():
                            logger.info(f"   - {row['action_date']}: {row['daily_actions']}ê±´, {row['daily_users']}ëª…")
                except Exception as e:
                    logger.warning(f"âš ï¸ ë‚ ì§œë³„ ë¶„í¬ ì¡°íšŒ ì‹¤íŒ¨ (ë¬´ì‹œí•¨): {str(e)}")
            
            return user_ids
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ìƒ ì‚¬ìš©ì ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIHubì—¬í–‰ê°ì •ë³´ âž¡ï¸ user í…Œì´ë¸” ë§¤í•‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User ID Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plan í…Œì´ë¸” ì»¬ëŸ¼ í™•ì¸: ['plan_id', 'user_id', 'start_date', 'end_date', 'title', 'transport_info', 'location', 'group_id', 'is_public', 'total_cost']\n",
      "   plan_id  user_id start_date   end_date title transport_info location  \\\n",
      "0     7000    40005 2023-04-29 2023-05-03   E02                      ì¸ì²œ   \n",
      "1     7001    40043 2023-04-28 2023-05-01   E03                      ê²½ê¸°   \n",
      "2     7002    40191 2023-04-28 2023-05-01   G06                      ê²½ê¸°   \n",
      "3     7003    40316 2023-05-27 2023-05-30   E01                      ì„œìš¸   \n",
      "4     7004    40668 2023-05-20 2023-05-21   E02                      ì¸ì²œ   \n",
      "\n",
      "  group_id  is_public total_cost  \n",
      "0                   1             \n",
      "1                   1             \n",
      "2                   1             \n",
      "3                   1             \n",
      "4                   1             \n",
      "ì €ìž¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸\n",
    "# ì´ ì½”ë“œëŠ” ì›ë³¸ ë°ì´í„°ì…‹ì„ ìš°ë¦¬ ì‹œìŠ¤í…œì— ë§žê²Œ ë³€í™˜í•˜ëŠ” ìž‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "# 1. ì›ë³¸ ë°ì´í„° íŒŒì¼ ë¡œë“œ (ì—¬í–‰ê° Master, ì—¬í–‰ ë°ì´í„°)\n",
    "# 2. User í…Œì´ë¸” ìƒì„± - TRAVELER_IDì—ì„œ ë¬¸ìž ì œê±° í›„ ìˆ«ìžë§Œ ì¶”ì¶œí•˜ì—¬ user_id ìƒì„±\n",
    "# 3. Plan í…Œì´ë¸” ìƒì„± - Masterì™€ Travel ë°ì´í„° ì¡°ì¸ í›„ í•„ìš”í•œ í•„ë“œ ì¶”ì¶œ\n",
    "# 4. ìƒì„±ëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ìž¥\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ì½ê¸°\n",
    "df_master = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/west/tn_traveller_master_ì—¬í–‰ê° Master_G.csv', encoding='utf-8')\n",
    "df_travel = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/west/tn_travel_ì—¬í–‰_G.csv', encoding='utf-8')\n",
    "\n",
    "# User í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "temp_id = df_master['TRAVELER_ID'].str.replace(r'[a-zA-Z]', '', regex=True).astype(int)\n",
    "user_df = pd.DataFrame({\n",
    "    'user_id': 40000 + temp_id,\n",
    "    'email': df_master['TRAVELER_ID'].astype(str) + '@gmail.com',\n",
    "    'name': df_master['TRAVELER_ID']\n",
    "})\n",
    "\n",
    "# Plan í…Œì´ë¸” ìƒì„±\n",
    "df_plan = pd.merge(df_travel, df_master[['TRAVELER_ID', 'TRAVEL_STATUS_DESTINATION']], \n",
    "                   on='TRAVELER_ID', how='left')\n",
    "\n",
    "traveler_ids = df_plan['TRAVELER_ID'].str.replace(r'[a-zA-Z]', '', regex=True).astype(int)\n",
    "\n",
    "plan_df = pd.DataFrame({\n",
    "    'plan_id': range(7000, 7000 + len(df_plan)),\n",
    "    'user_id': 40000 + traveler_ids,\n",
    "    'start_date': pd.to_datetime(df_plan['TRAVEL_START_YMD']),\n",
    "    'end_date': pd.to_datetime(df_plan['TRAVEL_END_YMD']),\n",
    "    'title': df_plan['TRAVEL_NM'],\n",
    "    'transport_info': '',          # ë¹ˆê°’\n",
    "    'location': df_plan['TRAVEL_STATUS_DESTINATION'],\n",
    "    'group_id': '',                # ë¹ˆê°’\n",
    "    'is_public': 1,                # 1ë¡œ ê³ ì •\n",
    "    'total_cost': ''               # ë¹ˆê°’\n",
    "})\n",
    "\n",
    "print(\"\\nPlan í…Œì´ë¸” ì»¬ëŸ¼ í™•ì¸:\", plan_df.columns.tolist())\n",
    "print(plan_df.head())\n",
    "\n",
    "# ì €ìž¥\n",
    "user_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/user.csv', index=False)\n",
    "plan_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/plan.csv', index=False)\n",
    "print(\"ì €ìž¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Profile Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   profile_id  user_id nickname profile_image introduction  \\\n",
      "0           1    42178  g002178          None         None   \n",
      "1           2    44485  g004485          None         None   \n",
      "2           3    45167  g005167          None         None   \n",
      "3           4    42887  g002887          None         None   \n",
      "4           5    44189  g004189          None         None   \n",
      "\n",
      "            created_at updated_at  \n",
      "0  2025-05-26 22:33:49       None  \n",
      "1  2025-05-26 22:33:49       None  \n",
      "2  2025-05-26 22:33:49       None  \n",
      "3  2025-05-26 22:33:49       None  \n",
      "4  2025-05-26 22:33:49       None  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‚¬ìš©ìž í”„ë¡œí•„ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ìž…ë‹ˆë‹¤.\n",
    "\n",
    "1. ê¸°ì¡´ì— ìƒì„±í•œ user.csv íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "2. ê° ì‚¬ìš©ìžì— ëŒ€í•œ í”„ë¡œí•„ ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:\n",
    "   - profile_id: ìˆœì°¨ì ìœ¼ë¡œ í• ë‹¹ (ì‹¤ì œ DBì—ì„œëŠ” auto_increment)\n",
    "   - user_id: user.csvì˜ user_idì™€ ë§¤í•‘\n",
    "   - nickname: userì˜ name ê°’ ì‚¬ìš©\n",
    "   - ê¸°íƒ€ í•„ë“œ: ì´ˆê¸°ê°’ ì„¤ì •\n",
    "3. ìƒì„±ëœ í”„ë¡œí•„ ë°ì´í„°ë¥¼ profile.csv íŒŒì¼ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë°ì´í„°ëŠ” ì‚¬ìš©ìž í”„ë¡œí•„ ê´€ë¦¬ ë° ì¶”ì²œ ì‹œìŠ¤í…œì˜ user_preferences í…Œì´ë¸” êµ¬ì„±ì— í™œìš©ë©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ê¸°ì¡´ì— ìƒì„±í•œ user_migrated.csv íŒŒì¼ ì½ê¸°\n",
    "user_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/user.csv', encoding='utf-8')\n",
    "profile_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/profile.csv', encoding='utf-8')\n",
    "\n",
    "# í˜„ìž¬ ì‹œê°ì„ created_at ê°’ìœ¼ë¡œ ì‚¬ìš© (ë¬¸ìžì—´ í˜•íƒœë¡œ ë³€í™˜)\n",
    "current_ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# profile í…Œì´ë¸”ì— ë§žê²Œ ë§¤í•‘: \n",
    "# profile_id: auto_increment íš¨ê³¼ë¥¼ ìœ„í•´ 1ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ í• ë‹¹ (ì‹¤ì œ DBì—ì„œëŠ” auto_increment ë˜ë¯€ë¡œ CSVì—ì„œ ì°¸ê³ ìš©)\n",
    "# user_id: user_migrated.csvì˜ user_id ì‚¬ìš©\n",
    "# nickname: userì˜ name ì»¬ëŸ¼ ì‚¬ìš©\n",
    "# profile_image, introduction, updated_at: null ì²˜ë¦¬ (ì—¬ê¸°ì„œëŠ” ë¹ˆ ë¬¸ìžì—´ë¡œ í‘œì‹œ)\n",
    "profile_df = pd.DataFrame()\n",
    "profile_df['profile_id'] = range(1, 1 + len(user_df))\n",
    "profile_df['user_id'] = user_df['user_id']\n",
    "profile_df['nickname'] = user_df['name']\n",
    "profile_df['profile_image'] = None   # ë˜ëŠ” ë¹ˆ ë¬¸ìžì—´: ''\n",
    "profile_df['introduction'] = None      # ë˜ëŠ” ë¹ˆ ë¬¸ìžì—´: ''\n",
    "profile_df['created_at'] = current_ts\n",
    "profile_df['updated_at'] = None        # ë˜ëŠ” ë¹ˆ ë¬¸ìžì—´: ''\n",
    "\n",
    "# ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "print(profile_df.head())\n",
    "\n",
    "# profile.csv íŒŒì¼ë¡œ ì €ìž¥\n",
    "profile_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/profile.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== plan.csv ì»¬ëŸ¼ ===\n",
      "['plan_id', 'user_id', 'start_date', 'end_date', 'title', 'transport_info', 'location', 'group_id', 'is_public', 'total_cost']\n",
      "=== ë°©ë¬¸ì§€ì •ë³´ ì»¬ëŸ¼ ===\n",
      "['VISIT_AREA_ID', 'TRAVEL_ID', 'VISIT_ORDER', 'VISIT_AREA_NM', 'VISIT_START_YMD', 'VISIT_END_YMD', 'ROAD_NM_ADDR', 'LOTNO_ADDR', 'X_COORD', 'Y_COORD', 'ROAD_NM_CD', 'LOTNO_CD', 'POI_ID', 'POI_NM', 'RESIDENCE_TIME_MIN', 'VISIT_AREA_TYPE_CD', 'REVISIT_YN', 'VISIT_CHC_REASON_CD', 'LODGING_TYPE_CD', 'DGSTFN', 'REVISIT_INTENTION', 'RCMDTN_INTENTION', 'SGG_CD']\n",
      "=== ë³‘í•© ê²°ê³¼ ìƒ˜í”Œ ===\n",
      "   TRAVEL_ID  user_id  plan_id\n",
      "0  e_e000005    40005     7000\n",
      "1  e_e000005    40005     7036\n",
      "2  e_e000005    40005     7000\n",
      "3  e_e000005    40005     7036\n",
      "4  e_e000005    40005     7000\n",
      "=== place.csv íŒŒì¼ë¡œ ì €ìž¥ ì™„ë£Œ ===\n",
      "   place_id  plan_id                      place  is_public  visit_date  \\\n",
      "0         1     7000                 ìœ ë“±ë¡œ655ë²ˆê¸¸27          1  2023-04-29   \n",
      "1         2     7036                 ìœ ë“±ë¡œ655ë²ˆê¸¸27          1  2023-04-29   \n",
      "2         3     7000         ëŒ€ì „ ëŒ€ë•êµ¬ ë•ì•”ë¡œ222ë²ˆê¸¸ 34          1  2023-04-29   \n",
      "3         4     7036         ëŒ€ì „ ëŒ€ë•êµ¬ ë•ì•”ë¡œ222ë²ˆê¸¸ 34          1  2023-04-29   \n",
      "4         5     7000  ì¶©ë¶ ì²­ì£¼ì‹œ í¥ë•êµ¬ ì˜¥ì‚°ë©´ ê²½ë¶€ê³ ì†ë„ë¡œ 318          1  2023-04-29   \n",
      "5         6     7036  ì¶©ë¶ ì²­ì£¼ì‹œ í¥ë•êµ¬ ì˜¥ì‚°ë©´ ê²½ë¶€ê³ ì†ë„ë¡œ 318          1  2023-04-29   \n",
      "6         7     7000              ì¸ì²œ ì¤‘êµ¬ ì›”ë¯¸ë¬¸í™”ë¡œ 9          1  2023-04-29   \n",
      "7         8     7036              ì¸ì²œ ì¤‘êµ¬ ì›”ë¯¸ë¬¸í™”ë¡œ 9          1  2023-04-29   \n",
      "8         9     7000            ì¸ì²œ ì¤‘êµ¬ ë¶ì„±ë™1ê°€ ì‚° 1          1  2023-04-29   \n",
      "9        10     7036            ì¸ì²œ ì¤‘êµ¬ ë¶ì„±ë™1ê°€ ì‚° 1          1  2023-04-29   \n",
      "\n",
      "  place_cost  memo        lat         lon                   p_name  p_order  \n",
      "0       None  None        NaN         NaN                        ì§‘        1  \n",
      "1       None  None        NaN         NaN                        ì§‘        1  \n",
      "2       None  None  36.439598  127.425684  ì•„ì£¼ ë§¤ìš´ ê³µì£¼ ì¹¼êµ­ìˆ˜ ì£¼ê¾¸ë¯¸êµ¬ì´ ì‹ íƒ„ì§„ì         2  \n",
      "3       None  None  36.439598  127.425684  ì•„ì£¼ ë§¤ìš´ ê³µì£¼ ì¹¼êµ­ìˆ˜ ì£¼ê¾¸ë¯¸êµ¬ì´ ì‹ íƒ„ì§„ì         2  \n",
      "4       None  None  36.716110  127.349358             ì²­ì£¼ íœ´ê²Œì†Œ ì„œìš¸ ë°©í–¥        3  \n",
      "5       None  None  36.716110  127.349358             ì²­ì£¼ íœ´ê²Œì†Œ ì„œìš¸ ë°©í–¥        3  \n",
      "6       None  None  37.476967  126.599158                    ê°¤ëŸ­ì‹œí˜¸í…”        4  \n",
      "7       None  None  37.476967  126.599158                    ê°¤ëŸ­ì‹œí˜¸í…”        4  \n",
      "8       None  None  37.471738  126.599231                      ì›”ë¯¸ë„        6  \n",
      "9       None  None  37.471738  126.599231                      ì›”ë¯¸ë„        6  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Aihubì—ì„œ ì œê³µí•˜ëŠ” 'tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_E.csv' ë°ì´í„°ë¥¼\n",
    "ìš°ë¦¬ ì‹œìŠ¤í…œì˜ plan.csvì™€ ì—°ê²°í•˜ì—¬, ëª¨ë“  TRAVEL_IDì— ëŒ€í•œ place í…Œì´ë¸” í˜•ì‹ CSVë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "íŠ¹ížˆ TRAVEL_ID('e_e000004') â†’ user_id(4)ì²˜ëŸ¼,\n",
    "TRAVEL_IDì—ì„œ 'e_e000' ì ‘ë‘ì‚¬ë¥¼ ì œê±°í•œ ë’¤ intë¡œ ë³€í™˜í•˜ì—¬ user_idë¥¼ êµ¬í•œ í›„,\n",
    "í•´ë‹¹ user_idë¥¼ plan.csvì™€ ë§¤í•‘(plan_id)í•˜ëŠ” ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ìŒ ìž‘ì—…ì„ í•©ë‹ˆë‹¤:\n",
    "1) plan.csv ë¡œë“œ (user_id, plan_id ì •ë³´ë¥¼ ê°–ê³  ìžˆì–´ì•¼ í•¨)\n",
    "2) ë°©ë¬¸ì§€ì •ë³´ íŒŒì¼ ë¡œë“œ (tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_E.csv)\n",
    "3) TRAVEL_IDì—ì„œ ì ‘ë‘ì‚¬ ì œê±° í›„ int ë³€í™˜ â†’ user_id\n",
    "4) plan.csvì™€ user_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ mergeí•˜ì—¬ plan_id í• ë‹¹\n",
    "5) place í…Œì´ë¸” ì»¬ëŸ¼(place, is_public, visit_date, lat, lon, p_name, p_order ë“±) ìƒì„±\n",
    "6) ê²°ê³¼ë¥¼ place_migrated.csvì— ì €ìž¥\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# 1) plan.csv ë¡œë“œ\n",
    "df_plan = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/plan.csv', encoding='utf-8')\n",
    "print(\"=== plan.csv ì»¬ëŸ¼ ===\")\n",
    "print(df_plan.columns.tolist())\n",
    "\n",
    "# 2) ë°©ë¬¸ì§€ì •ë³´ íŒŒì¼ ë¡œë“œ\n",
    "df_v = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/west/tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_G.csv', encoding='utf-8')\n",
    "print(\"=== ë°©ë¬¸ì§€ì •ë³´ ì»¬ëŸ¼ ===\")\n",
    "print(df_v.columns.tolist())\n",
    "\n",
    "# 3) TRAVEL_ID -> user_id ë³€í™˜(40000 + ìˆ«ìž)\n",
    "def convert_travel_id_to_user_id(travel_id: str) -> int:\n",
    "    # ì˜ˆ: 'e_e000004' â†’ 40004, 'f_f000007' â†’ 40007\n",
    "    cleaned_id = re.sub(r'^[a-z]_[a-z]', '', travel_id)\n",
    "    return 40000 + int(cleaned_id)\n",
    "\n",
    "df_v['user_id'] = df_v['TRAVEL_ID'].apply(convert_travel_id_to_user_id)\n",
    "\n",
    "# 4) plan.csvì™€ user_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ merge â†’ plan_id í• ë‹¹\n",
    "df_plan_map = df_plan[['user_id', 'plan_id']].drop_duplicates()\n",
    "df_merged = pd.merge(df_v, df_plan_map, on='user_id', how='inner')\n",
    "\n",
    "print(\"=== ë³‘í•© ê²°ê³¼ ìƒ˜í”Œ ===\")\n",
    "print(df_merged[['TRAVEL_ID','user_id','plan_id']].head())\n",
    "\n",
    "# 5) place í…Œì´ë¸” ìƒì„± (í•„ìš” ì»¬ëŸ¼ë§Œ, ìˆœì„œ ë§žì¶¤)\n",
    "place_df = pd.DataFrame()\n",
    "place_df['place_id'] = range(1, 1 + len(df_merged))\n",
    "place_df['plan_id'] = df_merged['plan_id']\n",
    "place_df['place'] = np.where(\n",
    "    df_merged['ROAD_NM_ADDR'].notnull() & (df_merged['ROAD_NM_ADDR'] != ''),\n",
    "    df_merged['ROAD_NM_ADDR'],\n",
    "    df_merged['LOTNO_ADDR']\n",
    ")\n",
    "place_df['is_public'] = 1\n",
    "place_df['visit_date'] = df_merged['VISIT_START_YMD']\n",
    "place_df['place_cost'] = None\n",
    "place_df['memo'] = None\n",
    "place_df['lat'] = df_merged['Y_COORD']\n",
    "place_df['lon'] = df_merged['X_COORD']\n",
    "place_df['p_name'] = df_merged['VISIT_AREA_NM']\n",
    "place_df['p_order'] = df_merged['VISIT_ORDER'].astype(int)\n",
    "\n",
    "# 6) ê²°ê³¼ ì €ìž¥\n",
    "place_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/place.csv', index=False, encoding='utf-8')\n",
    "print(\"=== place.csv íŒŒì¼ë¡œ ì €ìž¥ ì™„ë£Œ ===\")\n",
    "print(place_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³€ê²½ëœ ë°ì´í„° ìƒ˜í”Œ:\n",
      "     place_id  plan_id     place  is_public  visit_date  place_cost  memo  \\\n",
      "58         59     7001       NaN          0  2023-04-29         NaN   NaN   \n",
      "63         64     7001       NaN          0  2023-04-30         NaN   NaN   \n",
      "127       128     7004       ì„ ë‘ë¦¬          0  2023-05-20         NaN   NaN   \n",
      "264       265     7019  ì˜¤ì´Œë¦¬ ì‚° 32          0  2023-09-24         NaN   NaN   \n",
      "373       374     7027  ì•„ì–‘ë¡œ34ê¸¸10          0  2023-06-07         NaN   NaN   \n",
      "398       399     7031     íš¨ì²œìš°ë¯¸ë¦°          0  2023-09-02         NaN   NaN   \n",
      "405       406     7031     íš¨ì²œìš°ë¯¸ë¦°          0  2023-09-02         NaN   NaN   \n",
      "443       444     7024       NaN          0  2023-04-30         NaN   NaN   \n",
      "444       445     7035       NaN          0  2023-04-30         NaN   NaN   \n",
      "865       866     7064       NaN          0  2023-05-24         NaN   NaN   \n",
      "\n",
      "     lat  lon     p_name  p_order  \n",
      "58   NaN  NaN  ë³¸ê°€(ë¶€ëª¨ë‹˜ ì§‘)       13  \n",
      "63   NaN  NaN  ë³¸ê°€(ë¶€ëª¨ë‹˜ ì§‘)       18  \n",
      "127  NaN  NaN       ì¹œì²™ ì§‘        2  \n",
      "264  NaN  NaN       ì¹œì§€ ì§‘        8  \n",
      "373  NaN  NaN    ì¹œêµ¬ ì¹œì§€ ì§‘        1  \n",
      "398  NaN  NaN    ì¹œêµ¬ ì¹œì§€ ì§‘        1  \n",
      "405  NaN  NaN       ì¹œêµ¬ ì§‘        8  \n",
      "443  NaN  NaN      í• ë¨¸ë‹ˆ ì§‘        3  \n",
      "444  NaN  NaN      í• ë¨¸ë‹ˆ ì§‘        3  \n",
      "865  NaN  NaN       ì§€ì¸ ì§‘       23  \n",
      "=== ì§‘ ê´€ë ¨ í‚¤ì›Œë“œ(35ê°œ)ê°€ í¬í•¨ëœ ë°ì´í„° ê³µê°œì—¬ë¶€ ë³€ê²½ ë° ì €ìž¥ ì™„ë£Œ ===\n",
      "ì´ 341ê°œ ë ˆì½”ë“œê°€ ë¹„ê³µê°œë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "p_nameì— ì§‘ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„°ì˜ ê³µê°œì—¬ë¶€ Falseë¡œ ë³€ê²½\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1) place.csv ë¡œë“œ\n",
    "place_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/place.csv', encoding='utf-8')\n",
    "\n",
    "# 2) p_nameì— ì§‘ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„° ì°¾ê¸°\n",
    "home_keywords = [\n",
    "    'ê´‘ì£¼ ì§‘', 'ë”¸ ì§‘ ë°©ë¬¸', 'ê´‘ëª…ì‚¬ê±°ë¦¬ì—­ ê·¼ì²˜ ì¹œêµ¬ë„¤ ì§‘', 'ë§í¬ë™ 527-9 ì§‘', \n",
    "    'ì§‘ ê°•ë‚¨ì ', 'ë™í–‰ìž ì§‘ì—ì„œ ì—¬í–‰ ì¢…ë£Œ', 'ì§‘ ê·¼ì²˜', 'ì™¸í• ë¨¸ë‹ˆ ì§‘', 'ì–´ë¨¸ë‹ˆ ì§‘', 'ê³ ëª¨ì§‘', \n",
    "    'ë‚¨ì•½ì£¼ ê±°ì£¼ ì¹œêµ¬ë„¤ ì§‘', 'í• ë¨¸ë‹ˆ ì§‘', 'ì§‘ ë„ì°©', 'ê°€ì¡± ì§‘', 'ë³¸ê°€ ì§‘ ë„ì°©', 'ì¹œêµ¬ë„¤ ì§‘',\n",
    "    'ì¹œêµ¬ ì§‘', 'ì§€ì¸ ì§‘', 'ì¹œêµ¬ ì¹œì§€ ì§‘', 'ì¹œì§€ ì§‘', 'ë¶€ëª¨ë‹˜ ì§‘', \n",
    "    'ì—°ë‚¨ ê³ ì„ ì§‘', 'ìš°ë¦¬ ì§‘', 'ì¹œì§€ ëŒ', 'ì—¬ìžì¹œêµ¬ ì§‘', 'ì—¬ìžì¹œêµ¬ í• ë¨¸ë‹ˆ ì§‘',\n",
    "    'í• ë¨¸ë‹ˆë„¤ ì§‘', 'ì§€ì¸ ì§‘ ë°©ë¬¸', 'ë³¸ì¸ ì§‘', 'ì¹œê°€ ì§‘', 'ë™ìƒ ì§‘', \n",
    "    'ì¹œì²™ ì§‘', 'ì—„ë§ˆ ì§‘', 'í˜• ì§‘', 'ê³ í–¥ ì§‘'\n",
    "]\n",
    "\n",
    "# ëª¨ë“  í‚¤ì›Œë“œì— ëŒ€í•œ ì¡°ê±´ ìƒì„±\n",
    "home_places = place_df['p_name'].str.contains('|'.join(home_keywords), case=False, na=False)\n",
    "\n",
    "# 3) ê³µê°œì—¬ë¶€ ë³€ê²½ - ì§‘ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„°ë§Œ 0ìœ¼ë¡œ ë³€ê²½\n",
    "place_df.loc[home_places, 'is_public'] = 0\n",
    "place_df.loc[place_df['p_name'] == 'ì§‘', 'is_public'] = 0\n",
    "\n",
    "# ë³€ê²½ëœ ë°ì´í„° í™•ì¸\n",
    "print(\"ë³€ê²½ëœ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "print(place_df[home_places].head(10) if any(home_places) else \"ë³€ê²½ëœ ë°ì´í„° ì—†ìŒ\")\n",
    "\n",
    "# 4) ê²°ê³¼ ì €ìž¥\n",
    "place_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/place.csv', index=False, encoding='utf-8')\n",
    "print(f\"=== ì§‘ ê´€ë ¨ í‚¤ì›Œë“œ({len(home_keywords)}ê°œ)ê°€ í¬í•¨ëœ ë°ì´í„° ê³µê°œì—¬ë¶€ ë³€ê²½ ë° ì €ìž¥ ì™„ë£Œ ===\")\n",
    "print(f\"ì´ {home_places.sum()}ê°œ ë ˆì½”ë“œê°€ ë¹„ê³µê°œë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== plan.csv === ['plan_id', 'user_id', 'start_date', 'end_date', 'title', 'transport_info', 'location', 'group_id', 'is_public', 'total_cost']\n",
      "=== place.csv === ['place_id', 'plan_id', 'place', 'is_public', 'visit_date', 'place_cost', 'memo', 'lat', 'lon', 'p_name', 'p_order']\n",
      "=== visit_area_info.csv === ['VISIT_AREA_ID', 'TRAVEL_ID', 'VISIT_ORDER', 'VISIT_AREA_NM', 'VISIT_START_YMD', 'VISIT_END_YMD', 'ROAD_NM_ADDR', 'LOTNO_ADDR', 'X_COORD', 'Y_COORD', 'ROAD_NM_CD', 'LOTNO_CD', 'POI_ID', 'POI_NM', 'RESIDENCE_TIME_MIN', 'VISIT_AREA_TYPE_CD', 'REVISIT_YN', 'VISIT_CHC_REASON_CD', 'LODGING_TYPE_CD', 'DGSTFN', 'REVISIT_INTENTION', 'RCMDTN_INTENTION', 'SGG_CD']\n",
      "plan.csv í–‰ ìˆ˜: 2560\n",
      "place.csv í–‰ ìˆ˜: 28592\n",
      "visit_area_info.csv í–‰ ìˆ˜: 28389\n",
      "=== df_plan_place ìƒ˜í”Œ ===\n",
      "   place_id  plan_id                      place  is_public  visit_date  \\\n",
      "0         1     7000                 ìœ ë“±ë¡œ655ë²ˆê¸¸27          0  2023-04-29   \n",
      "1         2     7036                 ìœ ë“±ë¡œ655ë²ˆê¸¸27          0  2023-04-29   \n",
      "2         3     7000         ëŒ€ì „ ëŒ€ë•êµ¬ ë•ì•”ë¡œ222ë²ˆê¸¸ 34          1  2023-04-29   \n",
      "3         4     7036         ëŒ€ì „ ëŒ€ë•êµ¬ ë•ì•”ë¡œ222ë²ˆê¸¸ 34          1  2023-04-29   \n",
      "4         5     7000  ì¶©ë¶ ì²­ì£¼ì‹œ í¥ë•êµ¬ ì˜¥ì‚°ë©´ ê²½ë¶€ê³ ì†ë„ë¡œ 318          1  2023-04-29   \n",
      "\n",
      "   place_cost  memo        lat         lon                   p_name  p_order  \\\n",
      "0         NaN   NaN        NaN         NaN                        ì§‘        1   \n",
      "1         NaN   NaN        NaN         NaN                        ì§‘        1   \n",
      "2         NaN   NaN  36.439598  127.425684  ì•„ì£¼ ë§¤ìš´ ê³µì£¼ ì¹¼êµ­ìˆ˜ ì£¼ê¾¸ë¯¸êµ¬ì´ ì‹ íƒ„ì§„ì         2   \n",
      "3         NaN   NaN  36.439598  127.425684  ì•„ì£¼ ë§¤ìš´ ê³µì£¼ ì¹¼êµ­ìˆ˜ ì£¼ê¾¸ë¯¸êµ¬ì´ ì‹ íƒ„ì§„ì         2   \n",
      "4         NaN   NaN  36.716110  127.349358             ì²­ì£¼ íœ´ê²Œì†Œ ì„œìš¸ ë°©í–¥        3   \n",
      "\n",
      "   user_id  start_date    end_date  \n",
      "0    40005  2023-04-29  2023-05-03  \n",
      "1    40005  2023-04-28  2023-05-01  \n",
      "2    40005  2023-04-29  2023-05-03  \n",
      "3    40005  2023-04-28  2023-05-01  \n",
      "4    40005  2023-04-29  2023-05-03  \n",
      "df_plan_place í–‰ ìˆ˜: 28592\n",
      "df_plan_place NaN ê°’ í™•ì¸: \n",
      "place_id          0\n",
      "plan_id           0\n",
      "place          1384\n",
      "is_public         0\n",
      "visit_date        0\n",
      "place_cost    28592\n",
      "memo          28592\n",
      "lat            7098\n",
      "lon            7097\n",
      "p_name            0\n",
      "p_order           0\n",
      "user_id           0\n",
      "start_date        0\n",
      "end_date          0\n",
      "dtype: int64\n",
      "=== p_name ê³ ìœ ê°’ 10ê°œ ìƒ˜í”Œ ===\n",
      "['ì§‘' 'ì•„ì£¼ ë§¤ìš´ ê³µì£¼ ì¹¼êµ­ìˆ˜ ì£¼ê¾¸ë¯¸êµ¬ì´ ì‹ íƒ„ì§„ì ' 'ì²­ì£¼ íœ´ê²Œì†Œ ì„œìš¸ ë°©í–¥' 'ê°¤ëŸ­ì‹œí˜¸í…”' 'ì›”ë¯¸ë„' 'ì›”ë¯¸í…Œë§ˆíŒŒí¬'\n",
      " 'ì–´ë°˜ ì •ì›' 'ì›”ë¯¸ë„ ê°€ë½êµ­ìˆ˜ ì›”ë¯¸ë„ì ' 'ê°œí•­eì§€ íˆ¬ì–´' 'ì¸ì²œ ë§¥ì£¼']\n",
      "=== VISIT_AREA_NM ê³ ìœ ê°’ 10ê°œ ìƒ˜í”Œ ===\n",
      "['ì§‘' 'ì•„ì£¼ ë§¤ìš´ ê³µì£¼ ì¹¼êµ­ìˆ˜ ì£¼ê¾¸ë¯¸êµ¬ì´ ì‹ íƒ„ì§„ì ' 'ì²­ì£¼ íœ´ê²Œì†Œ ì„œìš¸ ë°©í–¥' 'ê°¤ëŸ­ì‹œí˜¸í…”' 'ì›”ë¯¸ë„' 'ì›”ë¯¸í…Œë§ˆíŒŒí¬'\n",
      " 'ì–´ë°˜ ì •ì›' 'ì›”ë¯¸ë„ ê°€ë½êµ­ìˆ˜ ì›”ë¯¸ë„ì ' 'ê°œí•­eì§€ íˆ¬ì–´' 'ì¸ì²œ ë§¥ì£¼']\n",
      "ê³µê°œ ìž¥ì†Œ ìˆ˜: 23662, ë¹„ê³µê°œ ìž¥ì†Œ ìˆ˜: 4930\n",
      "=== log_df NaN ê°’ í™•ì¸ ===\n",
      "log_id          0\n",
      "is_public       0\n",
      "user_id      4930\n",
      "plan_id      4930\n",
      "comment      4930\n",
      "create_at    4930\n",
      "dtype: int64\n",
      "ì´ ë ˆì½”ë“œ: 28592, ê³µê°œ(is_public=1): 23662, ë¹„ê³µê°œ(is_public=0): 4930\n",
      "=== log.csv ìƒì„± ì™„ë£Œ ===\n",
      "\n",
      "=== ê³µê°œ ë°ì´í„° ìƒ˜í”Œ ===\n",
      "   log_id  is_public  user_id  plan_id  \\\n",
      "2   60002          1  40005.0   7000.0   \n",
      "3   60003          1  40005.0   7036.0   \n",
      "4   60004          1  40005.0   7000.0   \n",
      "5   60005          1  40005.0   7036.0   \n",
      "6   60006          1  40005.0   7000.0   \n",
      "\n",
      "                                      comment   create_at  \n",
      "2  [ì•„ì£¼ ë§¤ìš´ ê³µì£¼ ì¹¼êµ­ìˆ˜ ì£¼ê¾¸ë¯¸êµ¬ì´ ì‹ íƒ„ì§„ì ] ë§Œì¡±ë„=5.0, ìž¬ë°©ë¬¸=5.0  2023-04-29  \n",
      "3  [ì•„ì£¼ ë§¤ìš´ ê³µì£¼ ì¹¼êµ­ìˆ˜ ì£¼ê¾¸ë¯¸êµ¬ì´ ì‹ íƒ„ì§„ì ] ë§Œì¡±ë„=5.0, ìž¬ë°©ë¬¸=5.0  2023-04-29  \n",
      "4             [ì²­ì£¼ íœ´ê²Œì†Œ ì„œìš¸ ë°©í–¥] ë§Œì¡±ë„=5.0, ìž¬ë°©ë¬¸=5.0  2023-04-29  \n",
      "5             [ì²­ì£¼ íœ´ê²Œì†Œ ì„œìš¸ ë°©í–¥] ë§Œì¡±ë„=5.0, ìž¬ë°©ë¬¸=5.0  2023-04-29  \n",
      "6                    [ê°¤ëŸ­ì‹œí˜¸í…”] ë§Œì¡±ë„=5.0, ìž¬ë°©ë¬¸=5.0  2023-04-29  \n",
      "\n",
      "=== ë¹„ê³µê°œ ë°ì´í„° ìƒ˜í”Œ ===\n",
      "    log_id  is_public  user_id  plan_id comment create_at\n",
      "0    60000          0      NaN      NaN     NaN       NaN\n",
      "1    60001          0      NaN      NaN     NaN       NaN\n",
      "44   60044          0      NaN      NaN     NaN       NaN\n",
      "45   60045          0      NaN      NaN     NaN       NaN\n",
      "46   60046          0      NaN      NaN     NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” plan.csv, place.csv, ê·¸ë¦¬ê³  AIHubì˜ visit_area_info.csv(ë°©ë¬¸ì§€ì •ë³´) íŒŒì¼ì„\n",
    "í•¨ê»˜ í™œìš©í•˜ì—¬ 'log.csv'(ê°€ìƒì˜ ì—¬í–‰ ê¸°ë¡ í…Œì´ë¸”)ì„ ë§Œë“¤ì–´ë‚´ëŠ” ì˜ˆì‹œìž…ë‹ˆë‹¤.\n",
    "\n",
    "[ëª©í‘œ]\n",
    "1) plan.csv + place.csvë¥¼ mergeí•´ì„œ (user_id, plan_id, p_name, visit_date ë“±) ì •ë³´ë¥¼ í™•ë³´\n",
    "2) place.csv + visit_area_info.csvë¥¼ mergeí•´ì„œ AIHubì˜ ì¶”ê°€ ì •ë³´(DGSTFN, REVISIT_INTENTION ë“±)ë¥¼ ê°€ì ¸ì˜´\n",
    "3) (1)ê³¼ (2)ì˜ ë³‘í•© ê²°ê³¼ì—ì„œ log í…Œì´ë¸”ì— í•„ìš”í•œ ì»¬ëŸ¼(log_id, user_id, plan_id, comment, create_at, is_public ë“±)ì„ ìƒì„±\n",
    "4) ìµœì¢… ê²°ê³¼ë¥¼ log.csv ë¡œ ì €ìž¥\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) CSV íŒŒì¼ ë¡œë“œ\n",
    "df_plan = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/plan.csv', encoding='utf-8')\n",
    "df_place = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/place.csv', encoding='utf-8')\n",
    "df_visit = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/west/tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_G.csv', encoding='utf-8')  # AIHub ë°©ë¬¸ì§€ì •ë³´\n",
    "\n",
    "print(\"=== plan.csv ===\", df_plan.columns.tolist())\n",
    "print(\"=== place.csv ===\", df_place.columns.tolist())\n",
    "print(\"=== visit_area_info.csv ===\", df_visit.columns.tolist())\n",
    "\n",
    "# ë””ë²„ê¹…ì„ ìœ„í•œ ì •ë³´ ì¶œë ¥\n",
    "print(f\"plan.csv í–‰ ìˆ˜: {len(df_plan)}\")\n",
    "print(f\"place.csv í–‰ ìˆ˜: {len(df_place)}\")\n",
    "print(f\"visit_area_info.csv í–‰ ìˆ˜: {len(df_visit)}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) plan + place ë³‘í•©\n",
    "#    place í…Œì´ë¸”ì—ëŠ” plan_idê°€ ìžˆê³ , plan í…Œì´ë¸”ì—ëŠ” (plan_id, user_id, start_date, end_date ë“±)ì´ ìžˆìŒ\n",
    "#    -> í•˜ë‚˜ì˜ DFë¡œ í•©ì³ì„œ (user_id, plan_id, p_name, place, visit_date, ...) ë“±ì„ ê°€ì§„ë‹¤\n",
    "# ------------------------------------------------------------------------------\n",
    "df_plan_place = pd.merge(\n",
    "    df_place,\n",
    "    df_plan[['plan_id', 'user_id', 'start_date', 'end_date']],\n",
    "    on='plan_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# df_plan_placeì—ëŠ” user_id(í”Œëžœ ìž‘ì„±ìž), p_name(ë°©ë¬¸ì§€ëª…), visit_date ë“± ì •ë³´ê°€ í¬í•¨ë¨\n",
    "print(\"=== df_plan_place ìƒ˜í”Œ ===\")\n",
    "print(df_plan_place.head())\n",
    "print(f\"df_plan_place í–‰ ìˆ˜: {len(df_plan_place)}\")\n",
    "print(f\"df_plan_place NaN ê°’ í™•ì¸: \\n{df_plan_place.isna().sum()}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3-1) ë””ë²„ê¹…: VISIT_AREA_NMê³¼ p_name ê°’ í™•ì¸\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"=== p_name ê³ ìœ ê°’ 10ê°œ ìƒ˜í”Œ ===\")\n",
    "print(df_plan_place['p_name'].dropna().unique()[:10])\n",
    "\n",
    "print(\"=== VISIT_AREA_NM ê³ ìœ ê°’ 10ê°œ ìƒ˜í”Œ ===\")\n",
    "print(df_visit['VISIT_AREA_NM'].dropna().unique()[:10])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3-2) place + visit_area_info ë³‘í•© (ì§ì ‘ ë§¤í•‘ ì—†ì´ ì¼ë‹¨ place.csvë§Œ ì‚¬ìš©)\n",
    "# ------------------------------------------------------------------------------\n",
    "# ì¼ë‹¨ AIHubì˜ ë°©ë¬¸ì§€ì •ë³´ë¥¼ ì°¸ê³ í•˜ì§€ ì•Šê³ , place.csvì˜ ë°ì´í„°ë§Œ ì‚¬ìš©í•´ì„œ log ìƒì„±\n",
    "df_plan_place_ai = df_plan_place.copy()\n",
    "\n",
    "# ë°©ë¬¸ì§€ ë§Œì¡±ë„ì™€ ìž¬ë°©ë¬¸ ì˜í–¥ì„ ìƒì„± (ì‹¤ì œë¡œëŠ” AIHub ë°ì´í„° ì‚¬ìš©)\n",
    "df_plan_place_ai['DGSTFN'] = df_visit['DGSTFN']\n",
    "df_plan_place_ai['REVISIT_INTENTION'] = df_visit['REVISIT_INTENTION']\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) log í…Œì´ë¸”ìš© DataFrame êµ¬ì„±\n",
    "#    -> ìš”êµ¬ì‚¬í•­: place.csvì˜ is_publicì´ 0ì¸ ë°ì´í„°ëŠ” logë¥¼ ë§Œë“¤ì§€ ì•Šê³ , \n",
    "#       ìƒì„±ëœ logëŠ” isPublicë§Œ 0ìœ¼ë¡œ ì„¤ì •í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” nullë¡œ ì„¤ì •\n",
    "# ------------------------------------------------------------------------------\n",
    "# ë¨¼ì € is_publicì´ 1ì¸ ìž¥ì†Œë§Œ í•„í„°ë§ (ê³µê°œëœ ìž¥ì†Œë§Œ) - ì›ë³¸ ë°ì´í„°ì—ì„œ í™•ì¸\n",
    "place_public_count = df_plan_place_ai[df_plan_place_ai['is_public'] == 1].shape[0]\n",
    "place_private_count = df_plan_place_ai[df_plan_place_ai['is_public'] == 0].shape[0]\n",
    "print(f\"ê³µê°œ ìž¥ì†Œ ìˆ˜: {place_public_count}, ë¹„ê³µê°œ ìž¥ì†Œ ìˆ˜: {place_private_count}\")\n",
    "\n",
    "# ê³µê°œìš© ë¡œê·¸ë§Œ ìƒì„±\n",
    "log_df = pd.DataFrame()\n",
    "\n",
    "# log_id ìƒì„±: ëª¨ë“  ìž¥ì†Œ ë°ì´í„°ì— ëŒ€í•´ ì¼ë ¨ë²ˆí˜¸ ë¶€ì—¬\n",
    "log_df['log_id'] = range(60000, 60000 + len(df_plan_place_ai))\n",
    "\n",
    "# is_public: ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ placeì˜ is_public ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "log_df['is_public'] = df_plan_place_ai['is_public']\n",
    "\n",
    "# placeì˜ is_public ê°’ì— ë”°ë¼ ì„ íƒì ìœ¼ë¡œ ë°ì´í„° ì±„ìš°ê¸°\n",
    "# is_public = 1ì¸ ìž¥ì†Œ ë°ì´í„°ë§Œ ë‚´ìš© ì±„ìš°ê¸°\n",
    "# is_public = 0ì¸ ìž¥ì†Œ ë°ì´í„°ëŠ” NaNìœ¼ë¡œ ë‘ê¸°\n",
    "is_public_mask = df_plan_place_ai['is_public'] == 1\n",
    "\n",
    "# user_id, plan_id, place_id ì±„ìš°ê¸° - ê³µê°œ ë°ì´í„°ë§Œ\n",
    "log_df['user_id'] = np.where(is_public_mask, df_plan_place_ai['user_id'], np.nan)\n",
    "log_df['plan_id'] = np.where(is_public_mask, df_plan_place_ai['plan_id'], np.nan)\n",
    "\n",
    "# NaN ê°’ì´ í¬í•¨ë˜ì–´ ìžˆìœ¼ë©´ intë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì €ìž¥ ì „ì— í•„ìš”í•œ ë¶€ë¶„ë§Œ intë¡œ ë³€í™˜\n",
    "# ê³µê°œ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "mask = log_df['is_public'] == 1\n",
    "if mask.any():\n",
    "    log_df.loc[mask, 'user_id'] = log_df.loc[mask, 'user_id'].astype(int)\n",
    "    log_df.loc[mask, 'plan_id'] = log_df.loc[mask, 'plan_id'].astype(int)\n",
    "\n",
    "# comment ìƒì„± - ê³µê°œ ë°ì´í„°ë§Œ\n",
    "def make_comment(row):\n",
    "    if row['is_public'] != 1:\n",
    "        return np.nan\n",
    "        \n",
    "    p_name = row.get('p_name', 'ì•Œ ìˆ˜ ì—†ëŠ” ìž¥ì†Œ')\n",
    "    dgs = row.get('DGSTFN', np.nan)\n",
    "    rvt = row.get('REVISIT_INTENTION', np.nan)\n",
    "    \n",
    "    # Noneê°’ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë¬¸ìžì—´ ë³€í™˜:\n",
    "    if pd.isna(dgs):\n",
    "        dgs = 'N/A'\n",
    "    if pd.isna(rvt):\n",
    "        rvt = 'N/A'\n",
    "    \n",
    "    if pd.isna(p_name) or p_name == '':\n",
    "        p_name = 'ì•Œ ìˆ˜ ì—†ëŠ” ìž¥ì†Œ'\n",
    "    \n",
    "    return f\"[{p_name}] ë§Œì¡±ë„={dgs}, ìž¬ë°©ë¬¸={rvt}\"\n",
    "\n",
    "log_df['comment'] = df_plan_place_ai.apply(make_comment, axis=1)\n",
    "\n",
    "# create_at: ê³µê°œ ë°ì´í„°ë§Œ ë‚ ì§œ ì‚¬ìš©, ë¹„ê³µê°œëŠ” NaN\n",
    "log_df['create_at'] = np.where(is_public_mask, df_plan_place_ai['visit_date'], np.nan)\n",
    "\n",
    "\n",
    "# NaN ê°’ í™•ì¸\n",
    "print(\"=== log_df NaN ê°’ í™•ì¸ ===\")\n",
    "print(log_df.isna().sum())\n",
    "print(f\"ì´ ë ˆì½”ë“œ: {len(log_df)}, ê³µê°œ(is_public=1): {log_df['is_public'].sum()}, ë¹„ê³µê°œ(is_public=0): {len(log_df) - log_df['is_public'].sum()}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) ê²°ê³¼ ì €ìž¥\n",
    "# ------------------------------------------------------------------------------\n",
    "log_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/log.csv', index=False, encoding='utf-8')\n",
    "print(\"=== log.csv ìƒì„± ì™„ë£Œ ===\")\n",
    "# ê³µê°œ/ë¹„ê³µê°œ ë°ì´í„° ê°ê° 5ê°œì”© ì¶œë ¥\n",
    "print(\"\\n=== ê³µê°œ ë°ì´í„° ìƒ˜í”Œ ===\")\n",
    "print(log_df[log_df['is_public'] == 1].head(5))\n",
    "print(\"\\n=== ë¹„ê³µê°œ ë°ì´í„° ìƒ˜í”Œ ===\")\n",
    "print(log_df[log_df['is_public'] == 0].head(5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì„±ëœ follow ìˆ˜: 12682 / ì‚¬ìš©ìž ìˆ˜: 2560\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "user.csvë¥¼ ì½ì–´ ê°€ìƒì˜ follow.csvë¥¼ ìƒì„±í•œë‹¤.\n",
    " - ë¹„ìŠ·í•œ ì§€ì—­/ìŠ¤íƒ€ì¼ì„ ì„ í˜¸í•˜ë©´ íŒ”ë¡œìš° í™•ë¥ ì„ ë†’ìž„\n",
    " - ì¼ë¶€ ì‚¬ìš©ìžë¥¼ 'ì¸í”Œë£¨ì–¸ì„œ'ë¡œ ì§€ì •í•´ ë§Žì´ íŒ”ë¡œìš° ë°›ìŒ\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------------\n",
    "# í•˜ì´í¼ íŒŒë¼ë¯¸í„°\n",
    "# --------------------\n",
    "AVG_FOLLOW_OUT = 5          # í•œ ì‚¬ìš©ìžê°€ íŒ”ë¡œìš°í•˜ëŠ” í‰ê·  ìˆ˜\n",
    "INFLU_RATIO    = 0.05       # ì¸í”Œë£¨ì–¸ì„œ ë¹„ìœ¨ (ìƒìœ„ 5%)\n",
    "W_SIM          = 0.7        # ìœ ì‚¬ ì·¨í–¥ ê°€ì¤‘ì¹˜\n",
    "W_RAND         = 0.3        # ë¬´ìž‘ìœ„ ê°€ì¤‘ì¹˜\n",
    "SEED           = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 1) ì‚¬ìš©ìž ë¡œë“œ\n",
    "user_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/user.csv')  # ìµœì†Œ user_id ì»¬ëŸ¼ í•„ìš”\n",
    "user_ids = user_df['user_id'].tolist()\n",
    "N = len(user_ids)\n",
    "\n",
    "# 2) ìœ ì‚¬ë„ í–‰ë ¬(0~1) ë§Œë“¤ê¸° â”€ ì—¬ê¸°ì„œëŠ”\n",
    "#    ê°™ì€ region / ìŠ¤íƒ€ì¼ì´ë©´ 1, ì•„ë‹ˆë©´ 0 ì˜ ë‹¨ìˆœ ì˜ˆì‹œ\n",
    "#    (ì„ í˜¸ ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ì „ë¶€ 0 ë°°ì—´ë¡œ ë‘ê³  ì™„ì „ ëžœë¤)\n",
    "sim = np.zeros((N, N))\n",
    "\n",
    "if {'pref_region','pref_style'}.issubset(user_df.columns):\n",
    "    for i, u in enumerate(user_ids):\n",
    "        for j, v in enumerate(user_ids):\n",
    "            if i==j:\n",
    "                continue\n",
    "            same_region = user_df.at[i, 'pref_region'] == user_df.at[j, 'pref_region']\n",
    "            same_style  = user_df.at[i, 'pref_style']  == user_df.at[j, 'pref_style']\n",
    "            sim[i, j] = 0.5*same_region + 0.5*same_style  # ë‘˜ë‹¤ ê°™ìœ¼ë©´ 1, í•˜ë‚˜ë§Œ ê°™ìœ¼ë©´ 0.5\n",
    "\n",
    "# 3) ì¸í”Œë£¨ì–¸ì„œ ì„ ì • (íŒ”ë¡œì›Œ ë§Žì´ ë°›ìŒ)\n",
    "infl_n = max(1, int(N * INFLU_RATIO))\n",
    "infl_ids = np.random.choice(user_ids, infl_n, replace=False)\n",
    "\n",
    "# 4) íŒ”ë¡œìš° ìƒì„±\n",
    "follows = []\n",
    "f_id = 1\n",
    "for idx, uid in enumerate(user_ids):\n",
    "    # íŒ”ë¡œìš°í•  ìˆ˜ candidate pool (ìžê¸° ì œì™¸)\n",
    "    candidates = [x for x in user_ids if x != uid]\n",
    "\n",
    "    # ê¸°ë³¸ íŒ”ë¡œìš° ìˆ˜ = Poisson(AVG_FOLLOW_OUT)\n",
    "    k = max(1, np.random.poisson(lam=AVG_FOLLOW_OUT))\n",
    "\n",
    "    # ê°€ì¤‘ì¹˜:  w_sim * sim + w_rand * uniform\n",
    "    weights = (W_SIM * sim[idx] + W_RAND * np.random.rand(N))\n",
    "    weights[idx] = 0  # self 0\n",
    "    # ì¸í”Œë£¨ì–¸ì„œëŠ” weight ë³´ì •(ë§Žì´ íŒ”ë¡œìš° ë°›ë„ë¡)\n",
    "    for j, cand in enumerate(user_ids):\n",
    "        if cand in infl_ids:\n",
    "            weights[j] *= 2.5   # ê°€ì¤‘ì¹˜ ìƒìŠ¹\n",
    "\n",
    "    # ì •ê·œí™” í›„ ìƒ˜í”Œ\n",
    "    probs = weights / weights.sum()\n",
    "    to_follow = np.random.choice(user_ids, size=k, replace=False, p=probs)\n",
    "\n",
    "    for target in to_follow:\n",
    "        follows.append({'f_id': f_id, 'from_user': uid, 'to_user': int(target)})\n",
    "        f_id += 1\n",
    "\n",
    "# 5) deduplicate í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ì œê±°\n",
    "follow_df = pd.DataFrame(follows).drop_duplicates()\n",
    "follow_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/follow.csv', index=False)\n",
    "print(f\"ìƒì„±ëœ follow ìˆ˜: {len(follow_df)} / ì‚¬ìš©ìž ìˆ˜: {N}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Like Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "log_df     = pd.read_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/log.csv\")\n",
    "follow_df  = pd.read_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/follow.csv\")          # from_user, to_user\n",
    "visit_df   = pd.read_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/west/tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_G.csv\") # DGSTFN ë“±\n",
    "\n",
    "# 1) ìž‘ì„±ìž â†’ DGSTFN ë§¤í•‘ ëŒ€ë¹„ìš©\n",
    "log_meta = log_df[['log_id', 'user_id', 'create_at']].merge(\n",
    "    visit_df[['VISIT_AREA_ID', 'DGSTFN']],\n",
    "    left_on='log_id',      # log_id == VISIT_AREA_ID ë¼ê³  ê°€ì •(ì´ë¯¸ ë§¤í•‘)\n",
    "    right_on='VISIT_AREA_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "likes = []\n",
    "\n",
    "for _, row in log_meta.iterrows():\n",
    "    author = row['user_id']\n",
    "    likers = follow_df.loc[follow_df['to_user']==author, 'from_user'].tolist()   # íŒ”ë¡œì›Œë“¤\n",
    "    candidate_pool = set(likers) | set(np.random.choice(log_df['user_id'], 5))   # íŒ”ë¡œì›Œ+ëžœë¤ 5ëª…\n",
    "    \n",
    "    for u in candidate_pool:\n",
    "        # ë™ì¼ ì‚¬ìš©ìžê°€ ìžê¸° ê¸€ì—” ì¢‹ì•„ìš” ì•ˆ ëˆ„ë¥´ê²Œ í•  ìˆ˜ë„ ìžˆìŒ\n",
    "        if u == author: \n",
    "            continue\n",
    "        \n",
    "        # í™•ë¥  ê²°ì •\n",
    "        if u in likers:\n",
    "            p = 0.35\n",
    "        elif row['DGSTFN']>=4:\n",
    "            p = 0.20\n",
    "        else:\n",
    "            p = 0.05\n",
    "        \n",
    "        if rng.random() < p:\n",
    "            likes.append({'log_id': row['log_id'], 'user_id': u})\n",
    "\n",
    "like_df = pd.DataFrame(likes).drop_duplicates()\n",
    "like_df.to_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/like.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Comment (ëŒ“ê¸€) Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "  5: [\"ì™€, ìµœê³ ë„¤ìš”!\", \"ì—¬ê¸° ê¼­ ê°€ë´ì•¼ê² ì–´ìš”ðŸ˜\", \"ì‚¬ì§„ì´ ì •ë§ ë©‹ì ¸ìš”!\"],\n",
    "  4: [\"ì¢‹ì•„ë³´ì—¬ìš”!\", \"ê¿€íŒ ê°ì‚¬í•´ìš”\", \"ê°€ë³´ê³  ì‹¶ì–´ìš”\"],\n",
    "  3: [\"ì •ë³´ ê³ ë§ˆì›Œìš”!\", \"ìž¬ë°Œì–´ ë³´ìž…ë‹ˆë‹¤\"],\n",
    "  2: [\"ì•„ì‰¬ì› êµ°ìš”ðŸ˜¢\", \"ë‹¤ìŒì—” ë” ì¢‹ê¸¸!\"],\n",
    "  1: [\"í—‰â€¦ ë³„ë¡œì˜€ë‚˜ ë´ìš”\", \"ì •ë³´ ê³µìœ  ê°ì‚¬\"]\n",
    "}\n",
    "\n",
    "import itertools, datetime as dt\n",
    "comments = []\n",
    "loco_id  = itertools.count(1)\n",
    "\n",
    "for _, row in log_meta.iterrows():\n",
    "    author   = row['user_id']\n",
    "    rating   = int(row['DGSTFN']) if not np.isnan(row['DGSTFN']) else 3\n",
    "    pool_temp= templates.get(rating, templates[3])\n",
    "\n",
    "    followers = follow_df.loc[follow_df['to_user']==author, 'from_user']\n",
    "    cand_non  = rng.choice(log_df['user_id'], 5, replace=False)\n",
    "    for u in set(followers) | set(cand_non):\n",
    "        if u==author:\n",
    "            continue\n",
    "        p = 0.12 if u in followers.values else 0.03\n",
    "        if rng.random() < p:\n",
    "            # create_at ì²˜ë¦¬: NaTë©´ í˜„ìž¬ì‹œê°„ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©\n",
    "            base_time = pd.to_datetime(row['create_at'])\n",
    "            if pd.isnull(base_time):\n",
    "                base_time = pd.Timestamp.now()\n",
    "            comment_time = base_time + pd.Timedelta(minutes=int(rng.integers(5, 720)))\n",
    "            comments.append({\n",
    "                'loco_id'    : next(loco_id),\n",
    "                'log_id'     : row['log_id'],\n",
    "                'user_id'    : u,\n",
    "                'loco_comment': rng.choice(pool_temp),\n",
    "                'create_at'  : comment_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'parent_id'  : None\n",
    "            })\n",
    "\n",
    "comment_df = pd.DataFrame(comments)\n",
    "comment_df.to_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/log_comment.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Action Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = []\n",
    "ts_now = pd.Timestamp('now')\n",
    "\n",
    "# â‘  post\n",
    "ua.extend([{\n",
    "    'action_id'  : i,\n",
    "    'user_id'    : r['user_id'],\n",
    "    'target_id'  : r['log_id'],\n",
    "    'action_type': 'post',\n",
    "    'target_type': 'log',\n",
    "    'action_time': r['create_at']\n",
    "} for i, r in log_df.iterrows()])\n",
    "\n",
    "# â‘¡ like\n",
    "for _, r in like_df.iterrows():\n",
    "    ua.append({\n",
    "        'action_id'  : None,\n",
    "        'user_id'    : r['user_id'],\n",
    "        'target_id'  : r['log_id'],\n",
    "        'action_type': 'like',\n",
    "        'target_type': 'log',\n",
    "        'action_time': ts_now.isoformat()\n",
    "    })\n",
    "\n",
    "# â‘¢ comment\n",
    "for _, r in comment_df.iterrows():\n",
    "    ua.append({\n",
    "        'action_id'  : None,\n",
    "        'user_id'    : r['user_id'],\n",
    "        'target_id'  : r['log_id'],\n",
    "        'action_type': 'comment',\n",
    "        'target_type': 'log',\n",
    "        'action_time': r['create_at']\n",
    "    })\n",
    "\n",
    "user_actions_df = pd.DataFrame(ua)\n",
    "user_actions_df['action_id'] = range(170000, 170000 + len(user_actions_df))\n",
    "user_actions_df.to_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_w/user_actions.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

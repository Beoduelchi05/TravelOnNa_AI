{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIHub여행객정보 ➡️ user 테이블 매핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User ID Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plan 테이블 컬럼 확인: ['plan_id', 'user_id', 'start_date', 'end_date', 'title', 'transport_info', 'location', 'group_id', 'is_public', 'total_cost']\n",
      "   plan_id  user_id start_date   end_date title transport_info location  \\\n",
      "0     4000    20003 2023-04-30 2023-05-01   F03                      서울   \n",
      "1     4001    20340 2023-05-27 2023-05-30   E03                      경기   \n",
      "2     4002    20515 2023-06-03 2023-06-07   F06                      경남   \n",
      "3     4003    20571 2023-05-24 2023-05-27   E01                      서울   \n",
      "4     4004    20601 2023-05-26 2023-05-30   F02                      대구   \n",
      "\n",
      "  group_id  is_public total_cost  \n",
      "0                   1             \n",
      "1                   1             \n",
      "2                   1             \n",
      "3                   1             \n",
      "4                   1             \n",
      "저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 및 변환 스크립트\n",
    "# 이 코드는 원본 데이터셋을 우리 시스템에 맞게 변환하는 작업을 수행합니다.\n",
    "# 1. 원본 데이터 파일 로드 (여행객 Master, 여행 데이터)\n",
    "# 2. User 테이블 생성 - TRAVELER_ID에서 문자 제거 후 숫자만 추출하여 user_id 생성\n",
    "# 3. Plan 테이블 생성 - Master와 Travel 데이터 조인 후 필요한 필드 추출\n",
    "# 4. 생성된 데이터를 CSV 파일로 저장\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 파일 읽기\n",
    "df_master = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/east/tn_traveller_master_여행객 Master_F.csv', encoding='utf-8')\n",
    "df_travel = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/east/tn_travel_여행_F.csv', encoding='utf-8')\n",
    "\n",
    "# User 테이블 생성 (기존과 동일)\n",
    "temp_id = df_master['TRAVELER_ID'].str.replace(r'[a-zA-Z]', '', regex=True).astype(int)\n",
    "user_df = pd.DataFrame({\n",
    "    'user_id': 20000 + temp_id,\n",
    "    'email': df_master['TRAVELER_ID'].astype(str) + '@gmail.com',\n",
    "    'name': df_master['TRAVELER_ID']\n",
    "})\n",
    "\n",
    "# Plan 테이블 생성\n",
    "df_plan = pd.merge(df_travel, df_master[['TRAVELER_ID', 'TRAVEL_STATUS_DESTINATION']], \n",
    "                   on='TRAVELER_ID', how='left')\n",
    "\n",
    "traveler_ids = df_plan['TRAVELER_ID'].str.replace(r'[a-zA-Z]', '', regex=True).astype(int)\n",
    "\n",
    "plan_df = pd.DataFrame({\n",
    "    'plan_id': range(4000, 4000 + len(df_plan)),\n",
    "    'user_id': 20000 + traveler_ids,\n",
    "    'start_date': pd.to_datetime(df_plan['TRAVEL_START_YMD']),\n",
    "    'end_date': pd.to_datetime(df_plan['TRAVEL_END_YMD']),\n",
    "    'title': df_plan['TRAVEL_NM'],\n",
    "    'transport_info': '',          # 빈값\n",
    "    'location': df_plan['TRAVEL_STATUS_DESTINATION'],\n",
    "    'group_id': '',                # 빈값\n",
    "    'is_public': 1,                # 1로 고정\n",
    "    'total_cost': ''               # 빈값\n",
    "})\n",
    "\n",
    "print(\"\\nPlan 테이블 컬럼 확인:\", plan_df.columns.tolist())\n",
    "print(plan_df.head())\n",
    "\n",
    "# 저장\n",
    "user_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/user.csv', index=False)\n",
    "plan_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/plan.csv', index=False)\n",
    "print(\"저장 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Profile Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   profile_id  user_id nickname profile_image introduction  \\\n",
      "0           1    20531  f000531          None         None   \n",
      "1           2    29186  f009186          None         None   \n",
      "2           3    36521  f016521          None         None   \n",
      "3           4    22539  f002539          None         None   \n",
      "4           5    25129  f005129          None         None   \n",
      "\n",
      "            created_at updated_at  \n",
      "0  2025-05-26 11:37:39       None  \n",
      "1  2025-05-26 11:37:39       None  \n",
      "2  2025-05-26 11:37:39       None  \n",
      "3  2025-05-26 11:37:39       None  \n",
      "4  2025-05-26 11:37:39       None  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "이 스크립트는 사용자 프로필 데이터를 생성하는 과정입니다.\n",
    "\n",
    "1. 기존에 생성한 user.csv 파일을 읽어옵니다.\n",
    "2. 각 사용자에 대한 프로필 정보를 생성합니다:\n",
    "   - profile_id: 순차적으로 할당 (실제 DB에서는 auto_increment)\n",
    "   - user_id: user.csv의 user_id와 매핑\n",
    "   - nickname: user의 name 값 사용\n",
    "   - 기타 필드: 초기값 설정\n",
    "3. 생성된 프로필 데이터를 profile.csv 파일로 저장합니다.\n",
    "\n",
    "이 데이터는 사용자 프로필 관리 및 추천 시스템의 user_preferences 테이블 구성에 활용됩니다.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 기존에 생성한 user_migrated.csv 파일 읽기\n",
    "user_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/user.csv', encoding='utf-8')\n",
    "profile_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/profile.csv', encoding='utf-8')\n",
    "\n",
    "# 현재 시각을 created_at 값으로 사용 (문자열 형태로 변환)\n",
    "current_ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# profile 테이블에 맞게 매핑: \n",
    "# profile_id: auto_increment 효과를 위해 1부터 순차적으로 할당 (실제 DB에서는 auto_increment 되므로 CSV에서 참고용)\n",
    "# user_id: user_migrated.csv의 user_id 사용\n",
    "# nickname: user의 name 컬럼 사용\n",
    "# profile_image, introduction, updated_at: null 처리 (여기서는 빈 문자열로 표시)\n",
    "profile_df = pd.DataFrame()\n",
    "profile_df['profile_id'] = range(1, 1 + len(user_df))\n",
    "profile_df['user_id'] = user_df['user_id']\n",
    "profile_df['nickname'] = user_df['name']\n",
    "profile_df['profile_image'] = None   # 또는 빈 문자열: ''\n",
    "profile_df['introduction'] = None      # 또는 빈 문자열: ''\n",
    "profile_df['created_at'] = current_ts\n",
    "profile_df['updated_at'] = None        # 또는 빈 문자열: ''\n",
    "\n",
    "# 결과 미리보기\n",
    "print(profile_df.head())\n",
    "\n",
    "# profile.csv 파일로 저장\n",
    "profile_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/profile.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여행객.csv columns: ['TRAVELER_ID', 'RESIDENCE_SGG_CD', 'GENDER', 'AGE_GRP', 'EDU_NM', 'EDU_FNSH_SE', 'MARR_STTS', 'FAMILY_MEMB', 'JOB_NM', 'JOB_ETC', 'INCOME', 'HOUSE_INCOME', 'TRAVEL_TERM', 'TRAVEL_NUM', 'TRAVEL_LIKE_SIDO_1', 'TRAVEL_LIKE_SGG_1', 'TRAVEL_LIKE_SIDO_2', 'TRAVEL_LIKE_SGG_2', 'TRAVEL_LIKE_SIDO_3', 'TRAVEL_LIKE_SGG_3', 'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4', 'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8', 'TRAVEL_STATUS_RESIDENCE', 'TRAVEL_STATUS_DESTINATION', 'TRAVEL_STATUS_ACCOMPANY', 'TRAVEL_STATUS_YMD', 'TRAVEL_MOTIVE_1', 'TRAVEL_MOTIVE_2', 'TRAVEL_MOTIVE_3', 'TRAVEL_COMPANIONS_NUM']\n",
      "tn_travel_여행_E.csv columns: ['TRAVEL_ID', 'TRAVEL_NM', 'TRAVELER_ID', 'TRAVEL_PURPOSE', 'TRAVEL_START_YMD', 'TRAVEL_END_YMD', 'MVMN_NM', 'TRAVEL_PERSONA', 'TRAVEL_MISSION', 'TRAVEL_MISSION_CHECK']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'e000003'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m plan_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_plan[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAVEL_STATUS_DESTINATION\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 만약 사용자와의 매핑이 필요하다면, user 테이블과 동일한 TRAVELER_ID를 기준으로 매핑할 수 있음\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 여기서는 간단히 TRAVELER_ID를 user_id로 사용한다고 가정 (실제 migration 시에는 이전에 생성한 매핑을 참조)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m plan_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_plan\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTRAVELER_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# plan_id를 1000부터 순차적으로 할당 (auto_increment 효과)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m plan_df\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplan_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(plan_df)))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/mino/lib/python3.11/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/mino/lib/python3.11/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/mino/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/mino/lib/python3.11/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/mino/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/mino/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/mino/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'e000003'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 여행객.csv 파일 읽기: TRAVELER_ID, TRAVEL_STATUS_DESTINATION 컬럼이 포함되어 있다고 가정\n",
    "df_traveler = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/east/tn_traveller_master_여행객 Master_F.csv', encoding='utf-8')\n",
    "\n",
    "# tn_travel_여행_E.csv 파일 읽기: TRAVELER_ID, TRAVEL_START_YMD, TRAVEL_END_YMD 컬럼이 포함되어 있다고 가정\n",
    "df_travel = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/east/tn_travel_여행_F.csv', encoding='utf-8')\n",
    "\n",
    "# 파일의 컬럼 확인\n",
    "print(\"여행객.csv columns:\", df_traveler.columns.tolist())\n",
    "print(\"tn_travel_여행_E.csv columns:\", df_travel.columns.tolist())\n",
    "\n",
    "# 두 데이터프레임을 TRAVELER_ID를 기준으로 조인 (여행객 정보의 'TRAVEL_STATUS_DESTINATION'을 가져옴)\n",
    "df_plan = pd.merge(df_travel, df_traveler[['TRAVELER_ID', 'TRAVEL_STATUS_DESTINATION']], \n",
    "                   on='TRAVELER_ID', how='left')\n",
    "\n",
    "# plan 테이블에 필요한 컬럼 매핑\n",
    "# - start_date : TRAVEL_START_YMD\n",
    "# - end_date   : TRAVEL_END_YMD\n",
    "# - location   : TRAVEL_STATUS_DESTINATION\n",
    "\n",
    "plan_df = pd.DataFrame()\n",
    "plan_df['start_date'] = df_plan['TRAVEL_START_YMD']\n",
    "plan_df['end_date'] = df_plan['TRAVEL_END_YMD']\n",
    "plan_df['location'] = df_plan['TRAVEL_STATUS_DESTINATION']\n",
    "\n",
    "# 만약 사용자와의 매핑이 필요하다면, user 테이블과 동일한 TRAVELER_ID를 기준으로 매핑할 수 있음\n",
    "# 여기서는 간단히 TRAVELER_ID를 user_id로 사용한다고 가정 (실제 migration 시에는 이전에 생성한 매핑을 참조)\n",
    "plan_df['user_id'] = df_plan['TRAVELER_ID'].astype(int)\n",
    "\n",
    "# plan_id를 1000부터 순차적으로 할당 (auto_increment 효과)\n",
    "plan_df.insert(0, 'plan_id', range(1000, 1000 + len(plan_df)))\n",
    "\n",
    "# 결과 미리보기\n",
    "print(plan_df.head())\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "plan_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/plan_migrated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== plan.csv 컬럼 ===\n",
      "['plan_id', 'user_id', 'start_date', 'end_date', 'title', 'transport_info', 'location', 'group_id', 'is_public', 'total_cost']\n",
      "=== 방문지정보 컬럼 ===\n",
      "['VISIT_AREA_ID', 'TRAVEL_ID', 'VISIT_ORDER', 'VISIT_AREA_NM', 'VISIT_START_YMD', 'VISIT_END_YMD', 'ROAD_NM_ADDR', 'LOTNO_ADDR', 'X_COORD', 'Y_COORD', 'ROAD_NM_CD', 'LOTNO_CD', 'POI_ID', 'POI_NM', 'RESIDENCE_TIME_MIN', 'VISIT_AREA_TYPE_CD', 'REVISIT_YN', 'VISIT_CHC_REASON_CD', 'LODGING_TYPE_CD', 'DGSTFN', 'REVISIT_INTENTION', 'RCMDTN_INTENTION', 'SGG_CD']\n",
      "=== 병합 결과 샘플 ===\n",
      "   TRAVEL_ID  user_id  plan_id\n",
      "0  e_e000003    20003     4000\n",
      "1  e_e000003    20003     4000\n",
      "2  e_e000003    20003     4000\n",
      "3  e_e000003    20003     4000\n",
      "4  e_e000003    20003     4000\n",
      "=== place.csv 파일로 저장 완료 ===\n",
      "   place_id  plan_id                   place  is_public  visit_date  \\\n",
      "0         1     4000           경기 김포시 풍년로 19          1  2023-04-30   \n",
      "1         2     4000   경기 안성시 원곡면 경부고속도로 365          1  2023-04-30   \n",
      "2         3     4000                 금강로 596          1  2023-04-30   \n",
      "3         4     4000           경북 김천시 운동장길 1          1  2023-04-30   \n",
      "4         5     4000  충남 천안시 서북구 입장면 연곡길 407          1  2023-04-30   \n",
      "5         6     4000           경기 김포시 풍년로 19          1  2023-04-30   \n",
      "6         7     4001                 씨제이나인파크          1  2023-05-27   \n",
      "7         8     4060                 씨제이나인파크          1  2023-05-27   \n",
      "8         9     4001     경기 포천시 신북면 호국로 2451          1  2023-05-27   \n",
      "9        10     4060     경기 포천시 신북면 호국로 2451          1  2023-05-27   \n",
      "\n",
      "  place_cost  memo        lat         lon             p_name  p_order  \n",
      "0       None  None        NaN         NaN                  집        1  \n",
      "1       None  None  37.013556  127.144690         안성휴게소 부산방향        2  \n",
      "2       None  None  36.279001  127.672032              금강휴게소        3  \n",
      "3       None  None  36.139677  128.086424            김천종합운동장        4  \n",
      "4       None  None  36.943005  127.192712  입장 거봉포도 휴게소 서울 방향        5  \n",
      "5       None  None        NaN         NaN                  집        6  \n",
      "6       None  None        NaN         NaN                  집        1  \n",
      "7       None  None        NaN         NaN                  집        1  \n",
      "8       None  None  37.964150  127.247150               자유 궁        2  \n",
      "9       None  None  37.964150  127.247150               자유 궁        2  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "이 스크립트는 Aihub에서 제공하는 'tn_visit_area_info_방문지정보_E.csv' 데이터를\n",
    "우리 시스템의 plan.csv와 연결하여, 모든 TRAVEL_ID에 대한 place 테이블 형식 CSV를 생성합니다.\n",
    "\n",
    "특히 TRAVEL_ID('e_e000004') → user_id(4)처럼,\n",
    "TRAVEL_ID에서 'e_e000' 접두사를 제거한 뒤 int로 변환하여 user_id를 구한 후,\n",
    "해당 user_id를 plan.csv와 매핑(plan_id)하는 로직을 포함합니다.\n",
    "\n",
    "구체적으로 다음 작업을 합니다:\n",
    "1) plan.csv 로드 (user_id, plan_id 정보를 갖고 있어야 함)\n",
    "2) 방문지정보 파일 로드 (tn_visit_area_info_방문지정보_E.csv)\n",
    "3) TRAVEL_ID에서 접두사 제거 후 int 변환 → user_id\n",
    "4) plan.csv와 user_id를 기준으로 merge하여 plan_id 할당\n",
    "5) place 테이블 컬럼(place, is_public, visit_date, lat, lon, p_name, p_order 등) 생성\n",
    "6) 결과를 place_migrated.csv에 저장\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# 1) plan.csv 로드\n",
    "df_plan = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/plan.csv', encoding='utf-8')\n",
    "print(\"=== plan.csv 컬럼 ===\")\n",
    "print(df_plan.columns.tolist())\n",
    "\n",
    "# 2) 방문지정보 파일 로드\n",
    "df_v = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/east/tn_visit_area_info_방문지정보_F.csv', encoding='utf-8')\n",
    "print(\"=== 방문지정보 컬럼 ===\")\n",
    "print(df_v.columns.tolist())\n",
    "\n",
    "# 3) TRAVEL_ID -> user_id 변환(20000 + 숫자)\n",
    "def convert_travel_id_to_user_id(travel_id: str) -> int:\n",
    "    # 예: 'e_e000004' → 20004, 'f_f000007' → 20007\n",
    "    cleaned_id = re.sub(r'^[a-z]_[a-z]', '', travel_id)\n",
    "    return 20000 + int(cleaned_id)\n",
    "\n",
    "df_v['user_id'] = df_v['TRAVEL_ID'].apply(convert_travel_id_to_user_id)\n",
    "\n",
    "# 4) plan.csv와 user_id를 기준으로 merge → plan_id 할당\n",
    "df_plan_map = df_plan[['user_id', 'plan_id']].drop_duplicates()\n",
    "df_merged = pd.merge(df_v, df_plan_map, on='user_id', how='inner')\n",
    "\n",
    "print(\"=== 병합 결과 샘플 ===\")\n",
    "print(df_merged[['TRAVEL_ID','user_id','plan_id']].head())\n",
    "\n",
    "# 5) place 테이블 생성 (필요 컬럼만, 순서 맞춤)\n",
    "place_df = pd.DataFrame()\n",
    "place_df['place_id'] = range(1, 1 + len(df_merged))\n",
    "place_df['plan_id'] = df_merged['plan_id']\n",
    "place_df['place'] = np.where(\n",
    "    df_merged['ROAD_NM_ADDR'].notnull() & (df_merged['ROAD_NM_ADDR'] != ''),\n",
    "    df_merged['ROAD_NM_ADDR'],\n",
    "    df_merged['LOTNO_ADDR']\n",
    ")\n",
    "place_df['is_public'] = 1\n",
    "place_df['visit_date'] = df_merged['VISIT_START_YMD']\n",
    "place_df['place_cost'] = None\n",
    "place_df['memo'] = None\n",
    "place_df['lat'] = df_merged['Y_COORD']\n",
    "place_df['lon'] = df_merged['X_COORD']\n",
    "place_df['p_name'] = df_merged['VISIT_AREA_NM']\n",
    "place_df['p_order'] = df_merged['VISIT_ORDER'].astype(int)\n",
    "\n",
    "# 6) 결과 저장\n",
    "place_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/place.csv', index=False, encoding='utf-8')\n",
    "print(\"=== place.csv 파일로 저장 완료 ===\")\n",
    "print(place_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변경된 데이터 샘플:\n",
      "     place_id  plan_id               place  is_public  visit_date  place_cost  \\\n",
      "112       113     4005         서울 국회단지 14길          0  2023-05-20         NaN   \n",
      "113       114     4195         서울 국회단지 14길          0  2023-05-20         NaN   \n",
      "122       123     4005         서울 국회단지 14길          0  2023-05-20         NaN   \n",
      "123       124     4195         서울 국회단지 14길          0  2023-05-20         NaN   \n",
      "219       220     4011       울산 동구 상진2길 25          0  2023-04-29         NaN   \n",
      "220       221     6553       울산 동구 상진2길 25          0  2023-04-29         NaN   \n",
      "257       258     4012  경기 수원시 영통구 영통로 498          0  2023-04-30         NaN   \n",
      "373       374     4021               한신아파트          0  2023-04-29         NaN   \n",
      "375       376     4021              한신휴플러스          0  2023-04-30         NaN   \n",
      "391       392     4022             송정한신아파트          0  2023-04-30         NaN   \n",
      "\n",
      "     memo  lat  lon   p_name  p_order  \n",
      "112   NaN  NaN  NaN  친구 친지 집        1  \n",
      "113   NaN  NaN  NaN  친구 친지 집        1  \n",
      "122   NaN  NaN  NaN     친구 집        6  \n",
      "123   NaN  NaN  NaN     친구 집        6  \n",
      "219   NaN  NaN  NaN  친구 친지 집        1  \n",
      "220   NaN  NaN  NaN  친구 친지 집        1  \n",
      "257   NaN  NaN  NaN  친구 친지 집        1  \n",
      "373   NaN  NaN  NaN     친지 집        8  \n",
      "375   NaN  NaN  NaN     친지 집       10  \n",
      "391   NaN  NaN  NaN  친척 집 방문       15  \n",
      "=== 집 관련 키워드(35개)가 포함된 데이터 공개여부 변경 및 저장 완료 ===\n",
      "총 314개 레코드가 비공개로 변경되었습니다.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "p_name에 집 관련 키워드가 포함된 데이터의 공개여부 False로 변경\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1) place.csv 로드\n",
    "place_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/place.csv', encoding='utf-8')\n",
    "\n",
    "# 2) p_name에 집 관련 키워드가 포함된 데이터 찾기\n",
    "home_keywords = [\n",
    "    '광주 집', '딸 집 방문', '광명사거리역 근처 친구네 집', '망포동 527-9 집', \n",
    "    '집 강남점', '동행자 집에서 여행 종료', '집 근처', '외할머니 집', '어머니 집', '고모집', \n",
    "    '남약주 거주 친구네 집', '할머니 집', '집 도착', '가족 집', '본가 집 도착', '친구네 집',\n",
    "    '친구 집', '지인 집', '친구 친지 집', '친지 집', '부모님 집', \n",
    "    '연남 고을 집', '우리 집', '친지 댁', '여자친구 집', '여자친구 할머니 집',\n",
    "    '할머니네 집', '지인 집 방문', '본인 집', '친가 집', '동생 집', \n",
    "    '친척 집', '엄마 집', '형 집', '고향 집'\n",
    "]\n",
    "\n",
    "# 모든 키워드에 대한 조건 생성\n",
    "home_places = place_df['p_name'].str.contains('|'.join(home_keywords), case=False, na=False)\n",
    "\n",
    "# 3) 공개여부 변경 - 집 관련 키워드가 포함된 데이터만 0으로 변경\n",
    "place_df.loc[home_places, 'is_public'] = 0\n",
    "place_df.loc[place_df['p_name'] == '집', 'is_public'] = 0\n",
    "\n",
    "# 변경된 데이터 확인\n",
    "print(\"변경된 데이터 샘플:\")\n",
    "print(place_df[home_places].head(10) if any(home_places) else \"변경된 데이터 없음\")\n",
    "\n",
    "# 4) 결과 저장\n",
    "place_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/place.csv', index=False, encoding='utf-8')\n",
    "print(f\"=== 집 관련 키워드({len(home_keywords)}개)가 포함된 데이터 공개여부 변경 및 저장 완료 ===\")\n",
    "print(f\"총 {home_places.sum()}개 레코드가 비공개로 변경되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== plan.csv === ['plan_id', 'user_id', 'start_date', 'end_date', 'title', 'transport_info', 'location', 'group_id', 'is_public', 'total_cost']\n",
      "=== place.csv === ['place_id', 'plan_id', 'place', 'is_public', 'visit_date', 'place_cost', 'memo', 'lat', 'lon', 'p_name', 'p_order']\n",
      "=== visit_area_info.csv === ['VISIT_AREA_ID', 'TRAVEL_ID', 'VISIT_ORDER', 'VISIT_AREA_NM', 'VISIT_START_YMD', 'VISIT_END_YMD', 'ROAD_NM_ADDR', 'LOTNO_ADDR', 'X_COORD', 'Y_COORD', 'ROAD_NM_CD', 'LOTNO_CD', 'POI_ID', 'POI_NM', 'RESIDENCE_TIME_MIN', 'VISIT_AREA_TYPE_CD', 'REVISIT_YN', 'VISIT_CHC_REASON_CD', 'LODGING_TYPE_CD', 'DGSTFN', 'REVISIT_INTENTION', 'RCMDTN_INTENTION', 'SGG_CD']\n",
      "plan.csv 행 수: 2560\n",
      "place.csv 행 수: 29613\n",
      "visit_area_info.csv 행 수: 29392\n",
      "=== df_plan_place 샘플 ===\n",
      "   place_id  plan_id                   place  is_public  visit_date  \\\n",
      "0         1     4000           경기 김포시 풍년로 19          0  2023-04-30   \n",
      "1         2     4000   경기 안성시 원곡면 경부고속도로 365          1  2023-04-30   \n",
      "2         3     4000                 금강로 596          1  2023-04-30   \n",
      "3         4     4000           경북 김천시 운동장길 1          1  2023-04-30   \n",
      "4         5     4000  충남 천안시 서북구 입장면 연곡길 407          1  2023-04-30   \n",
      "\n",
      "   place_cost  memo        lat         lon             p_name  p_order  \\\n",
      "0         NaN   NaN        NaN         NaN                  집        1   \n",
      "1         NaN   NaN  37.013556  127.144690         안성휴게소 부산방향        2   \n",
      "2         NaN   NaN  36.279001  127.672032              금강휴게소        3   \n",
      "3         NaN   NaN  36.139677  128.086424            김천종합운동장        4   \n",
      "4         NaN   NaN  36.943005  127.192712  입장 거봉포도 휴게소 서울 방향        5   \n",
      "\n",
      "   user_id  start_date    end_date  \n",
      "0    20003  2023-04-30  2023-05-01  \n",
      "1    20003  2023-04-30  2023-05-01  \n",
      "2    20003  2023-04-30  2023-05-01  \n",
      "3    20003  2023-04-30  2023-05-01  \n",
      "4    20003  2023-04-30  2023-05-01  \n",
      "df_plan_place 행 수: 29613\n",
      "df_plan_place NaN 값 확인: \n",
      "place_id          0\n",
      "plan_id           0\n",
      "place          1421\n",
      "is_public         0\n",
      "visit_date        0\n",
      "place_cost    29613\n",
      "memo          29613\n",
      "lat            6979\n",
      "lon            6979\n",
      "p_name            0\n",
      "p_order           0\n",
      "user_id           0\n",
      "start_date        0\n",
      "end_date          0\n",
      "dtype: int64\n",
      "=== p_name 고유값 10개 샘플 ===\n",
      "['집' '안성휴게소 부산방향' '금강휴게소' '김천종합운동장' '입장 거봉포도 휴게소 서울 방향' '자유 궁'\n",
      " '포천 자연마을 서울 캠핑장' '고석정 국민관광지' '한탄강 하늘다리' '포천 봄꽃 정원']\n",
      "=== VISIT_AREA_NM 고유값 10개 샘플 ===\n",
      "['집' '안성휴게소 부산방향' '금강휴게소' '김천종합운동장' '입장 거봉포도 휴게소 서울 방향' '자유 궁'\n",
      " '포천 자연마을 서울 캠핑장' '고석정 국민관광지' '한탄강 하늘다리' '포천 봄꽃 정원']\n",
      "공개 장소 수: 24185, 비공개 장소 수: 5428\n",
      "=== log_df NaN 값 확인 ===\n",
      "log_id          0\n",
      "is_public       0\n",
      "user_id      5428\n",
      "plan_id      5428\n",
      "comment      5428\n",
      "create_at    5428\n",
      "dtype: int64\n",
      "총 레코드: 29613, 공개(is_public=1): 24185, 비공개(is_public=0): 5428\n",
      "=== log.csv 생성 완료 ===\n",
      "\n",
      "=== 공개 데이터 샘플 ===\n",
      "   log_id  is_public  user_id  plan_id                               comment  \\\n",
      "1   30001          1  20003.0   4000.0         [안성휴게소 부산방향] 만족도=4.0, 재방문=4.0   \n",
      "2   30002          1  20003.0   4000.0              [금강휴게소] 만족도=4.0, 재방문=4.0   \n",
      "3   30003          1  20003.0   4000.0            [김천종합운동장] 만족도=5.0, 재방문=5.0   \n",
      "4   30004          1  20003.0   4000.0  [입장 거봉포도 휴게소 서울 방향] 만족도=4.0, 재방문=4.0   \n",
      "8   30008          1  20340.0   4001.0               [자유 궁] 만족도=5.0, 재방문=5.0   \n",
      "\n",
      "    create_at  \n",
      "1  2023-04-30  \n",
      "2  2023-04-30  \n",
      "3  2023-04-30  \n",
      "4  2023-04-30  \n",
      "8  2023-05-27  \n",
      "\n",
      "=== 비공개 데이터 샘플 ===\n",
      "    log_id  is_public  user_id  plan_id comment create_at\n",
      "0    30000          0      NaN      NaN     NaN       NaN\n",
      "5    30005          0      NaN      NaN     NaN       NaN\n",
      "6    30006          0      NaN      NaN     NaN       NaN\n",
      "7    30007          0      NaN      NaN     NaN       NaN\n",
      "36   30036          0      NaN      NaN     NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "이 스크립트는 plan.csv, place.csv, 그리고 AIHub의 visit_area_info.csv(방문지정보) 파일을\n",
    "함께 활용하여 'log.csv'(가상의 여행 기록 테이블)을 만들어내는 예시입니다.\n",
    "\n",
    "[목표]\n",
    "1) plan.csv + place.csv를 merge해서 (user_id, plan_id, p_name, visit_date 등) 정보를 확보\n",
    "2) place.csv + visit_area_info.csv를 merge해서 AIHub의 추가 정보(DGSTFN, REVISIT_INTENTION 등)를 가져옴\n",
    "3) (1)과 (2)의 병합 결과에서 log 테이블에 필요한 컬럼(log_id, user_id, plan_id, comment, create_at, is_public 등)을 생성\n",
    "4) 최종 결과를 log.csv 로 저장\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) CSV 파일 로드\n",
    "df_plan = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/plan.csv', encoding='utf-8')\n",
    "df_place = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/place.csv', encoding='utf-8')\n",
    "df_visit = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/east/tn_visit_area_info_방문지정보_F.csv', encoding='utf-8')  # AIHub 방문지정보\n",
    "\n",
    "print(\"=== plan.csv ===\", df_plan.columns.tolist())\n",
    "print(\"=== place.csv ===\", df_place.columns.tolist())\n",
    "print(\"=== visit_area_info.csv ===\", df_visit.columns.tolist())\n",
    "\n",
    "# 디버깅을 위한 정보 출력\n",
    "print(f\"plan.csv 행 수: {len(df_plan)}\")\n",
    "print(f\"place.csv 행 수: {len(df_place)}\")\n",
    "print(f\"visit_area_info.csv 행 수: {len(df_visit)}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) plan + place 병합\n",
    "#    place 테이블에는 plan_id가 있고, plan 테이블에는 (plan_id, user_id, start_date, end_date 등)이 있음\n",
    "#    -> 하나의 DF로 합쳐서 (user_id, plan_id, p_name, place, visit_date, ...) 등을 가진다\n",
    "# ------------------------------------------------------------------------------\n",
    "df_plan_place = pd.merge(\n",
    "    df_place,\n",
    "    df_plan[['plan_id', 'user_id', 'start_date', 'end_date']],\n",
    "    on='plan_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# df_plan_place에는 user_id(플랜 작성자), p_name(방문지명), visit_date 등 정보가 포함됨\n",
    "print(\"=== df_plan_place 샘플 ===\")\n",
    "print(df_plan_place.head())\n",
    "print(f\"df_plan_place 행 수: {len(df_plan_place)}\")\n",
    "print(f\"df_plan_place NaN 값 확인: \\n{df_plan_place.isna().sum()}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3-1) 디버깅: VISIT_AREA_NM과 p_name 값 확인\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"=== p_name 고유값 10개 샘플 ===\")\n",
    "print(df_plan_place['p_name'].dropna().unique()[:10])\n",
    "\n",
    "print(\"=== VISIT_AREA_NM 고유값 10개 샘플 ===\")\n",
    "print(df_visit['VISIT_AREA_NM'].dropna().unique()[:10])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3-2) place + visit_area_info 병합 (직접 매핑 없이 일단 place.csv만 사용)\n",
    "# ------------------------------------------------------------------------------\n",
    "# 일단 AIHub의 방문지정보를 참고하지 않고, place.csv의 데이터만 사용해서 log 생성\n",
    "df_plan_place_ai = df_plan_place.copy()\n",
    "\n",
    "# 방문지 만족도와 재방문 의향을 생성 (실제로는 AIHub 데이터 사용)\n",
    "df_plan_place_ai['DGSTFN'] = df_visit['DGSTFN']\n",
    "df_plan_place_ai['REVISIT_INTENTION'] = df_visit['REVISIT_INTENTION']\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) log 테이블용 DataFrame 구성\n",
    "#    -> 요구사항: place.csv의 is_public이 0인 데이터는 log를 만들지 않고, \n",
    "#       생성된 log는 isPublic만 0으로 설정하고 나머지는 null로 설정\n",
    "# ------------------------------------------------------------------------------\n",
    "# 먼저 is_public이 1인 장소만 필터링 (공개된 장소만) - 원본 데이터에서 확인\n",
    "place_public_count = df_plan_place_ai[df_plan_place_ai['is_public'] == 1].shape[0]\n",
    "place_private_count = df_plan_place_ai[df_plan_place_ai['is_public'] == 0].shape[0]\n",
    "print(f\"공개 장소 수: {place_public_count}, 비공개 장소 수: {place_private_count}\")\n",
    "\n",
    "# 공개용 로그만 생성\n",
    "log_df = pd.DataFrame()\n",
    "\n",
    "# log_id 생성: 모든 장소 데이터에 대해 일련번호 부여\n",
    "log_df['log_id'] = range(30000, 30000 + len(df_plan_place_ai))\n",
    "\n",
    "# is_public: 모든 데이터에 대해 place의 is_public 값 그대로 사용\n",
    "log_df['is_public'] = df_plan_place_ai['is_public']\n",
    "\n",
    "# place의 is_public 값에 따라 선택적으로 데이터 채우기\n",
    "# is_public = 1인 장소 데이터만 내용 채우기\n",
    "# is_public = 0인 장소 데이터는 NaN으로 두기\n",
    "is_public_mask = df_plan_place_ai['is_public'] == 1\n",
    "\n",
    "# user_id, plan_id, place_id 채우기 - 공개 데이터만\n",
    "log_df['user_id'] = np.where(is_public_mask, df_plan_place_ai['user_id'], np.nan)\n",
    "log_df['plan_id'] = np.where(is_public_mask, df_plan_place_ai['plan_id'], np.nan)\n",
    "\n",
    "# NaN 값이 포함되어 있으면 int로 변환할 수 없으므로, 저장 전에 필요한 부분만 int로 변환\n",
    "# 공개 데이터에 대해서만 정수형으로 변환\n",
    "mask = log_df['is_public'] == 1\n",
    "if mask.any():\n",
    "    log_df.loc[mask, 'user_id'] = log_df.loc[mask, 'user_id'].astype(int)\n",
    "    log_df.loc[mask, 'plan_id'] = log_df.loc[mask, 'plan_id'].astype(int)\n",
    "\n",
    "# comment 생성 - 공개 데이터만\n",
    "def make_comment(row):\n",
    "    if row['is_public'] != 1:\n",
    "        return np.nan\n",
    "        \n",
    "    p_name = row.get('p_name', '알 수 없는 장소')\n",
    "    dgs = row.get('DGSTFN', np.nan)\n",
    "    rvt = row.get('REVISIT_INTENTION', np.nan)\n",
    "    \n",
    "    # None값을 방지하기 위해 문자열 변환:\n",
    "    if pd.isna(dgs):\n",
    "        dgs = 'N/A'\n",
    "    if pd.isna(rvt):\n",
    "        rvt = 'N/A'\n",
    "    \n",
    "    if pd.isna(p_name) or p_name == '':\n",
    "        p_name = '알 수 없는 장소'\n",
    "    \n",
    "    return f\"[{p_name}] 만족도={dgs}, 재방문={rvt}\"\n",
    "\n",
    "log_df['comment'] = df_plan_place_ai.apply(make_comment, axis=1)\n",
    "\n",
    "# create_at: 공개 데이터만 날짜 사용, 비공개는 NaN\n",
    "log_df['create_at'] = np.where(is_public_mask, df_plan_place_ai['visit_date'], np.nan)\n",
    "\n",
    "\n",
    "# NaN 값 확인\n",
    "print(\"=== log_df NaN 값 확인 ===\")\n",
    "print(log_df.isna().sum())\n",
    "print(f\"총 레코드: {len(log_df)}, 공개(is_public=1): {log_df['is_public'].sum()}, 비공개(is_public=0): {len(log_df) - log_df['is_public'].sum()}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) 결과 저장\n",
    "# ------------------------------------------------------------------------------\n",
    "log_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/log.csv', index=False, encoding='utf-8')\n",
    "print(\"=== log.csv 생성 완료 ===\")\n",
    "# 공개/비공개 데이터 각각 5개씩 출력\n",
    "print(\"\\n=== 공개 데이터 샘플 ===\")\n",
    "print(log_df[log_df['is_public'] == 1].head(5))\n",
    "print(\"\\n=== 비공개 데이터 샘플 ===\")\n",
    "print(log_df[log_df['is_public'] == 0].head(5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 follow 수: 12682 / 사용자 수: 2560\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "user.csv를 읽어 가상의 follow.csv를 생성한다.\n",
    " - 비슷한 지역/스타일을 선호하면 팔로우 확률을 높임\n",
    " - 일부 사용자를 '인플루언서'로 지정해 많이 팔로우 받음\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------------\n",
    "# 하이퍼 파라미터\n",
    "# --------------------\n",
    "AVG_FOLLOW_OUT = 5          # 한 사용자가 팔로우하는 평균 수\n",
    "INFLU_RATIO    = 0.05       # 인플루언서 비율 (상위 5%)\n",
    "W_SIM          = 0.7        # 유사 취향 가중치\n",
    "W_RAND         = 0.3        # 무작위 가중치\n",
    "SEED           = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 1) 사용자 로드\n",
    "user_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/user.csv')  # 최소 user_id 컬럼 필요\n",
    "user_ids = user_df['user_id'].tolist()\n",
    "N = len(user_ids)\n",
    "\n",
    "# 2) 유사도 행렬(0~1) 만들기 ─ 여기서는\n",
    "#    같은 region / 스타일이면 1, 아니면 0 의 단순 예시\n",
    "#    (선호 데이터가 없다면 전부 0 배열로 두고 완전 랜덤)\n",
    "sim = np.zeros((N, N))\n",
    "\n",
    "if {'pref_region','pref_style'}.issubset(user_df.columns):\n",
    "    for i, u in enumerate(user_ids):\n",
    "        for j, v in enumerate(user_ids):\n",
    "            if i==j:\n",
    "                continue\n",
    "            same_region = user_df.at[i, 'pref_region'] == user_df.at[j, 'pref_region']\n",
    "            same_style  = user_df.at[i, 'pref_style']  == user_df.at[j, 'pref_style']\n",
    "            sim[i, j] = 0.5*same_region + 0.5*same_style  # 둘다 같으면 1, 하나만 같으면 0.5\n",
    "\n",
    "# 3) 인플루언서 선정 (팔로워 많이 받음)\n",
    "infl_n = max(1, int(N * INFLU_RATIO))\n",
    "infl_ids = np.random.choice(user_ids, infl_n, replace=False)\n",
    "\n",
    "# 4) 팔로우 생성\n",
    "follows = []\n",
    "f_id = 1\n",
    "for idx, uid in enumerate(user_ids):\n",
    "    # 팔로우할 수 candidate pool (자기 제외)\n",
    "    candidates = [x for x in user_ids if x != uid]\n",
    "\n",
    "    # 기본 팔로우 수 = Poisson(AVG_FOLLOW_OUT)\n",
    "    k = max(1, np.random.poisson(lam=AVG_FOLLOW_OUT))\n",
    "\n",
    "    # 가중치:  w_sim * sim + w_rand * uniform\n",
    "    weights = (W_SIM * sim[idx] + W_RAND * np.random.rand(N))\n",
    "    weights[idx] = 0  # self 0\n",
    "    # 인플루언서는 weight 보정(많이 팔로우 받도록)\n",
    "    for j, cand in enumerate(user_ids):\n",
    "        if cand in infl_ids:\n",
    "            weights[j] *= 2.5   # 가중치 상승\n",
    "\n",
    "    # 정규화 후 샘플\n",
    "    probs = weights / weights.sum()\n",
    "    to_follow = np.random.choice(user_ids, size=k, replace=False, p=probs)\n",
    "\n",
    "    for target in to_follow:\n",
    "        follows.append({'f_id': f_id, 'from_user': uid, 'to_user': int(target)})\n",
    "        f_id += 1\n",
    "\n",
    "# 5) deduplicate 혹시 모를 중복 제거\n",
    "follow_df = pd.DataFrame(follows).drop_duplicates()\n",
    "follow_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/follow.csv', index=False)\n",
    "print(f\"생성된 follow 수: {len(follow_df)} / 사용자 수: {N}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Like Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# 데이터 로드\n",
    "log_df     = pd.read_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/log.csv\")\n",
    "follow_df  = pd.read_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/follow.csv\")          # from_user, to_user\n",
    "visit_df   = pd.read_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/east/tn_visit_area_info_방문지정보_F.csv\") # DGSTFN 등\n",
    "\n",
    "# 1) 작성자 → DGSTFN 매핑 대비용\n",
    "log_meta = log_df[['log_id', 'user_id', 'create_at']].merge(\n",
    "    visit_df[['VISIT_AREA_ID', 'DGSTFN']],\n",
    "    left_on='log_id',      # log_id == VISIT_AREA_ID 라고 가정(이미 매핑)\n",
    "    right_on='VISIT_AREA_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "likes = []\n",
    "\n",
    "for _, row in log_meta.iterrows():\n",
    "    author = row['user_id']\n",
    "    likers = follow_df.loc[follow_df['to_user']==author, 'from_user'].tolist()   # 팔로워들\n",
    "    candidate_pool = set(likers) | set(np.random.choice(log_df['user_id'], 5))   # 팔로워+랜덤 5명\n",
    "    \n",
    "    for u in candidate_pool:\n",
    "        # 동일 사용자가 자기 글엔 좋아요 안 누르게 할 수도 있음\n",
    "        if u == author: \n",
    "            continue\n",
    "        \n",
    "        # 확률 결정\n",
    "        if u in likers:\n",
    "            p = 0.35\n",
    "        elif row['DGSTFN']>=4:\n",
    "            p = 0.20\n",
    "        else:\n",
    "            p = 0.05\n",
    "        \n",
    "        if rng.random() < p:\n",
    "            likes.append({'log_id': row['log_id'], 'user_id': u})\n",
    "\n",
    "like_df = pd.DataFrame(likes).drop_duplicates()\n",
    "like_df.to_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/like.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Comment (댓글) Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "  5: [\"와, 최고네요!\", \"여기 꼭 가봐야겠어요😍\", \"사진이 정말 멋져요!\"],\n",
    "  4: [\"좋아보여요!\", \"꿀팁 감사해요\", \"가보고 싶어요\"],\n",
    "  3: [\"정보 고마워요!\", \"재밌어 보입니다\"],\n",
    "  2: [\"아쉬웠군요😢\", \"다음엔 더 좋길!\"],\n",
    "  1: [\"헉… 별로였나 봐요\", \"정보 공유 감사\"]\n",
    "}\n",
    "\n",
    "import itertools, datetime as dt\n",
    "comments = []\n",
    "loco_id  = itertools.count(1)\n",
    "\n",
    "for _, row in log_meta.iterrows():\n",
    "    author   = row['user_id']\n",
    "    rating   = int(row['DGSTFN']) if not np.isnan(row['DGSTFN']) else 3\n",
    "    pool_temp= templates.get(rating, templates[3])\n",
    "\n",
    "    followers = follow_df.loc[follow_df['to_user']==author, 'from_user']\n",
    "    cand_non  = rng.choice(log_df['user_id'], 5, replace=False)\n",
    "    for u in set(followers) | set(cand_non):\n",
    "        if u==author:\n",
    "            continue\n",
    "        p = 0.12 if u in followers.values else 0.03\n",
    "        if rng.random() < p:\n",
    "            # create_at 처리: NaT면 현재시간을 기본값으로 사용\n",
    "            base_time = pd.to_datetime(row['create_at'])\n",
    "            if pd.isnull(base_time):\n",
    "                base_time = pd.Timestamp.now()\n",
    "            comment_time = base_time + pd.Timedelta(minutes=int(rng.integers(5, 720)))\n",
    "            comments.append({\n",
    "                'loco_id'    : next(loco_id),\n",
    "                'log_id'     : row['log_id'],\n",
    "                'user_id'    : u,\n",
    "                'loco_comment': rng.choice(pool_temp),\n",
    "                'create_at'  : comment_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'parent_id'  : None\n",
    "            })\n",
    "\n",
    "comment_df = pd.DataFrame(comments)\n",
    "comment_df.to_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/log_comment.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Action Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = []\n",
    "ts_now = pd.Timestamp('now')\n",
    "\n",
    "# ① post\n",
    "ua.extend([{\n",
    "    'action_id'  : i,\n",
    "    'user_id'    : r['user_id'],\n",
    "    'target_id'  : r['log_id'],\n",
    "    'action_type': 'post',\n",
    "    'target_type': 'log',\n",
    "    'action_time': r['create_at']\n",
    "} for i, r in log_df.iterrows()])\n",
    "\n",
    "# ② like\n",
    "for _, r in like_df.iterrows():\n",
    "    ua.append({\n",
    "        'action_id'  : None,\n",
    "        'user_id'    : r['user_id'],\n",
    "        'target_id'  : r['log_id'],\n",
    "        'action_type': 'like',\n",
    "        'target_type': 'log',\n",
    "        'action_time': ts_now.isoformat()\n",
    "    })\n",
    "\n",
    "# ③ comment\n",
    "for _, r in comment_df.iterrows():\n",
    "    ua.append({\n",
    "        'action_id'  : None,\n",
    "        'user_id'    : r['user_id'],\n",
    "        'target_id'  : r['log_id'],\n",
    "        'action_type': 'comment',\n",
    "        'target_type': 'log',\n",
    "        'action_time': r['create_at']\n",
    "    })\n",
    "\n",
    "user_actions_df = pd.DataFrame(ua)\n",
    "user_actions_df['action_id'] = range(70000, 70000 + len(user_actions_df))\n",
    "user_actions_df.to_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_e/user_actions.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

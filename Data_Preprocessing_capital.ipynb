{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIHubì—¬í–‰ê°ì •ë³´ âž¡ï¸ user í…Œì´ë¸” ë§¤í•‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User ID Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master ë°ì´í„° ì»¬ëŸ¼: ['TRAVELER_ID', 'RESIDENCE_SGG_CD', 'GENDER', 'AGE_GRP', 'EDU_NM', 'EDU_FNSH_SE', 'MARR_STTS', 'FAMILY_MEMB', 'JOB_NM', 'JOB_ETC', 'INCOME', 'HOUSE_INCOME', 'TRAVEL_TERM', 'TRAVEL_NUM', 'TRAVEL_LIKE_SIDO_1', 'TRAVEL_LIKE_SGG_1', 'TRAVEL_LIKE_SIDO_2', 'TRAVEL_LIKE_SGG_2', 'TRAVEL_LIKE_SIDO_3', 'TRAVEL_LIKE_SGG_3', 'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4', 'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8', 'TRAVEL_STATUS_RESIDENCE', 'TRAVEL_STATUS_DESTINATION', 'TRAVEL_STATUS_ACCOMPANY', 'TRAVEL_STATUS_YMD', 'TRAVEL_MOTIVE_1', 'TRAVEL_MOTIVE_2', 'TRAVEL_MOTIVE_3', 'TRAVEL_COMPANIONS_NUM']\n",
      "Travel ë°ì´í„° ì»¬ëŸ¼: ['TRAVEL_ID', 'TRAVEL_NM', 'TRAVELER_ID', 'TRAVEL_PURPOSE', 'TRAVEL_START_YMD', 'TRAVEL_END_YMD', 'MVMN_NM', 'TRAVEL_PERSONA', 'TRAVEL_MISSION', 'TRAVEL_MISSION_CHECK']\n",
      "Master ë°ì´í„° ê¸¸ì´: 2560\n",
      "Travel ë°ì´í„° ê¸¸ì´: 2560\n",
      "ë¬¸ìž ì œê±° í›„: 0    004720\n",
      "1    000914\n",
      "2    003564\n",
      "3    000396\n",
      "4    001890\n",
      "Name: TRAVELER_ID, dtype: object\n",
      "ì •ìˆ˜ ë³€í™˜ í›„: 0    4720\n",
      "1     914\n",
      "2    3564\n",
      "3     396\n",
      "4    1890\n",
      "Name: TRAVELER_ID, dtype: int64\n",
      "\n",
      "User í…Œì´ë¸” ìµœì¢… ê²°ê³¼:\n",
      "   user_id              email     name\n",
      "0     4720  e004720@gmail.com  e004720\n",
      "1      914  e000914@gmail.com  e000914\n",
      "2     3564  e003564@gmail.com  e003564\n",
      "3      396  e000396@gmail.com  e000396\n",
      "4     1890  e001890@gmail.com  e001890\n",
      "User í…Œì´ë¸” ê¸¸ì´: 2560\n",
      "ì¡°ì¸ í›„ Plan ë°ì´í„° ê¸¸ì´: 2560\n",
      "\n",
      "Plan í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸°:\n",
      "   plan_id  user_id start_date   end_date title purpose location\n",
      "0     1000        4 2023-04-30 2023-05-01   E03       3       ê²½ê¸°\n",
      "1     1001        6 2023-04-30 2023-05-02   E03      21       ê²½ê¸°\n",
      "2     1002        9 2023-04-29 2023-05-01   E03     2;4       ê²½ê¸°\n",
      "3     1003       10 2023-04-29 2023-05-01   E01     3;6       ì„œìš¸\n",
      "4     1004       11 2023-04-28 2023-05-01   E01    1;21       ì„œìš¸\n",
      "Plan í…Œì´ë¸” ê¸¸ì´: 2560\n",
      "\n",
      "ë°ì´í„° ì €ìž¥ ì¤‘...\n",
      "ì €ìž¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸\n",
    "# ì´ ì½”ë“œëŠ” ì›ë³¸ ë°ì´í„°ì…‹ì„ ìš°ë¦¬ ì‹œìŠ¤í…œì— ë§žê²Œ ë³€í™˜í•˜ëŠ” ìž‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "# 1. ì›ë³¸ ë°ì´í„° íŒŒì¼ ë¡œë“œ (ì—¬í–‰ê° Master, ì—¬í–‰ ë°ì´í„°)\n",
    "# 2. User í…Œì´ë¸” ìƒì„± - TRAVELER_IDì—ì„œ ë¬¸ìž ì œê±° í›„ ìˆ«ìžë§Œ ì¶”ì¶œí•˜ì—¬ user_id ìƒì„±\n",
    "# 3. Plan í…Œì´ë¸” ìƒì„± - Masterì™€ Travel ë°ì´í„° ì¡°ì¸ í›„ í•„ìš”í•œ í•„ë“œ ì¶”ì¶œ\n",
    "# 4. ìƒì„±ëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ìž¥\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ì½ê¸°\n",
    "df_master = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/capital/tn_traveller_master_ì—¬í–‰ê° Master_E.csv', encoding='utf-8')\n",
    "df_travel = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/capital/tn_travel_ì—¬í–‰_E.csv', encoding='utf-8')\n",
    "\n",
    "print(\"Master ë°ì´í„° ì»¬ëŸ¼:\", df_master.columns.tolist())\n",
    "print(\"Travel ë°ì´í„° ì»¬ëŸ¼:\", df_travel.columns.tolist())\n",
    "print(f\"Master ë°ì´í„° ê¸¸ì´: {len(df_master)}\")\n",
    "print(f\"Travel ë°ì´í„° ê¸¸ì´: {len(df_travel)}\")\n",
    "\n",
    "# 1. User í…Œì´ë¸” ë°ì´í„° ìƒì„± \n",
    "user_df = pd.DataFrame()\n",
    "\n",
    "# ë‹¨ê³„ë³„ë¡œ ë³€í™˜í•˜ë©´ì„œ í™•ì¸\n",
    "# 1ë‹¨ê³„: ë¬¸ìž ì œê±° í›„ ê²°ê³¼ í™•ì¸\n",
    "temp_id = df_master['TRAVELER_ID'].str.replace(r'[a-zA-Z]', '', regex=True)\n",
    "print(\"ë¬¸ìž ì œê±° í›„:\", temp_id.head())\n",
    "\n",
    "# 2ë‹¨ê³„: ìˆ«ìžë§Œ ë‚¨ì€ ê²ƒì„ ì •ìˆ˜ë¡œ ë³€í™˜\n",
    "temp_id = temp_id.astype(int)\n",
    "print(\"ì •ìˆ˜ ë³€í™˜ í›„:\", temp_id.head())\n",
    "\n",
    "# 3ë‹¨ê³„: ìµœì¢… ê³„ì‚° - user_id ìƒì„± ë°©ì‹ í†µì¼\n",
    "user_df['user_id'] = temp_id\n",
    "user_df['email'] = df_master['TRAVELER_ID'].astype(str) + '@gmail.com'\n",
    "user_df['name'] = df_master['TRAVELER_ID'] # ìž„ì‹œ ì´ë¦„\n",
    "\n",
    "print(\"\\nUser í…Œì´ë¸” ìµœì¢… ê²°ê³¼:\")\n",
    "print(user_df.head())\n",
    "print(f\"User í…Œì´ë¸” ê¸¸ì´: {len(user_df)}\")\n",
    "\n",
    "# 2. Plan í…Œì´ë¸” ë°ì´í„° ìƒì„±\n",
    "# Masterì™€ Travel ë°ì´í„° ì¡°ì¸\n",
    "df_plan = pd.merge(df_travel, df_master[['TRAVELER_ID', 'TRAVEL_STATUS_DESTINATION']], \n",
    "                   on='TRAVELER_ID', how='left')\n",
    "print(f\"ì¡°ì¸ í›„ Plan ë°ì´í„° ê¸¸ì´: {len(df_plan)}\")\n",
    "\n",
    "# ìƒˆë¡œìš´ plan_df ìƒì„±\n",
    "plan_df = pd.DataFrame()\n",
    "\n",
    "# plan_id ìƒì„±\n",
    "plan_df['plan_id'] = range(1000, 1000 + len(df_plan))\n",
    "\n",
    "# user_id ìƒì„± - user í…Œì´ë¸”ê³¼ ë™ì¼í•œ ë°©ì‹ ì‚¬ìš©\n",
    "traveler_ids = df_plan['TRAVELER_ID'].str.replace(r'[a-zA-Z]', '', regex=True).astype(int)\n",
    "plan_df['user_id'] = traveler_ids\n",
    "\n",
    "# ë‚ ì§œ ë³€í™˜ - to_date ëŒ€ì‹  to_datetime ì‚¬ìš©\n",
    "plan_df['start_date'] = pd.to_datetime(df_plan['TRAVEL_START_YMD'])\n",
    "plan_df['end_date'] = pd.to_datetime(df_plan['TRAVEL_END_YMD'])\n",
    "\n",
    "# ì¶”ê°€ í•„ë“œ ë³µì‚¬\n",
    "plan_df['title'] = df_plan['TRAVEL_NM']\n",
    "plan_df['purpose'] = df_plan['TRAVEL_PURPOSE']\n",
    "# location í•„ë“œ ì¶”ê°€\n",
    "plan_df['location'] = df_plan['TRAVEL_STATUS_DESTINATION']\n",
    "\n",
    "print(\"\\nPlan í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "print(plan_df.head())\n",
    "print(f\"Plan í…Œì´ë¸” ê¸¸ì´: {len(plan_df)}\")\n",
    "\n",
    "# ê²°ê³¼ CSV íŒŒì¼ë¡œ ì €ìž¥\n",
    "print(\"\\në°ì´í„° ì €ìž¥ ì¤‘...\")\n",
    "user_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/user.csv', index=False)\n",
    "plan_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/plan.csv', index=False)\n",
    "print(\"ì €ìž¥ ì™„ë£Œ!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Profile Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   profile_id  user_id nickname profile_image introduction  \\\n",
      "0           1        4  e000004          None         None   \n",
      "1           2        6  e000006          None         None   \n",
      "2           3        9  e000009          None         None   \n",
      "3           4       10  e000010          None         None   \n",
      "4           5       11  e000011          None         None   \n",
      "\n",
      "            created_at updated_at  \n",
      "0  2025-03-19 21:05:51       None  \n",
      "1  2025-03-19 21:05:51       None  \n",
      "2  2025-03-19 21:05:51       None  \n",
      "3  2025-03-19 21:05:51       None  \n",
      "4  2025-03-19 21:05:51       None  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‚¬ìš©ìž í”„ë¡œí•„ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ìž…ë‹ˆë‹¤.\n",
    "\n",
    "1. ê¸°ì¡´ì— ìƒì„±í•œ user.csv íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "2. ê° ì‚¬ìš©ìžì— ëŒ€í•œ í”„ë¡œí•„ ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:\n",
    "   - profile_id: ìˆœì°¨ì ìœ¼ë¡œ í• ë‹¹ (ì‹¤ì œ DBì—ì„œëŠ” auto_increment)\n",
    "   - user_id: user.csvì˜ user_idì™€ ë§¤í•‘\n",
    "   - nickname: userì˜ name ê°’ ì‚¬ìš©\n",
    "   - ê¸°íƒ€ í•„ë“œ: ì´ˆê¸°ê°’ ì„¤ì •\n",
    "3. ìƒì„±ëœ í”„ë¡œí•„ ë°ì´í„°ë¥¼ profile.csv íŒŒì¼ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë°ì´í„°ëŠ” ì‚¬ìš©ìž í”„ë¡œí•„ ê´€ë¦¬ ë° ì¶”ì²œ ì‹œìŠ¤í…œì˜ user_preferences í…Œì´ë¸” êµ¬ì„±ì— í™œìš©ë©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ê¸°ì¡´ì— ìƒì„±í•œ user_migrated.csv íŒŒì¼ ì½ê¸°\n",
    "user_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/user.csv', encoding='utf-8')\n",
    "profile_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/profile.csv', encoding='utf-8')\n",
    "\n",
    "# í˜„ìž¬ ì‹œê°ì„ created_at ê°’ìœ¼ë¡œ ì‚¬ìš© (ë¬¸ìžì—´ í˜•íƒœë¡œ ë³€í™˜)\n",
    "current_ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# profile í…Œì´ë¸”ì— ë§žê²Œ ë§¤í•‘: \n",
    "# profile_id: auto_increment íš¨ê³¼ë¥¼ ìœ„í•´ 1ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ í• ë‹¹ (ì‹¤ì œ DBì—ì„œëŠ” auto_increment ë˜ë¯€ë¡œ CSVì—ì„œ ì°¸ê³ ìš©)\n",
    "# user_id: user_migrated.csvì˜ user_id ì‚¬ìš©\n",
    "# nickname: userì˜ name ì»¬ëŸ¼ ì‚¬ìš©\n",
    "# profile_image, introduction, updated_at: null ì²˜ë¦¬ (ì—¬ê¸°ì„œëŠ” ë¹ˆ ë¬¸ìžì—´ë¡œ í‘œì‹œ)\n",
    "profile_df = pd.DataFrame()\n",
    "profile_df['profile_id'] = range(1, 1 + len(user_df))\n",
    "profile_df['user_id'] = user_df['user_id']\n",
    "profile_df['nickname'] = user_df['name']\n",
    "profile_df['profile_image'] = None   # ë˜ëŠ” ë¹ˆ ë¬¸ìžì—´: ''\n",
    "profile_df['introduction'] = None      # ë˜ëŠ” ë¹ˆ ë¬¸ìžì—´: ''\n",
    "profile_df['created_at'] = current_ts\n",
    "profile_df['updated_at'] = None        # ë˜ëŠ” ë¹ˆ ë¬¸ìžì—´: ''\n",
    "\n",
    "# ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "print(profile_df.head())\n",
    "\n",
    "# profile.csv íŒŒì¼ë¡œ ì €ìž¥\n",
    "profile_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/profile.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== plan.csv ì»¬ëŸ¼ ===\n",
      "['plan_id', 'user_id', 'start_date', 'end_date', 'title', 'transport_info', 'location', 'group_id', 'is_public', 'total_cost']\n",
      "=== ë°©ë¬¸ì§€ì •ë³´ ì»¬ëŸ¼ ===\n",
      "['VISIT_AREA_ID', 'TRAVEL_ID', 'VISIT_ORDER', 'VISIT_AREA_NM', 'VISIT_START_YMD', 'VISIT_END_YMD', 'ROAD_NM_ADDR', 'LOTNO_ADDR', 'X_COORD', 'Y_COORD', 'ROAD_NM_CD', 'LOTNO_CD', 'POI_ID', 'POI_NM', 'RESIDENCE_TIME_MIN', 'VISIT_AREA_TYPE_CD', 'REVISIT_YN', 'VISIT_CHC_REASON_CD', 'LODGING_TYPE_CD', 'DGSTFN', 'REVISIT_INTENTION', 'RCMDTN_INTENTION', 'SGG_CD']\n",
      "=== ë³‘í•© ê²°ê³¼ ìƒ˜í”Œ ===\n",
      "   VISIT_AREA_ID  TRAVEL_ID  VISIT_ORDER        VISIT_AREA_NM VISIT_START_YMD  \\\n",
      "0     2304300001  e_e000004            1                    ì§‘      2023-04-30   \n",
      "1     2304300002  e_e000004            2  í™”ì„± ê´€ê´‘ì—´ì°¨ ì•ˆë‚´ì†Œ ì—°ë¬´ëŒ€ ë§¤í‘œì†Œ      2023-04-30   \n",
      "2     2304300003  e_e000004            3                  ì°½ë£¡ë¬¸      2023-04-30   \n",
      "3     2304300004  e_e000004            4            ìˆ˜ì› í™”ì„± í™”í™ë¬¸      2023-04-30   \n",
      "4     2304300005  e_e000004            5                    ì§‘      2023-04-30   \n",
      "\n",
      "  VISIT_END_YMD             ROAD_NM_ADDR             LOTNO_ADDR     X_COORD  \\\n",
      "0    2023-04-30                      NaN                    NaN         NaN   \n",
      "1    2023-04-30  ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ì°½ë£¡ëŒ€ë¡œ103ë²ˆê¸¸ 20    ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ë§¤í–¥ë™ 3-32  127.023339   \n",
      "2    2023-04-30                      NaN         ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ë‚¨ìˆ˜ë™  127.025143   \n",
      "3    2023-04-30                      NaN  ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ë¶ìˆ˜ë™ 9000-1  127.017626   \n",
      "4    2023-05-01                      NaN                    NaN         NaN   \n",
      "\n",
      "     Y_COORD  ...  VISIT_AREA_TYPE_CD  REVISIT_YN VISIT_CHC_REASON_CD  \\\n",
      "0        NaN  ...                  21         NaN                 NaN   \n",
      "1  37.287878  ...                   2           N                10.0   \n",
      "2  37.287791  ...                   2           N                 1.0   \n",
      "3  37.287546  ...                   2           N                10.0   \n",
      "4        NaN  ...                  21         NaN                 NaN   \n",
      "\n",
      "  LODGING_TYPE_CD  DGSTFN  REVISIT_INTENTION RCMDTN_INTENTION        SGG_CD  \\\n",
      "0             NaN     NaN                NaN              NaN  4.159012e+09   \n",
      "1             NaN     4.0                3.0              4.0           NaN   \n",
      "2             NaN     4.0                4.0              4.0           NaN   \n",
      "3             NaN     4.0                3.0              3.0           NaN   \n",
      "4             NaN     NaN                NaN              NaN  4.159012e+09   \n",
      "\n",
      "   user_id  plan_id  \n",
      "0        4     1000  \n",
      "1        4     1000  \n",
      "2        4     1000  \n",
      "3        4     1000  \n",
      "4        4     1000  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "=== place.csv íŒŒì¼ë¡œ ì €ìž¥ ì™„ë£Œ ===\n",
      "   place_id  plan_id                       place  is_public  visit_date  \\\n",
      "0         1     1000                         NaN          1  2023-04-30   \n",
      "1         2     1000     ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ì°½ë£¡ëŒ€ë¡œ103ë²ˆê¸¸ 20          1  2023-04-30   \n",
      "2         3     1000              ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ë‚¨ìˆ˜ë™          1  2023-04-30   \n",
      "3         4     1000       ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ë¶ìˆ˜ë™ 9000-1          1  2023-04-30   \n",
      "4         5     1000                         NaN          1  2023-04-30   \n",
      "5         6     1001                         NaN          1  2023-04-30   \n",
      "6         7     1001             ì„œìš¸ ë™ëŒ€ë¬¸êµ¬ ì™•ì‚°ë¡œ 214          1  2023-04-30   \n",
      "7         8     1001       ê²½ê¸° ê°€í‰êµ° ì²­í‰ë©´ ì²­í‰ì—­ë¡œ 97-33          1  2023-04-30   \n",
      "8         9     1001        ê²½ê¸° ê°€í‰êµ° ì²­í‰ë©´ í•˜ì²œë¦¬ 158-2          1  2023-04-30   \n",
      "9        10     1001  ê²½ê¸° ë‚¨ì–‘ì£¼ì‹œ í™”ë„ì ê²½ì¶˜ë¡œ2696ë²ˆê¸¸ 4-15          1  2023-04-30   \n",
      "\n",
      "  place_cost  memo        lat         lon               p_name  p_order  \n",
      "0       None  None        NaN         NaN                    ì§‘        1  \n",
      "1       None  None  37.287878  127.023339  í™”ì„± ê´€ê´‘ì—´ì°¨ ì•ˆë‚´ì†Œ ì—°ë¬´ëŒ€ ë§¤í‘œì†Œ        2  \n",
      "2       None  None  37.287791  127.025143                  ì°½ë£¡ë¬¸        3  \n",
      "3       None  None  37.287546  127.017626            ìˆ˜ì› í™”ì„± í™”í™ë¬¸        4  \n",
      "4       None  None        NaN         NaN                    ì§‘        5  \n",
      "5       None  None        NaN         NaN                    ì§‘        1  \n",
      "6       None  None  37.581274  127.048636             ì²­ëŸ‰ë¦¬ì—­ ê²½ì¶˜ì„         2  \n",
      "7       None  None  37.735516  127.426623              ì²­í‰ì—­ ê²½ì¶˜ì„         3  \n",
      "8       None  None  37.745958  127.436200             ê²½ì¶˜ì„  ìžì „ê±°ê¸¸        4  \n",
      "9       None  None  37.673439  127.376025             ë² ì´ì»¤ë¦¬ ì‹œì–´í„°        5  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Aihubì—ì„œ ì œê³µí•˜ëŠ” 'tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_E.csv' ë°ì´í„°ë¥¼\n",
    "ìš°ë¦¬ ì‹œìŠ¤í…œì˜ plan.csvì™€ ì—°ê²°í•˜ì—¬, ëª¨ë“  TRAVEL_IDì— ëŒ€í•œ place í…Œì´ë¸” í˜•ì‹ CSVë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "íŠ¹ížˆ TRAVEL_ID('e_e000004') â†’ user_id(4)ì²˜ëŸ¼,\n",
    "TRAVEL_IDì—ì„œ 'e_e000' ì ‘ë‘ì‚¬ë¥¼ ì œê±°í•œ ë’¤ intë¡œ ë³€í™˜í•˜ì—¬ user_idë¥¼ êµ¬í•œ í›„,\n",
    "í•´ë‹¹ user_idë¥¼ plan.csvì™€ ë§¤í•‘(plan_id)í•˜ëŠ” ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ìŒ ìž‘ì—…ì„ í•©ë‹ˆë‹¤:\n",
    "1) plan.csv ë¡œë“œ (user_id, plan_id ì •ë³´ë¥¼ ê°–ê³  ìžˆì–´ì•¼ í•¨)\n",
    "2) ë°©ë¬¸ì§€ì •ë³´ íŒŒì¼ ë¡œë“œ (tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_E.csv)\n",
    "3) TRAVEL_IDì—ì„œ ì ‘ë‘ì‚¬ ì œê±° í›„ int ë³€í™˜ â†’ user_id\n",
    "4) plan.csvì™€ user_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ mergeí•˜ì—¬ plan_id í• ë‹¹\n",
    "5) place í…Œì´ë¸” ì»¬ëŸ¼(place, is_public, visit_date, lat, lon, p_name, p_order ë“±) ìƒì„±\n",
    "6) ê²°ê³¼ë¥¼ place_migrated.csvì— ì €ìž¥\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) plan.csv ë¡œë“œ\n",
    "df_plan = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/plan.csv', encoding='utf-8')\n",
    "print(\"=== plan.csv ì»¬ëŸ¼ ===\")\n",
    "print(df_plan.columns.tolist())\n",
    "\n",
    "# ì—¬ê¸°ì„œ df_planì—ëŠ” ìµœì†Œí•œ 'user_id', 'plan_id'ê°€ ìžˆë‹¤ê³  ê°€ì •\n",
    "# ì˜ˆ) user_id=4, plan_id=1000\n",
    "\n",
    "# 2) ë°©ë¬¸ì§€ì •ë³´ íŒŒì¼ ë¡œë“œ\n",
    "df_v = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/capital/tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_E.csv', encoding='utf-8')\n",
    "print(\"=== ë°©ë¬¸ì§€ì •ë³´ ì»¬ëŸ¼ ===\")\n",
    "print(df_v.columns.tolist())\n",
    "\n",
    "# 3) TRAVEL_ID -> user_id ë³€í™˜\n",
    "#    ì˜ˆ: 'e_e000004' -> '000004' -> 4, 'f_f000007' -> '000007' -> 7\n",
    "def convert_travel_id_to_user_id(travel_id: str) -> int:\n",
    "    # 1) 'e_e' ì œê±°\n",
    "    # 2) ë‚¨ì€ ë¬¸ìžì—´ì„ intë¡œ ë³€í™˜\n",
    "    #    travel_id ì˜ˆ: 'e_e000004' -> re.sub(r'^[a-z]_[a-z]', '', 'e_e000004') => '000004' -> int('000004') => 4\n",
    "    import re\n",
    "    cleaned_id = re.sub(r'^[a-z]_[a-z]', '', travel_id)\n",
    "    return int(cleaned_id)\n",
    "\n",
    "# ìƒˆ ì»¬ëŸ¼ user_idë¥¼ ë§Œë“¤ì–´ì„œ TRAVEL_IDë¥¼ ë³€í™˜\n",
    "df_v['user_id'] = df_v['TRAVEL_ID'].apply(convert_travel_id_to_user_id)\n",
    "\n",
    "# 4) plan.csvì™€ user_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ merge â†’ plan_id í• ë‹¹\n",
    "#    plan.csvì—ëŠ” user_idê°€ ìžˆê³ , ì´ë¥¼ í†µí•´ plan_idë¥¼ ê°€ì ¸ì˜´\n",
    "df_plan_map = df_plan[['user_id', 'plan_id']].drop_duplicates()\n",
    "df_merged = pd.merge(df_v, df_plan_map, on='user_id', how='inner')\n",
    "\n",
    "print(\"=== ë³‘í•© ê²°ê³¼ ìƒ˜í”Œ ===\")\n",
    "print(df_merged.head())\n",
    "\n",
    "# 5) place í…Œì´ë¸”ìš© DataFrame ìƒì„±\n",
    "#    place.csvê°€ ì´ë¯¸ ì¡´ìž¬í•œë‹¤ë©´, ê·¸ êµ¬ì¡°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ë„ ìžˆê³ ,\n",
    "#    ì—¬ê¸°ì„œëŠ” ë¹ˆ ë°ì´í„°í”„ë ˆìž„ì— ì§ì ‘ ì»¬ëŸ¼ì„ ë§Œë“¤ì–´ ì‚¬ìš©\n",
    "place_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/place.csv', encoding='utf-8')\n",
    "\n",
    "# place_id : ìž„ì‹œë¡œ 1ë¶€í„° ë¶€ì—¬ (ì‹¤ì œ DBì—ì„œëŠ” AUTO_INCREMENT)\n",
    "place_df['place_id'] = range(1, 1 + len(df_merged))\n",
    "\n",
    "# plan_id : df_merged['plan_id']\n",
    "place_df['plan_id'] = df_merged['plan_id']\n",
    "\n",
    "# place : ë„ë¡œëª… ì£¼ì†Œ(ROAD_NM_ADDR)ê°€ ìžˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì§€ë²ˆì£¼ì†Œ(LOTNO_ADDR)\n",
    "place_df['place'] = np.where(\n",
    "    df_merged['ROAD_NM_ADDR'].notnull() & (df_merged['ROAD_NM_ADDR'] != ''),\n",
    "    df_merged['ROAD_NM_ADDR'],\n",
    "    df_merged['LOTNO_ADDR']\n",
    ")\n",
    "\n",
    "# is_public : ì „ë¶€ 1ë¡œ ì„¤ì •\n",
    "place_df['is_public'] = 1\n",
    "\n",
    "# visit_date : VISIT_START_YMD\n",
    "place_df['visit_date'] = df_merged['VISIT_START_YMD']\n",
    "\n",
    "# place_cost, memo : null(None)ë¡œ ì²˜ë¦¬\n",
    "place_df['place_cost'] = None\n",
    "place_df['memo'] = None\n",
    "\n",
    "# lat, lon : Y_COORD(ìœ„ë„), X_COORD(ê²½ë„)\n",
    "place_df['lat'] = df_merged['Y_COORD']\n",
    "place_df['lon'] = df_merged['X_COORD']\n",
    "\n",
    "# p_name : ë°©ë¬¸ì§€ëª…(VISIT_AREA_NM)\n",
    "place_df['p_name'] = df_merged['VISIT_AREA_NM']\n",
    "\n",
    "# p_order : VISIT_ORDER (ì •ìˆ˜ ë³€í™˜)\n",
    "place_df['p_order'] = df_merged['VISIT_ORDER'].astype(int)\n",
    "\n",
    "# 6) ê²°ê³¼ ì €ìž¥\n",
    "place_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/place.csv', index=False, encoding='utf-8')\n",
    "print(\"=== place.csv íŒŒì¼ë¡œ ì €ìž¥ ì™„ë£Œ ===\")\n",
    "\n",
    "# ìƒ˜í”Œ í™•ì¸\n",
    "print(place_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³€ê²½ëœ ë°ì´í„° ìƒ˜í”Œ:\n",
      "     place_id  plan_id           place  is_public  visit_date  place_cost  \\\n",
      "16         17     1002            í‘¸ë¥´ì§€ì˜¤          0  2023-04-29         NaN   \n",
      "37         38     1003             NaN          0  2023-04-29         NaN   \n",
      "96         97     1009            ì•„ì´íŒŒí¬          0  2023-04-29         NaN   \n",
      "97         98     3554            ì•„ì´íŒŒí¬          0  2023-04-29         NaN   \n",
      "155       156     1016      ê°€ì˜¨ëˆ„ë¦¬ë¹Œ 101ë™          0  2023-04-30         NaN   \n",
      "344       345     1032             ìƒ1ë™          0  2023-05-27         NaN   \n",
      "367       368     1033       ìƒ1ë™ 392ë²ˆì§€          0  2023-05-31         NaN   \n",
      "369       370     1033  ê²½ê¸°ë„ ë¶€ì²œì‹œ ì¤‘ë™1180          0  2023-06-01         NaN   \n",
      "380       381     1033      ìƒ 1ë™ 392ë²ˆì§€          0  2023-06-01         NaN   \n",
      "382       383     1033          ì¤‘ë™1180          0  2023-06-02         NaN   \n",
      "\n",
      "     memo  lat  lon    p_name  p_order  \n",
      "16    NaN  NaN  NaN   ì¹œêµ¬ ì¹œì§€ ì§‘        1  \n",
      "37    NaN  NaN  NaN      ì¹œêµ¬ ì§‘       10  \n",
      "96    NaN  NaN  NaN   ì¹œêµ¬ ì¹œì§€ ì§‘        1  \n",
      "97    NaN  NaN  NaN   ì¹œêµ¬ ì¹œì§€ ì§‘        1  \n",
      "155   NaN  NaN  NaN   ì¹œêµ¬ ì¹œì§€ ì§‘        1  \n",
      "344   NaN  NaN  NaN      ì¹œêµ¬ ì§‘       12  \n",
      "367   NaN  NaN  NaN   ì¹œì§€ ì§‘ ìˆ™ë°•        5  \n",
      "369   NaN  NaN  NaN   ì¹œêµ¬ ì§‘ ë°©ë¬¸        7  \n",
      "380   NaN  NaN  NaN  ì¹œì§€ ì§‘(ìˆ™ë°•)       18  \n",
      "382   NaN  NaN  NaN      ì¹œêµ¬ ì§‘       20  \n",
      "=== ì§‘ ê´€ë ¨ í‚¤ì›Œë“œ(35ê°œ)ê°€ í¬í•¨ëœ ë°ì´í„° ê³µê°œì—¬ë¶€ ë³€ê²½ ë° ì €ìž¥ ì™„ë£Œ ===\n",
      "ì´ 346ê°œ ë ˆì½”ë“œê°€ ë¹„ê³µê°œë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "p_nameì— ì§‘ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„°ì˜ ê³µê°œì—¬ë¶€ Falseë¡œ ë³€ê²½\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1) place.csv ë¡œë“œ\n",
    "place_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/place.csv', encoding='utf-8')\n",
    "\n",
    "# 2) p_nameì— ì§‘ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„° ì°¾ê¸°\n",
    "home_keywords = [\n",
    "    'ê´‘ì£¼ ì§‘', 'ë”¸ ì§‘ ë°©ë¬¸', 'ê´‘ëª…ì‚¬ê±°ë¦¬ì—­ ê·¼ì²˜ ì¹œêµ¬ë„¤ ì§‘', 'ë§í¬ë™ 527-9 ì§‘', 'ì§‘ ê°•ë‚¨ì ', 'ë™í–‰ìž ì§‘ì—ì„œ ì—¬í–‰ ì¢…ë£Œ', 'ì§‘ ê·¼ì²˜', 'ì™¸í• ë¨¸ë‹ˆ ì§‘', 'ì–´ë¨¸ë‹ˆ ì§‘', 'ê³ ëª¨ì§‘', 'ë‚¨ì•½ì£¼ ê±°ì£¼ ì¹œêµ¬ë„¤ ì§‘', 'í• ë¨¸ë‹ˆ ì§‘', 'ì§‘ ë„ì°©', 'ê°€ì¡± ì§‘', 'ë³¸ê°€ ì§‘ ë„ì°©', 'ì¹œêµ¬ë„¤ ì§‘','ì¹œêµ¬ ì§‘', 'ì§€ì¸ ì§‘', 'ì¹œêµ¬ ì¹œì§€ ì§‘', 'ì¹œì§€ ì§‘', 'ë¶€ëª¨ë‹˜ ì§‘', \n",
    "    'ì—°ë‚¨ ê³ ì„ ì§‘', 'ìš°ë¦¬ ì§‘', 'ì¹œì§€ ëŒ', 'ì—¬ìžì¹œêµ¬ ì§‘', 'ì—¬ìžì¹œêµ¬ í• ë¨¸ë‹ˆ ì§‘',\n",
    "    'í• ë¨¸ë‹ˆë„¤ ì§‘', 'ì§€ì¸ ì§‘ ë°©ë¬¸', 'ë³¸ì¸ ì§‘', 'ì¹œê°€ ì§‘', 'ë™ìƒ ì§‘', \n",
    "    'ì¹œì²™ ì§‘', 'ì—„ë§ˆ ì§‘', 'í˜• ì§‘', 'ê³ í–¥ ì§‘'\n",
    "]\n",
    "\n",
    "# ëª¨ë“  í‚¤ì›Œë“œì— ëŒ€í•œ ì¡°ê±´ ìƒì„±\n",
    "home_places = place_df['p_name'].str.contains('|'.join(home_keywords), case=False, na=False)\n",
    "\n",
    "# 3) ê³µê°œì—¬ë¶€ ë³€ê²½ - ì§‘ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„°ë§Œ 0ìœ¼ë¡œ ë³€ê²½\n",
    "place_df.loc[home_places, 'is_public'] = 0\n",
    "place_df.loc[place_df['p_name'] == 'ì§‘', 'is_public'] = 0\n",
    "\n",
    "# ë³€ê²½ëœ ë°ì´í„° í™•ì¸\n",
    "print(\"ë³€ê²½ëœ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "print(place_df[home_places].head(10) if any(home_places) else \"ë³€ê²½ëœ ë°ì´í„° ì—†ìŒ\")\n",
    "\n",
    "# 4) ê²°ê³¼ ì €ìž¥\n",
    "place_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/place.csv', index=False, encoding='utf-8')\n",
    "print(f\"=== ì§‘ ê´€ë ¨ í‚¤ì›Œë“œ({len(home_keywords)}ê°œ)ê°€ í¬í•¨ëœ ë°ì´í„° ê³µê°œì—¬ë¶€ ë³€ê²½ ë° ì €ìž¥ ì™„ë£Œ ===\")\n",
    "print(f\"ì´ {home_places.sum()}ê°œ ë ˆì½”ë“œê°€ ë¹„ê³µê°œë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== plan.csv === ['plan_id', 'user_id', 'start_date', 'end_date', 'title', 'transport_info', 'location', 'group_id', 'is_public', 'total_cost']\n",
      "=== place.csv === ['place_id', 'plan_id', 'place', 'is_public', 'visit_date', 'place_cost', 'memo', 'lat', 'lon', 'p_name', 'p_order']\n",
      "=== visit_area_info.csv === ['VISIT_AREA_ID', 'TRAVEL_ID', 'VISIT_ORDER', 'VISIT_AREA_NM', 'VISIT_START_YMD', 'VISIT_END_YMD', 'ROAD_NM_ADDR', 'LOTNO_ADDR', 'X_COORD', 'Y_COORD', 'ROAD_NM_CD', 'LOTNO_CD', 'POI_ID', 'POI_NM', 'RESIDENCE_TIME_MIN', 'VISIT_AREA_TYPE_CD', 'REVISIT_YN', 'VISIT_CHC_REASON_CD', 'LODGING_TYPE_CD', 'DGSTFN', 'REVISIT_INTENTION', 'RCMDTN_INTENTION', 'SGG_CD']\n",
      "plan.csv í–‰ ìˆ˜: 2560\n",
      "place.csv í–‰ ìˆ˜: 21495\n",
      "visit_area_info.csv í–‰ ìˆ˜: 21384\n",
      "=== df_plan_place ìƒ˜í”Œ ===\n",
      "   place_id  plan_id                    place  is_public  visit_date  \\\n",
      "0         1     1000                      NaN          0  2023-04-30   \n",
      "1         2     1000  ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ì°½ë£¡ëŒ€ë¡œ103ë²ˆê¸¸ 20          1  2023-04-30   \n",
      "2         3     1000           ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ë‚¨ìˆ˜ë™          1  2023-04-30   \n",
      "3         4     1000    ê²½ê¸° ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ë¶ìˆ˜ë™ 9000-1          1  2023-04-30   \n",
      "4         5     1000                      NaN          0  2023-04-30   \n",
      "\n",
      "   place_cost  memo        lat         lon               p_name  p_order  \\\n",
      "0         NaN   NaN        NaN         NaN                    ì§‘        1   \n",
      "1         NaN   NaN  37.287878  127.023339  í™”ì„± ê´€ê´‘ì—´ì°¨ ì•ˆë‚´ì†Œ ì—°ë¬´ëŒ€ ë§¤í‘œì†Œ        2   \n",
      "2         NaN   NaN  37.287791  127.025143                  ì°½ë£¡ë¬¸        3   \n",
      "3         NaN   NaN  37.287546  127.017626            ìˆ˜ì› í™”ì„± í™”í™ë¬¸        4   \n",
      "4         NaN   NaN        NaN         NaN                    ì§‘        5   \n",
      "\n",
      "   user_id  start_date    end_date  \n",
      "0        4  2023-04-30  2023-05-01  \n",
      "1        4  2023-04-30  2023-05-01  \n",
      "2        4  2023-04-30  2023-05-01  \n",
      "3        4  2023-04-30  2023-05-01  \n",
      "4        4  2023-04-30  2023-05-01  \n",
      "df_plan_place í–‰ ìˆ˜: 21495\n",
      "df_plan_place NaN ê°’ í™•ì¸: \n",
      "place_id          0\n",
      "plan_id           0\n",
      "place          1456\n",
      "is_public         0\n",
      "visit_date        0\n",
      "place_cost    21495\n",
      "memo          21495\n",
      "lat            6927\n",
      "lon            6927\n",
      "p_name            0\n",
      "p_order           0\n",
      "user_id           0\n",
      "start_date        0\n",
      "end_date          0\n",
      "dtype: int64\n",
      "=== p_name ê³ ìœ ê°’ 10ê°œ ìƒ˜í”Œ ===\n",
      "['ì§‘' 'í™”ì„± ê´€ê´‘ì—´ì°¨ ì•ˆë‚´ì†Œ ì—°ë¬´ëŒ€ ë§¤í‘œì†Œ' 'ì°½ë£¡ë¬¸' 'ìˆ˜ì› í™”ì„± í™”í™ë¬¸' 'ì²­ëŸ‰ë¦¬ì—­ ê²½ì¶˜ì„ ' 'ì²­í‰ì—­ ê²½ì¶˜ì„ '\n",
      " 'ê²½ì¶˜ì„  ìžì „ê±°ê¸¸' 'ë² ì´ì»¤ë¦¬ ì‹œì–´í„°' 'ë°±ì•”ì²œ' 'ìžì‹œì˜¤ ìž£ ì£¼ê¾¸ë¯¸']\n",
      "=== VISIT_AREA_NM ê³ ìœ ê°’ 10ê°œ ìƒ˜í”Œ ===\n",
      "['ì§‘' 'í™”ì„± ê´€ê´‘ì—´ì°¨ ì•ˆë‚´ì†Œ ì—°ë¬´ëŒ€ ë§¤í‘œì†Œ' 'ì°½ë£¡ë¬¸' 'ìˆ˜ì› í™”ì„± í™”í™ë¬¸' 'ì²­ëŸ‰ë¦¬ì—­ ê²½ì¶˜ì„ ' 'ì²­í‰ì—­ ê²½ì¶˜ì„ '\n",
      " 'ê²½ì¶˜ì„  ìžì „ê±°ê¸¸' 'ë² ì´ì»¤ë¦¬ ì‹œì–´í„°' 'ë°±ì•”ì²œ' 'ìžì‹œì˜¤ ìž£ ì£¼ê¾¸ë¯¸']\n",
      "ê³µê°œ ìž¥ì†Œ ìˆ˜: 16511, ë¹„ê³µê°œ ìž¥ì†Œ ìˆ˜: 4984\n",
      "=== log_df NaN ê°’ í™•ì¸ ===\n",
      "log_id          0\n",
      "is_public       0\n",
      "user_id      4984\n",
      "plan_id      4984\n",
      "place_id     4984\n",
      "comment      4984\n",
      "create_at    4984\n",
      "dtype: int64\n",
      "ì´ ë ˆì½”ë“œ: 21495, ê³µê°œ(is_public=1): 16511, ë¹„ê³µê°œ(is_public=0): 4984\n",
      "=== log.csv ìƒì„± ì™„ë£Œ ===\n",
      "\n",
      "=== ê³µê°œ ë°ì´í„° ìƒ˜í”Œ ===\n",
      "   log_id  is_public  user_id  plan_id  place_id  \\\n",
      "1       2          1      4.0   1000.0       2.0   \n",
      "2       3          1      4.0   1000.0       3.0   \n",
      "3       4          1      4.0   1000.0       4.0   \n",
      "6       7          1      6.0   1001.0       7.0   \n",
      "7       8          1      6.0   1001.0       8.0   \n",
      "\n",
      "                                  comment   create_at  \n",
      "1  [í™”ì„± ê´€ê´‘ì—´ì°¨ ì•ˆë‚´ì†Œ ì—°ë¬´ëŒ€ ë§¤í‘œì†Œ] ë§Œì¡±ë„=4.0, ìž¬ë°©ë¬¸=3.0  2023-04-30  \n",
      "2                  [ì°½ë£¡ë¬¸] ë§Œì¡±ë„=4.0, ìž¬ë°©ë¬¸=4.0  2023-04-30  \n",
      "3            [ìˆ˜ì› í™”ì„± í™”í™ë¬¸] ë§Œì¡±ë„=4.0, ìž¬ë°©ë¬¸=3.0  2023-04-30  \n",
      "6             [ì²­ëŸ‰ë¦¬ì—­ ê²½ì¶˜ì„ ] ë§Œì¡±ë„=5.0, ìž¬ë°©ë¬¸=5.0  2023-04-30  \n",
      "7              [ì²­í‰ì—­ ê²½ì¶˜ì„ ] ë§Œì¡±ë„=5.0, ìž¬ë°©ë¬¸=5.0  2023-04-30  \n",
      "\n",
      "=== ë¹„ê³µê°œ ë°ì´í„° ìƒ˜í”Œ ===\n",
      "    log_id  is_public  user_id  plan_id  place_id comment create_at\n",
      "0        1          0      NaN      NaN       NaN     NaN       NaN\n",
      "4        5          0      NaN      NaN       NaN     NaN       NaN\n",
      "5        6          0      NaN      NaN       NaN     NaN       NaN\n",
      "15      16          0      NaN      NaN       NaN     NaN       NaN\n",
      "16      17          0      NaN      NaN       NaN     NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” plan.csv, place.csv, ê·¸ë¦¬ê³  AIHubì˜ visit_area_info.csv(ë°©ë¬¸ì§€ì •ë³´) íŒŒì¼ì„\n",
    "í•¨ê»˜ í™œìš©í•˜ì—¬ 'log.csv'(ê°€ìƒì˜ ì—¬í–‰ ê¸°ë¡ í…Œì´ë¸”)ì„ ë§Œë“¤ì–´ë‚´ëŠ” ì˜ˆì‹œìž…ë‹ˆë‹¤.\n",
    "\n",
    "[ëª©í‘œ]\n",
    "1) plan.csv + place.csvë¥¼ mergeí•´ì„œ (user_id, plan_id, p_name, visit_date ë“±) ì •ë³´ë¥¼ í™•ë³´\n",
    "2) place.csv + visit_area_info.csvë¥¼ mergeí•´ì„œ AIHubì˜ ì¶”ê°€ ì •ë³´(DGSTFN, REVISIT_INTENTION ë“±)ë¥¼ ê°€ì ¸ì˜´\n",
    "3) (1)ê³¼ (2)ì˜ ë³‘í•© ê²°ê³¼ì—ì„œ log í…Œì´ë¸”ì— í•„ìš”í•œ ì»¬ëŸ¼(log_id, user_id, plan_id, comment, create_at, is_public ë“±)ì„ ìƒì„±\n",
    "4) ìµœì¢… ê²°ê³¼ë¥¼ log.csv ë¡œ ì €ìž¥\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) CSV íŒŒì¼ ë¡œë“œ\n",
    "df_plan = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/plan.csv', encoding='utf-8')\n",
    "df_place = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/place.csv', encoding='utf-8')\n",
    "df_visit = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/capital/tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_E.csv', encoding='utf-8')  # AIHub ë°©ë¬¸ì§€ì •ë³´\n",
    "\n",
    "print(\"=== plan.csv ===\", df_plan.columns.tolist())\n",
    "print(\"=== place.csv ===\", df_place.columns.tolist())\n",
    "print(\"=== visit_area_info.csv ===\", df_visit.columns.tolist())\n",
    "\n",
    "# ë””ë²„ê¹…ì„ ìœ„í•œ ì •ë³´ ì¶œë ¥\n",
    "print(f\"plan.csv í–‰ ìˆ˜: {len(df_plan)}\")\n",
    "print(f\"place.csv í–‰ ìˆ˜: {len(df_place)}\")\n",
    "print(f\"visit_area_info.csv í–‰ ìˆ˜: {len(df_visit)}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) plan + place ë³‘í•©\n",
    "#    place í…Œì´ë¸”ì—ëŠ” plan_idê°€ ìžˆê³ , plan í…Œì´ë¸”ì—ëŠ” (plan_id, user_id, start_date, end_date ë“±)ì´ ìžˆìŒ\n",
    "#    -> í•˜ë‚˜ì˜ DFë¡œ í•©ì³ì„œ (user_id, plan_id, p_name, place, visit_date, ...) ë“±ì„ ê°€ì§„ë‹¤\n",
    "# ------------------------------------------------------------------------------\n",
    "df_plan_place = pd.merge(\n",
    "    df_place,\n",
    "    df_plan[['plan_id', 'user_id', 'start_date', 'end_date']],\n",
    "    on='plan_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# df_plan_placeì—ëŠ” user_id(í”Œëžœ ìž‘ì„±ìž), p_name(ë°©ë¬¸ì§€ëª…), visit_date ë“± ì •ë³´ê°€ í¬í•¨ë¨\n",
    "print(\"=== df_plan_place ìƒ˜í”Œ ===\")\n",
    "print(df_plan_place.head())\n",
    "print(f\"df_plan_place í–‰ ìˆ˜: {len(df_plan_place)}\")\n",
    "print(f\"df_plan_place NaN ê°’ í™•ì¸: \\n{df_plan_place.isna().sum()}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3-1) ë””ë²„ê¹…: VISIT_AREA_NMê³¼ p_name ê°’ í™•ì¸\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"=== p_name ê³ ìœ ê°’ 10ê°œ ìƒ˜í”Œ ===\")\n",
    "print(df_plan_place['p_name'].dropna().unique()[:10])\n",
    "\n",
    "print(\"=== VISIT_AREA_NM ê³ ìœ ê°’ 10ê°œ ìƒ˜í”Œ ===\")\n",
    "print(df_visit['VISIT_AREA_NM'].dropna().unique()[:10])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3-2) place + visit_area_info ë³‘í•© (ì§ì ‘ ë§¤í•‘ ì—†ì´ ì¼ë‹¨ place.csvë§Œ ì‚¬ìš©)\n",
    "# ------------------------------------------------------------------------------\n",
    "# ì¼ë‹¨ AIHubì˜ ë°©ë¬¸ì§€ì •ë³´ë¥¼ ì°¸ê³ í•˜ì§€ ì•Šê³ , place.csvì˜ ë°ì´í„°ë§Œ ì‚¬ìš©í•´ì„œ log ìƒì„±\n",
    "df_plan_place_ai = df_plan_place.copy()\n",
    "\n",
    "# ë°©ë¬¸ì§€ ë§Œì¡±ë„ì™€ ìž¬ë°©ë¬¸ ì˜í–¥ ìƒì„±\n",
    "import random\n",
    "df_plan_place_ai['DGSTFN'] = df_visit['DGSTFN']\n",
    "df_plan_place_ai['REVISIT_INTENTION'] = df_visit['REVISIT_INTENTION']\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) log í…Œì´ë¸”ìš© DataFrame êµ¬ì„±\n",
    "#    -> ìš”êµ¬ì‚¬í•­: place.csvì˜ is_publicì´ 0ì¸ ë°ì´í„°ëŠ” logë¥¼ ë§Œë“¤ì§€ ì•Šê³ , \n",
    "#       ìƒì„±ëœ logëŠ” isPublicë§Œ 0ìœ¼ë¡œ ì„¤ì •í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” nullë¡œ ì„¤ì •\n",
    "# ------------------------------------------------------------------------------\n",
    "# ë¨¼ì € is_publicì´ 1ì¸ ìž¥ì†Œë§Œ í•„í„°ë§ (ê³µê°œëœ ìž¥ì†Œë§Œ) - ì›ë³¸ ë°ì´í„°ì—ì„œ í™•ì¸\n",
    "place_public_count = df_plan_place_ai[df_plan_place_ai['is_public'] == 1].shape[0]\n",
    "place_private_count = df_plan_place_ai[df_plan_place_ai['is_public'] == 0].shape[0]\n",
    "print(f\"ê³µê°œ ìž¥ì†Œ ìˆ˜: {place_public_count}, ë¹„ê³µê°œ ìž¥ì†Œ ìˆ˜: {place_private_count}\")\n",
    "\n",
    "# ê³µê°œìš© ë¡œê·¸ë§Œ ìƒì„±\n",
    "log_df = pd.DataFrame()\n",
    "\n",
    "# log_id ìƒì„±: ëª¨ë“  ìž¥ì†Œ ë°ì´í„°ì— ëŒ€í•´ ì¼ë ¨ë²ˆí˜¸ ë¶€ì—¬\n",
    "log_df['log_id'] = range(1, 1 + len(df_plan_place_ai))\n",
    "\n",
    "# is_public: ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ placeì˜ is_public ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "log_df['is_public'] = df_plan_place_ai['is_public']\n",
    "\n",
    "# placeì˜ is_public ê°’ì— ë”°ë¼ ì„ íƒì ìœ¼ë¡œ ë°ì´í„° ì±„ìš°ê¸°\n",
    "# is_public = 1ì¸ ìž¥ì†Œ ë°ì´í„°ë§Œ ë‚´ìš© ì±„ìš°ê¸°\n",
    "# is_public = 0ì¸ ìž¥ì†Œ ë°ì´í„°ëŠ” NaNìœ¼ë¡œ ë‘ê¸°\n",
    "is_public_mask = df_plan_place_ai['is_public'] == 1\n",
    "\n",
    "# user_id, plan_id, place_id ì±„ìš°ê¸° - ê³µê°œ ë°ì´í„°ë§Œ\n",
    "log_df['user_id'] = np.where(is_public_mask, df_plan_place_ai['user_id'], np.nan)\n",
    "log_df['plan_id'] = np.where(is_public_mask, df_plan_place_ai['plan_id'], np.nan)\n",
    "log_df['place_id'] = np.where(is_public_mask, df_plan_place_ai['place_id'], np.nan)\n",
    "\n",
    "# NaN ê°’ì´ í¬í•¨ë˜ì–´ ìžˆìœ¼ë©´ intë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì €ìž¥ ì „ì— í•„ìš”í•œ ë¶€ë¶„ë§Œ intë¡œ ë³€í™˜\n",
    "# ê³µê°œ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "mask = log_df['is_public'] == 1\n",
    "if mask.any():\n",
    "    log_df.loc[mask, 'user_id'] = log_df.loc[mask, 'user_id'].astype(int)\n",
    "    log_df.loc[mask, 'plan_id'] = log_df.loc[mask, 'plan_id'].astype(int)\n",
    "    log_df.loc[mask, 'place_id'] = log_df.loc[mask, 'place_id'].astype(int)\n",
    "\n",
    "# comment ìƒì„± - ê³µê°œ ë°ì´í„°ë§Œ\n",
    "def make_comment(row):\n",
    "    if row['is_public'] != 1:\n",
    "        return np.nan\n",
    "        \n",
    "    p_name = row.get('p_name', 'ì•Œ ìˆ˜ ì—†ëŠ” ìž¥ì†Œ')\n",
    "    dgs = row.get('DGSTFN', np.nan)\n",
    "    rvt = row.get('REVISIT_INTENTION', np.nan)\n",
    "    \n",
    "    # Noneê°’ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë¬¸ìžì—´ ë³€í™˜:\n",
    "    if pd.isna(dgs):\n",
    "        dgs = 'N/A'\n",
    "    if pd.isna(rvt):\n",
    "        rvt = 'N/A'\n",
    "    \n",
    "    if pd.isna(p_name) or p_name == '':\n",
    "        p_name = 'ì•Œ ìˆ˜ ì—†ëŠ” ìž¥ì†Œ'\n",
    "    \n",
    "    return f\"[{p_name}] ë§Œì¡±ë„={dgs}, ìž¬ë°©ë¬¸={rvt}\"\n",
    "\n",
    "log_df['comment'] = df_plan_place_ai.apply(make_comment, axis=1)\n",
    "\n",
    "# create_at: ê³µê°œ ë°ì´í„°ë§Œ ë‚ ì§œ ì‚¬ìš©, ë¹„ê³µê°œëŠ” NaN\n",
    "log_df['create_at'] = np.where(is_public_mask, df_plan_place_ai['visit_date'], np.nan)\n",
    "\n",
    "\n",
    "# NaN ê°’ í™•ì¸\n",
    "print(\"=== log_df NaN ê°’ í™•ì¸ ===\")\n",
    "print(log_df.isna().sum())\n",
    "print(f\"ì´ ë ˆì½”ë“œ: {len(log_df)}, ê³µê°œ(is_public=1): {log_df['is_public'].sum()}, ë¹„ê³µê°œ(is_public=0): {len(log_df) - log_df['is_public'].sum()}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) ê²°ê³¼ ì €ìž¥\n",
    "# ------------------------------------------------------------------------------\n",
    "log_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/log.csv', index=False, encoding='utf-8')\n",
    "print(\"=== log.csv ìƒì„± ì™„ë£Œ ===\")\n",
    "# ê³µê°œ/ë¹„ê³µê°œ ë°ì´í„° ê°ê° 5ê°œì”© ì¶œë ¥\n",
    "print(\"\\n=== ê³µê°œ ë°ì´í„° ìƒ˜í”Œ ===\")\n",
    "print(log_df[log_df['is_public'] == 1].head(5))\n",
    "print(\"\\n=== ë¹„ê³µê°œ ë°ì´í„° ìƒ˜í”Œ ===\")\n",
    "print(log_df[log_df['is_public'] == 0].head(5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì„±ëœ follow ìˆ˜: 12682 / ì‚¬ìš©ìž ìˆ˜: 2560\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "user.csvë¥¼ ì½ì–´ ê°€ìƒì˜ follow.csvë¥¼ ìƒì„±í•œë‹¤.\n",
    " - ë¹„ìŠ·í•œ ì§€ì—­/ìŠ¤íƒ€ì¼ì„ ì„ í˜¸í•˜ë©´ íŒ”ë¡œìš° í™•ë¥ ì„ ë†’ìž„\n",
    " - ì¼ë¶€ ì‚¬ìš©ìžë¥¼ 'ì¸í”Œë£¨ì–¸ì„œ'ë¡œ ì§€ì •í•´ ë§Žì´ íŒ”ë¡œìš° ë°›ìŒ\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------------\n",
    "# í•˜ì´í¼ íŒŒë¼ë¯¸í„°\n",
    "# --------------------\n",
    "AVG_FOLLOW_OUT = 5          # í•œ ì‚¬ìš©ìžê°€ íŒ”ë¡œìš°í•˜ëŠ” í‰ê·  ìˆ˜\n",
    "INFLU_RATIO    = 0.05       # ì¸í”Œë£¨ì–¸ì„œ ë¹„ìœ¨ (ìƒìœ„ 5%)\n",
    "W_SIM          = 0.7        # ìœ ì‚¬ ì·¨í–¥ ê°€ì¤‘ì¹˜\n",
    "W_RAND         = 0.3        # ë¬´ìž‘ìœ„ ê°€ì¤‘ì¹˜\n",
    "SEED           = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 1) ì‚¬ìš©ìž ë¡œë“œ\n",
    "user_df = pd.read_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/user.csv')  # ìµœì†Œ user_id ì»¬ëŸ¼ í•„ìš”\n",
    "user_ids = user_df['user_id'].tolist()\n",
    "N = len(user_ids)\n",
    "\n",
    "# 2) ìœ ì‚¬ë„ í–‰ë ¬(0~1) ë§Œë“¤ê¸° â”€ ì—¬ê¸°ì„œëŠ”\n",
    "#    ê°™ì€ region / ìŠ¤íƒ€ì¼ì´ë©´ 1, ì•„ë‹ˆë©´ 0 ì˜ ë‹¨ìˆœ ì˜ˆì‹œ\n",
    "#    (ì„ í˜¸ ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ì „ë¶€ 0 ë°°ì—´ë¡œ ë‘ê³  ì™„ì „ ëžœë¤)\n",
    "sim = np.zeros((N, N))\n",
    "\n",
    "if {'pref_region','pref_style'}.issubset(user_df.columns):\n",
    "    for i, u in enumerate(user_ids):\n",
    "        for j, v in enumerate(user_ids):\n",
    "            if i==j:\n",
    "                continue\n",
    "            same_region = user_df.at[i, 'pref_region'] == user_df.at[j, 'pref_region']\n",
    "            same_style  = user_df.at[i, 'pref_style']  == user_df.at[j, 'pref_style']\n",
    "            sim[i, j] = 0.5*same_region + 0.5*same_style  # ë‘˜ë‹¤ ê°™ìœ¼ë©´ 1, í•˜ë‚˜ë§Œ ê°™ìœ¼ë©´ 0.5\n",
    "\n",
    "# 3) ì¸í”Œë£¨ì–¸ì„œ ì„ ì • (íŒ”ë¡œì›Œ ë§Žì´ ë°›ìŒ)\n",
    "infl_n = max(1, int(N * INFLU_RATIO))\n",
    "infl_ids = np.random.choice(user_ids, infl_n, replace=False)\n",
    "\n",
    "# 4) íŒ”ë¡œìš° ìƒì„±\n",
    "follows = []\n",
    "f_id = 1\n",
    "for idx, uid in enumerate(user_ids):\n",
    "    # íŒ”ë¡œìš°í•  ìˆ˜ candidate pool (ìžê¸° ì œì™¸)\n",
    "    candidates = [x for x in user_ids if x != uid]\n",
    "\n",
    "    # ê¸°ë³¸ íŒ”ë¡œìš° ìˆ˜ = Poisson(AVG_FOLLOW_OUT)\n",
    "    k = max(1, np.random.poisson(lam=AVG_FOLLOW_OUT))\n",
    "\n",
    "    # ê°€ì¤‘ì¹˜:  w_sim * sim + w_rand * uniform\n",
    "    weights = (W_SIM * sim[idx] + W_RAND * np.random.rand(N))\n",
    "    weights[idx] = 0  # self 0\n",
    "    # ì¸í”Œë£¨ì–¸ì„œëŠ” weight ë³´ì •(ë§Žì´ íŒ”ë¡œìš° ë°›ë„ë¡)\n",
    "    for j, cand in enumerate(user_ids):\n",
    "        if cand in infl_ids:\n",
    "            weights[j] *= 2.5   # ê°€ì¤‘ì¹˜ ìƒìŠ¹\n",
    "\n",
    "    # ì •ê·œí™” í›„ ìƒ˜í”Œ\n",
    "    probs = weights / weights.sum()\n",
    "    to_follow = np.random.choice(user_ids, size=k, replace=False, p=probs)\n",
    "\n",
    "    for target in to_follow:\n",
    "        follows.append({'f_id': f_id, 'from_user': uid, 'to_user': int(target)})\n",
    "        f_id += 1\n",
    "\n",
    "# 5) deduplicate í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ì œê±°\n",
    "follow_df = pd.DataFrame(follows).drop_duplicates()\n",
    "follow_df.to_csv('/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our/follow_migrated.csv', index=False)\n",
    "print(f\"ìƒì„±ëœ follow ìˆ˜: {len(follow_df)} / ì‚¬ìš©ìž ìˆ˜: {N}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Like Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "log_df     = pd.read_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/log.csv\")\n",
    "follow_df  = pd.read_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/follow.csv\")          # from_user, to_user\n",
    "visit_df   = pd.read_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/capital/tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_E.csv\") # DGSTFN ë“±\n",
    "\n",
    "# 1) ìž‘ì„±ìž â†’ DGSTFN ë§¤í•‘ ëŒ€ë¹„ìš©\n",
    "log_meta = log_df[['log_id', 'user_id', 'create_at']].merge(\n",
    "    visit_df[['VISIT_AREA_ID', 'DGSTFN']],\n",
    "    left_on='log_id',      # log_id == VISIT_AREA_ID ë¼ê³  ê°€ì •(ì´ë¯¸ ë§¤í•‘)\n",
    "    right_on='VISIT_AREA_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "likes = []\n",
    "\n",
    "for _, row in log_meta.iterrows():\n",
    "    author = row['user_id']\n",
    "    likers = follow_df.loc[follow_df['to_user']==author, 'from_user'].tolist()   # íŒ”ë¡œì›Œë“¤\n",
    "    candidate_pool = set(likers) | set(np.random.choice(log_df['user_id'], 5))   # íŒ”ë¡œì›Œ+ëžœë¤ 5ëª…\n",
    "    \n",
    "    for u in candidate_pool:\n",
    "        # ë™ì¼ ì‚¬ìš©ìžê°€ ìžê¸° ê¸€ì—” ì¢‹ì•„ìš” ì•ˆ ëˆ„ë¥´ê²Œ í•  ìˆ˜ë„ ìžˆìŒ\n",
    "        if u == author: \n",
    "            continue\n",
    "        \n",
    "        # í™•ë¥  ê²°ì •\n",
    "        if u in likers:\n",
    "            p = 0.35\n",
    "        elif row['DGSTFN']>=4:\n",
    "            p = 0.20\n",
    "        else:\n",
    "            p = 0.05\n",
    "        \n",
    "        if rng.random() < p:\n",
    "            likes.append({'log_id': row['log_id'], 'user_id': u})\n",
    "\n",
    "like_df = pd.DataFrame(likes).drop_duplicates()\n",
    "like_df.to_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/like.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Comment (ëŒ“ê¸€) Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "  5: [\"ì™€, ìµœê³ ë„¤ìš”!\", \"ì—¬ê¸° ê¼­ ê°€ë´ì•¼ê² ì–´ìš”ðŸ˜\", \"ì‚¬ì§„ì´ ì •ë§ ë©‹ì ¸ìš”!\"],\n",
    "  4: [\"ì¢‹ì•„ë³´ì—¬ìš”!\", \"ê¿€íŒ ê°ì‚¬í•´ìš”\", \"ê°€ë³´ê³  ì‹¶ì–´ìš”\"],\n",
    "  3: [\"ì •ë³´ ê³ ë§ˆì›Œìš”!\", \"ìž¬ë°Œì–´ ë³´ìž…ë‹ˆë‹¤\"],\n",
    "  2: [\"ì•„ì‰¬ì› êµ°ìš”ðŸ˜¢\", \"ë‹¤ìŒì—” ë” ì¢‹ê¸¸!\"],\n",
    "  1: [\"í—‰â€¦ ë³„ë¡œì˜€ë‚˜ ë´ìš”\", \"ì •ë³´ ê³µìœ  ê°ì‚¬\"]\n",
    "}\n",
    "\n",
    "import itertools, datetime as dt\n",
    "comments = []\n",
    "loco_id  = itertools.count(1)\n",
    "\n",
    "for _, row in log_meta.iterrows():\n",
    "    author   = row['user_id']\n",
    "    rating   = int(row['DGSTFN']) if not np.isnan(row['DGSTFN']) else 3\n",
    "    pool_temp= templates.get(rating, templates[3])\n",
    "\n",
    "    followers = follow_df.loc[follow_df['to_user']==author, 'from_user']\n",
    "    cand_non  = rng.choice(log_df['user_id'], 5, replace=False)\n",
    "    for u in set(followers) | set(cand_non):\n",
    "        if u==author:\n",
    "            continue\n",
    "        p = 0.12 if u in followers.values else 0.03\n",
    "        if rng.random() < p:\n",
    "            # create_at ì²˜ë¦¬: NaTë©´ í˜„ìž¬ì‹œê°„ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©\n",
    "            base_time = pd.to_datetime(row['create_at'])\n",
    "            if pd.isnull(base_time):\n",
    "                base_time = pd.Timestamp.now()\n",
    "            comment_time = base_time + pd.Timedelta(minutes=int(rng.integers(5, 720)))\n",
    "            comments.append({\n",
    "                'loco_id'    : next(loco_id),\n",
    "                'log_id'     : row['log_id'],\n",
    "                'user_id'    : u,\n",
    "                'loco_comment': rng.choice(pool_temp),\n",
    "                'create_at'  : comment_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'parent_id'  : None\n",
    "            })\n",
    "\n",
    "comment_df = pd.DataFrame(comments)\n",
    "comment_df.to_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/log_comment.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Action Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = []\n",
    "ts_now = pd.Timestamp('now')\n",
    "\n",
    "# â‘  post\n",
    "ua.extend([{\n",
    "    'action_id'  : i,\n",
    "    'user_id'    : r['user_id'],\n",
    "    'target_id'  : r['log_id'],\n",
    "    'action_type': 'post',\n",
    "    'target_type': 'log',\n",
    "    'action_time': r['create_at']\n",
    "} for i, r in log_df.iterrows()])\n",
    "\n",
    "# â‘¡ like\n",
    "for _, r in like_df.iterrows():\n",
    "    ua.append({\n",
    "        'action_id'  : None,\n",
    "        'user_id'    : r['user_id'],\n",
    "        'target_id'  : r['log_id'],\n",
    "        'action_type': 'like',\n",
    "        'target_type': 'log',\n",
    "        'action_time': ts_now.isoformat()\n",
    "    })\n",
    "\n",
    "# â‘¢ comment\n",
    "for _, r in comment_df.iterrows():\n",
    "    ua.append({\n",
    "        'action_id'  : None,\n",
    "        'user_id'    : r['user_id'],\n",
    "        'target_id'  : r['log_id'],\n",
    "        'action_type': 'comment',\n",
    "        'target_type': 'log',\n",
    "        'action_time': r['create_at']\n",
    "    })\n",
    "\n",
    "user_actions_df = pd.DataFrame(ua)\n",
    "user_actions_df['action_id'] = range(1, len(user_actions_df)+1)\n",
    "user_actions_df.to_csv(\"/Users/kimmo/TRAVEL-ON-NA/TravelOnNa_AI/Data/our_c/user_actions.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
